{
  "eval_results": {
    "bleu": 0.04008810933920555,
    "rouge1": 0.28185528048199204,
    "rouge2": 0.06689022485760546,
    "rougeL": 0.1524044345680387,
    "length_ratio": 2.761265157764213,
    "combined_f1": 0.0634788809242123,
    "final_score": 0.0634788809242123
  },
  "eval_dataset": [
    {
      "input_text": "Title: Label-Dependencies Aware Recurrent Neural Networks\nDomains: Computer science\n\nintroduction: in the last few years recurrent neural networks ( rnns )   have proved very effective in several natural language processing ( nlp ) tasks such as part - of - speech tagging ( pos tagging ) , chunking , named entity recognition ( ner ) , spoken language understanding ( slu ) , machine translation and even more   .these models are particularly effective thanks to their recurrent architecture , which allows neural models to keep in memory past information and re - use it at the current processing step .in the literature of rnns applied to nlp , several architectures have been proposed .at first elman and jordan rnns , introduced in and known also as simple rnns , have been adapted to nlp .the difference between these two models is in the type of connection giving the recurrent character to these two architectures : in the elman rnn the recursion is a loop at the hidden layer , while in the jordan rnn it relies the output layer to the hidden layer .this last recursion allows to use at the current step labels predicted for previous positions in a sequence .these two recurrent models have shown limitations in learning relatively long contexts   .in order to overcome this limitation the rnns known as long short - term memory ( lstm ) have been proposed   .recently , a simplified and , apparently , more effective variant of lstm has been proposed , using gated recurrent units and thus named gru   .despite outstanding performances on several nlp tasks , rnns have not been explicitly adapted to integrate effectively label - dependency information in sequence labeling tasks .their sequence labeling decisions are based on intrinsically local functions ( e.g. the softmax ) .in order to overcome this limitation , sophisticated hybrid rnn+crf models have been proposed where the traditional output layer is replaced by a crf neural layer .these models reach state - of - the - art performances , their evaluation however is not clear .in particular it is not clear if performances derive from the model itself , or thanks to particular experimental conditions .in   for example , the best result of pos tagging on the penn treebank corpus is an accuracy of inlineform0 , which is reached using word embeddings trained using glove   , on huge amount of unlabeled data .the model of   without pre - trained embeddings reaches an accuracy of inlineform1 , which does n't seem that outstanding if we consider that a crf model dating from 2010 , trained from scratch , without using any external resource , reaches an accuracy of inlineform2 on the same data   .we achieved the same result on the same data with a crf model trained from scratch using the incremental procedure described in   .moreover , the first version of the network proposed in this paper , but using a sigmoid activation function and only the inlineform3 regularization , tough with a slightly different data preprocessing , achieves an accuracy on the penn treebank of inlineform4   .the intuition behind this paper is that embeddings allow a fine and effective modeling not only of words , but also of labels and label dependencies , which are crucial in some tasks of sequence labeling .in this paper we propose , as alternative to rnn+crf models , a variant of rnn allowing this more effective modeling .surprisingly , a simple modification to the rnn architecture results in a very effective model : in our variant of rnnthe recurrent connection connects the output layer to the input layer and , since the first layer is just a look - up table mapping discrete items into embeddings , labels predicted at the output layer are mapped into embeddings the same way as words .label embeddings and word embeddings are combined at the hidden layer , allowing to learn relations between these two types of information , which are used to predict the label at current position in a sequence .our intuition is that using several label embeddings as context , a rnn is able to model correctly label - dependencies , the same way as more sophisticated models explicitly designed for sequence labeling like crfs   .this paper is a straight follow - up of   . contributions with respect to that work are as follows :i ) an analysis of performances of forward , backward and bidirectional models .ii )the use of relu hidden layer and dropout regularization   at the hidden and embedding layers for improved regularized models .iii )the integration of a character - level convolution layer .iv )an in - depth evaluation , showing the effect of different components and of different information level on the performance .v )a straightforward comparison of the proposed variant of rnn to elman , jordan , lstm and gru rnns , showing that the new variant is at least as effective as the best rnn models , such as lstm and gru .our variant is even more effective when taking label - dependencies into account is crucial in the task , proving that our intuition is correct .an high level schema of simple rnns and of the variant proposed in this paper is shown in figure figref1 ,where inlineform5 is the input word , inlineform6 is the label , inlineform7 , inlineform8 , inlineform9 and inlineform10are the model parameters , which will be discussed in the following sections .since evaluations on tasks like pos tagging on the penn treebank are basically reaching perfection ( state - of - the - art is at inlineform11 accuracy ) , any new model would probably provide little or no improvement .also , performances on this type of tasks seem to have reached a plateau , as models achieving inlineform12 accuracy or even better , were already published starting from 2003   .we propose instead to evaluate all the models on two different and widely used tasks of spoken language understanding   , which provide more variate evaluation settings : atis   and media   .atis is a relatively simple task and does n't require a sophisticated modeling of label dependencies .this task allows to evaluate models in similar settings as tasks like pos tagging or named entity recognition as defined in the conll shared task 2003 , both widely used as benchmarks in nlp papers .media is a very challenging task , where the ability of models to keep label dependencies into account is crucial to obtain good results .results show that our new variant is as effective as the best rnn models on a simple task like atis , still having the advantage of being much simpler .on the media task however , our variant outperforms all the other rnns by a large margin , and even sophisticated crf models , providing the best absolute result ever achieved on this task .the paper is organized as follows : in the next section we describe the rnns used in the literature for nlp , starting from existing models to arrive at describing the new variant we propose .in the section secref3 we present the corpora used for evaluation , the experimental settings and the results obtained in several experimental conditions .we draw some conclusions in section secref4 .\n\nrecurrent neural networks (rnns): in this section we describe the most popular rnns used for nlp , such as elman and jordan rnns and the most sophisticated rnns like lstm and gru   .we also describe training and inference procedures , and the rnn variant we propose .\n\nelman and jordan rnns: elman and jordan rnns are defined as follows :  displayform0  displayform0the difference between these two models is in the way of computing hidden activities , while the output is computed in the same way :  displayform0  inlineform13 and inlineform14 are respectively the hidden and output layer 's activities , inlineform15 is an activation function , inlineform16 , inlineform17and inlineform18 are the parameters at the hidden , output and recurrent layer , respectively( biases are omitted to keep equations lighter ) .inlineform19 is the hidden layer activity computed at previous time step and used as context in the elman rnn , while inlineform20 is the previous predicted labels , used as context in the jordan rnn .inlineform21 is the input , which is often the concatenation of word embeddings in a fixed window inlineform22( for window of words ) around the current word inlineform23 to be labeled .we define as inlineform24 the embedding of any word inlineform25 .inlineform26 is then defined as :  displayform0where inlineform27 is the concatenation of vectors ( or matrices in the following sections ) .the inlineform28 function , given a set inlineform29 of inlineform30 numerical values inlineform31 , associated to discrete elements inlineform32 , computes the probability associated to each element as :  inlineform33 inlineform34this function allows to compute the probability associated to each label and choose as predicted label the one with the highest probability .\n\nlong short-term memory (lstm) rnns: while lstm is often used as the name of the whole network , it just defines a different way of computing the hidden layer activities .lstms use gate units to control how past and present information affect the network 's internal state , and a cell to store past information that is going to be used as context at the current processing step .forget , input gates and cell state are computed as :  displayform0  inlineform35 is used to indicate a different activation function from inlineform36 .inlineform37 is actually an intermediate value used to update the cell state value as follows :  displayform0  inlineform38 is the element - wise multiplication .once these quantities have been computed , the output gate is computed and used to control the hidden layer activities at the current time step inlineform39 :  displayform0once again ( and in the remainder of the paper ) , biases are omitted to keep equations lighter .as we can see , each gate and the cell state have their own parameter matrices inlineform40 and inlineform41 , used for the linear transformation of the previous hidden state ( inlineform42 ) and the current input ( inlineform43 ) .the evolution of the lstm layer named gru ( gated recurrent units )   , combines together forget and input gates , and the previous hidden layer with the cell state :  displayform0gru is thus a simplification of lstm , it uses less units and it has less parameters to learn .\n\nld-rnn : label-dependencies aware recurrent neural networks: the variant of rnn that we propose in this paper can be thought of as having a recurrent connection from the output to the input layer .note that from a different perspective , this variant can just be seen as a feed - forward neural network ( ffnn ) using previous predicted labels as input .since jordan rnn has the same architecture , the only difference being that in contrast to jordan models we embed labels , we still prefer talking about recurrent network .this simple modification to the architecture of the network has important consequences on the model .the reason motivating this modification is that we want embeddings for labels and use them the same way as word embeddings .like we mentioned in the introduction , the first layer is a look - up table mapping discrete , or one - hot , representations into distributional representations .such representations can encode very fine syntactic and semantic properties , as it has already been proved by word2vec   or glove   .we want similar properties to be learned also for labels , so that to encode in label embeddings the label dependencies needed for sequence labeling tasks .in this paper we learn label embeddings from the sequences of labels associated to word sentences in annotated data .but this procedure could be applied also when structured label information is available .we could thus exploit syntactic parse trees , structured named entities or entity relations for learning sophisticated label embeddings .the idea of using label embeddings has been introduced in   for dependency parsing , resulting in a very effective parser .in this paper we go ahead with respect to   by using several label embeddings as context to predict the label at current position in a sequence .also we pre - train label embeddings like it is usually done for words .as consequence , we learn first generic dependencies between labels without their interactions with words .such interactions are then integrated and refined during the learning phase of the target sequence labeling task .for this ability to learn label - dependencies , we name our variant ld - rnn , standing for label dependencies aware rnn .using the same formalism as before , we define inlineform44the matrix for word embeddings , while inlineform45 is the matrix for label embeddings .the word - level input to our rnn is inlineform46 as for the other rnns , while the label - level input is :  displayform0which is the concatenation of vectors representing the inlineform47 previous predicted labels ( inlineform48 stands ( for window of labels ) ) .the hidden layer activities of our rnn variant are computed as :  displayform0we note that we could rewrite the equation above as inlineform49 with a similar formalism as before , the two equations are equivalent if we define inlineform50 .thanks to the use of label embeddings and their combination at the hidden layer , our ld - rnn variant learns very effectively label dependencies .since the other rnns in general do n't use explicitly the label information as context , they can predict incoherent label sequences .as we already mentioned , this limitation lead research toward hybrid rnn+crf models   .another consequence of the modification introduced in our rnn variant is an improved robustness to prediction mistakes .since we use several label embeddings as context ( see inlineform51 above ) , once the model has learned label embeddings , in the test phase it is unlikely that several prediction mistakes occur in the same context .even in that case , thanks to properties encoded in the embeddings , mistaken labels have similar representations to correct labels , allowing the model to possibly predict correct labels .reusing an example from   : if paris is replaced by rome in a text , this has no impact on several nlp tasks , as they are both proper nouns in pos tagging , localization in named entity recognition etc .using label embeddings provides the ld - rnn variant with the same robustness on the label side .while the traditional jordan rnn uses also previous labels as context information , it has not the same robustness because of the poor label representation used in adaptations of this model to nlp tasks .in jordan rnns used for nlp like labels are represented either with the probability distribution computed by the inlineform52 , or with the one - hot representation computed from the probability distribution .in the latter case it is clear that a prediction mistake can have a bad impact in the context , as the only value being 1 in the one - hot representation would be in the wrong position .instead , using the probability distribution may seem a kind of fazzy representation over several labels , but we have found empirically that the probability is very sharp and picked on one or just few labels .in any case this representation does n't provide the desired robustness that can be achieved with label embeddings .from another point of view , we can interpret the computation of the hidden activities in a jordan rnn as using label embeddings .in the equation eqref7 , the multiplication inlineform53 , since inlineform54 is a sparse vector , can be interpreted as the selection of an embedding from inlineform55 .even with this interpretation there is a substantial difference between a jordan rnn and our variant .in the jordan rnn , once the label embedding has been computed with inlineform56 , the result is not involved in the linear transformation applied by the matrix inlineform57 , which is only applied to the word - level input inlineform58 .the result of this multiplication is added to inlineform59and then the activation function is applied .in our variant in contrast , labels are first mapped into embeddings with inlineform60 .word and label inputs inlineform61 and inlineform62 are then both transformed by multiplying by inlineform63 , which is correctly dimensioned to apply the linear transformation on both inputs .in our variant thus , two different label transformations are always applied : i )the conversion from sparse to embedding representation ; ii )the linear transformation by multiplying label embeddings by inlineform64 .\n\nlearning and inference: we learn the ld - rnn variant like all the other rnns , by minimizing the cross - entropy between the expected label inlineform65 and the predicted label inlineform66 at position inlineform67 in the sequence , plus a inlineform68 regularization term :  displayform0  inlineform69 is a hyper - parameter to be tuned , inlineform70 is a short notation for inlineform71 .inlineform72 is the one - hot representation of the expected label .since inlineform73 above is the probability distribution over the label set , we can see the output of the network as the probability inlineform74 inlineform75 , where inlineform76 and inlineform77 are the input of the network ( words and labels ) , inlineform78 is the index of one of the labels defined in the targeted task .we can thus associate to the ld - rnn model the following decision function :  displayform0we note that this is still a local decision function , as the probability of each label is normalized at each position of a sequence .despite this , the use of label - embeddings inlineform79 as context allows the ld - rnn to effectively model label dependencies .since the other rnns like elman and lstm do n't use the label information in their context , their decision function can be defined as :  displayform0which can lead to incoherent predicted label sequences .we use the traditional back - propagation algorithm with momentum to learn our networks   .given the recurrent nature of the networks , the back - propagation through time ( bptt ) is often used   .this algorithm consists in unfolding the rnn for inlineform80 previous steps , inlineform81 being a parameter to choose , and using thus the inlineform82 previous inputs and hidden states to update the model 's parameters .the traditional back - propagation algorithm is then applied .this is equivalent to learn a feed - froward network of depth inlineform83 .the bptt algorithm is supposed to allow the network to learn arbitrary long contexts .however   has shown that rnns for language modeling learn best with only inlineform84 previous steps .this can be due to the fact that , at least in nlp , a longer context does not lead necessarily to better performances , as a longer context is also more noisy .since the bptt algorithm is quite expensive ,   chose to explicitly use the contextual information provided by the recurrent connection , and to use the traditional back - propagation algorithm , apparently without performance loss .in this paper we use the same strategy .when the contextual information is used explicitly in a jordan rnn , the hidden layer state is computed as follows :  displayform0a similar modification can be applied also to elman , lstm and gru rnns to keep into account explicitly the previous hidden states .to our knowledge however , these networks are effectively learned using only one previous hidden state   .from explanations above we can say that using explicit wide context of words and labels like we do in ld - rnn , can be seen as an approximation of the bptt algorithm .\n\ntoward more sophisticated networks: character-level convolution: even if word embeddings provide a very fine encoding of word features , several works such like   have shown that more effective models can be obtained using a convolution layer over characters of words .character - level information is indeed very useful to allow a model generalizing over rare inflected surface forms and even out - of - vocabulary words in the test phase .word embeddings are in fact much less effective in such cases .the convolution over word characters provide also the advantage of being very general : it can be applied in the same way to different languages , allowing to re - use the same system on different languages and tasks .in this paper we focus on a convolution layer similar to the one used in   for words .for any word inlineform85 of length inlineform86 , we define inlineform87 the embedding of the character inlineform88 of the word inlineform89 .we define inlineform90the matrix of parameters for the linear transformation applied by the convolution ( once again we omit the associated bias ) .we compute a convolution of window size inlineform91 over characters of a word inlineform92 as follows :  inlineform93 inlineform94  inlineform95  inlineform96the inlineform97 function is the so - called max - pooling   .while it is not strictly necessary mapping characters into embeddings , it would be probably less interesting applying the convolution on discrete representations .the matrix inlineform98 is made of the concatenation of vectors returned from the application of the linear transformation inlineform99 .its size is thus inlineform100 , where inlineform101 is the size of the convolution layer .the max - pooling computes the maxima over the word - length direction , thus the final outputinlineform102 has size inlineform103 , which is independent from the word length .inlineform104 can be interpreted as a distributional representation of the wordinlineform105 encoding the information at inlineform106 's character level .this is a complementary information with respect to word embeddings , which encode inter - word information , and provide the model with an information similar to what is provided by discrete lexical features like word prefixes , suffixes , capitalization information etc . , plus information about morphologically correct words of a given language .\n\nrnn complexities: the improved modeling of label dependencies in our ld - rnn variant is achieved at the cost of more parameters with respect to the simple rnn models .however the number of parameters is still much less than sophisticated networks like lstm .in this section we provide a comparison of rnns complexity in terms of the number of parameters .we introduce the following symbols : inlineform107 and inlineform108 are the size of the hidden and output layers , respectively .the size of the output layer is the number of labels ; inlineform109 is the embedding size , in ld - rnn we use the same size for word and label embeddings ; inlineform110 is the window size used for context words ; and inlineform111 is the number of label embeddings we use as context in ld - rnn .we analyze the hidden layer of all networks , and the embedding layer for ld - rnn .the other layers are exactly the same for all the networks described in this paper .for elman and jordan rnns , the hidden layer has the following number of parameters , respectively :  inlineform112  inlineform113subscripts indicate from which matrix the parameters come .the factor inlineform114 comes from the inlineform115 words used as input context and then mapped into embeddings .the factor inlineform116 in jordan rnn is due to the fact that the matrix inlineform117 connects output and hidden layers .in ld - rnn we have :  inlineform118the factor inlineform119 is due to the use of the matrixinlineform120 containing inlineform121 label embeddings of sizeinlineform122 .since in this paper we chose inlineform123 and inlineform124 , and since in ld - rnn we do n't use any matrix r on the recurrent connection , the fact of using label embeddings does n't increase the number of parameters of the ld - rnn variant .the hidden layer of ld - rnn however is dimensioned to connect all the word and label embeddings to all the hidden neurons .as consequence in the matrixinlineform125we have inlineform126 more parameters than in the matrix inlineform127 of elman and jordan rnns .in lstm and gru rnns we have two extra matrices inlineform128 and inlineform129 for each gate and for the cell state , used to connect the previous hidden layer and the current input , respectively .these two matrices contain thus inlineform130and inlineform131 parameters , respectively .using the same notation and the same settings as above , in the hidden layer of lstm and gru we have the following number of parameters :  inlineform132  inlineform133the 3 for gru reflects the fact that this network uses only 2 gates and a cell state .it should be pointed out , however , that while we have been testing lstm and gru with a word window for a matter of fair comparison , these layers are applied on the current word and the previous hidden layer only , without the need of a word window .this is because this layer learns automatically how to use previous word information .in such case the complexity of the lstm layer reduces to inlineform134 .if we choose inlineform135 , such complexity is comparable to that of ld - rnn in terms of number of parameters ( slightly less actually ) .the lstm is still more complex however because the hidden layer computation requires 4 gates and the cell state ( inlineform136 ) computations ( each involving 2 matrix multiplications ) , the update of the new cell state inlineform137 ( involving also 2 matrix multiplications ) , and only after the hidden state can be computed .ld - rnn 's hidden state , in contrast , requires only matrix rows selection and concatenation to compute inlineform138 and inlineform139 , which are very efficient operations , and then the hidden state can already be computed .as consequence , while the variant of rnn we propose in this paper is more complex than simple rnns , lstm and gru rnns are by far the most complex networks .\n\nforward, backward and bidirectional networks: the rnns introduced in this paper are proposed as forward , backward and bidirectional models   .the forward model is what has been described so far .the architecture of the backward model is exactly the same , the only difference is that the backward model processes data from the end to the begin of sequences .labels and hidden layers computed by the backward model can thus be used as future context in a bidirectional model .bidirectional models are described in details in   .in this paper we utilize the version using separate forward and backward models .the final output is computed as the geometric mean of the output of the two individual models , that is :  inlineform140where inlineform141 and inlineform142 are the output of the forward and backward models , respectively .in the development phase of our systems , we noticed no difference in terms of performance between the two types of bidirectional models described in   .we chose thus the version described above , since it allows to initialize all the parameters with the forward and backward models previously trained .as consequence the bidirectional model is very close to a very good optimum since the first learning iteration , and very few iterations are needed to learn the final model .\n\ncorpora for spoken language understanding: we evaluated our models on two tasks of spoken language understanding ( slu )   :the atis corpus ( air travel information system )   was collected for building a spoken dialog system able to provide flight information in the united states .atis is a simple task dating from 1993 .training data are made of 4978 sentences chosen among dependency - free sentences in the atis-2 and atis-3 corpora .the test set is made of 893 sentences taken from the atis-3 nov93 and dec94 data .since there are not official development data , we taken a part of the training set for this purpose .the word and label dictionaries contain 1117 and 85 items , respectively .we use the version of the corpus published in   , where some word classes are available , such as city names , airport names , time expressions etc .these classes can be used as features to improve the generalization of the model on rare or unseen words .more details about this corpus can be found in   .an example of utterance transcription taken from this corpus is \u201c i want all the flights from boston to philadelphia today \u201d .the words boston , philadelphia and today in the transcription are associated to the concepts departure.city , arrival.city and departure.date , respectively .all the other words do n't belong to any concept , they are associated to the void concept named o ( for outside ) .this example show the simplicity of this task : the annotation is sparse , only 3 words of the transcription are associated to a non - void concept ; there is no segmentation problem , as each concept is associate to one word .because of these two characteristics , the atis task is similar on the one hand to a pos tagging task , where there is no segmentation of labels over multiple words ; on the other hand it is similar to a linear named entity recognition task , where the annotation is sparse .we are aware of the existence of two version of the atis corpus : the official version published starting from   , and the version associated to the tutorial of deep learning made available by the authors of   .. this last version has been modified , some proper nouns have been re - segmented( for example the token new - york has been replaced by two tokens new york ) , and a preprocessing has been applied to reduce the word dictionary ( numbers have been converted into the conventional token digit , and singletons of the training data , as well as out - of - vocabulary words of the developpement and test data , have been converted into the token unk ) .following the tutorial of   we have been able to download the second version of the atis corpus .however in this version word classes that are available in the first version are not given .we ran some experiments with these data , using only words as input .the results we obtained are comparable with those published in   , in part from same authors of   .however without word classes we can not fairly compare with works that are using them .in this paper we thus compare only with published works that used the official version of atis .the french corpus media   was collected to create and evaluate spoken dialog systems providing touristic information about hotels in france .this corpus is made of 1250 dialogs collected with wizard - of - oz approach .the dialogs have been manually transcribed and annotated following a rich concept ontology .simple semantic components can be combined to create complex semantic structures .the rich semantic annotation is a source of difficulties , but also the annotation of coreference phenomena .some words can not be correctly annotated without knowing a relatively long context , often going beyond a single dialog turn .for example in the utterance transcription \u201c yes , the one which price is less than 50 euros per night \u201d , the one is a mention of an hotel previously introduced in the dialog .statistics on the corpus media are shown in table tabref38 .the task resulting from the corpus media can be modeled as a sequence labeling task by chunking the concepts over several words using the traditional bio notation   .thanks to the characteristics of these two corpora , together with their relatively small size which allows training models in a reasonable time , these two tasks provide ideal settings for the evaluation of models for sequence labeling .a comparative example of annotation , showing also the word classes available for the two tasks and mentioned above , is shown in the table tabref37 .\n\nsettings: the rnn variant ld - rnn has been implemented in octave using openblas for low - level computations .ld - rnn models are trained with the following procedure :neural network language models ( nnlm ) , like the one described in   , are trained for words and labels to generate the embeddings ( separately ) .forward and backward models are trained using the word and label embeddings trained at previous step .the bidirectional model is trained using as starting point the forward and backward models trained at previous step .we ran also some experiments using embeddings trained with word2vec   .the results obtained are not significantly different from those obtained following the procedure described above .this outcome is similar to the one obtained in   .since the tasks addressed in this paper are made of small data , we believe that any embedding is equally effective .in particular tools like word2vec are designed to work on relatively big amount of data .results obtained with word2vec embeddings will not be described in the following sections .we roughly tuned the number of learning epochs for each model on the development data of the addressed tasks : 30 epochs are used to train word embeddings , 20 for label embeddings , 30 for the forward and backward models , 8 for the bidirectional model ( the optimum of this model is often reached at the first epoch on the atis task , between the 3rd and the 5th epoch on media ) .at the end of the training phase , we keep the model giving the best prediction accuracy on the development data .we stop training the model if the accuracy is not improved for 5 consecutive epochs ( also known as early stopping strategy   ) .we initialize all the weights with the \u201c so called \u201d xavier initialization   , theoretically motivated in   as keeping the standard deviation of the weights during the training phase when using relu , which is the type of hidden layer unit we chose for our variant of rnn .we also tuned some of the hyper - parameters on the development data : we found out that the best initial learning rate is inlineform143 , this is linearly decreased with a value computed as the ratio between the initial learning rate and the number of epochs ( learing rate decay ) .we combine dropout and inlineform144 regularization   ,the best value for the dropout probability is inlineform145 at the hidden layer , inlineform146 at the embedding layer on atis , inlineform147 on media .the best coefficient ( inlineform148 ) for the inlineform149 regularization is inlineform150 for all the models , except for the bidirectional model where the best is inlineform151 .we ran also some experiments for optimizing the size of the different layers .in order to minimize the time and the number of experiments , this optimization has been based on the result provided by the forward model on the two tasks , and using only words and labels as input ( without word classes and character convolution , which were optimized separately ) .the best size for the embeddings and the hidden layer is 200 for both tasks .the best size for the character convolution layer is 50 on atis , 80 on media .in both cases , the best size for the convolution window is 1 , meaning that characters are used individually as input to the convolution .a window of size 3 ( one character on the left , one on the right , plus the current character ) gives roughly the same results , we thus prefer the simpler model .with a window of size 5 , results starts to slightly deteriorate .we also optimized the size of the word and label context used in the ld - rnn variant .on atis the best word context size is 11 ( 5 on the lest , 5 on the right plus the current word ) , the best label context size is 5 .on media the best sizes are 7 and 5 respectively .these values are the same found in   and comparable to those of   .the best parameters found in this phase has been used to obtain baseline models .the goal was to understand the behavior of the models with the different level of information used : the word classes available for the tasks , and the character level convolution .some parameters needed to be re - tuned , as we will describe later on .concerning training and testing time of our models , the overall time to train and test forward , backward and bidirectional models , using only words and classes as input , is roughly 1 hour 10 minutes on media , 40 minutes on atis .these times go to 2 hours for media and 2 hours 10 minutes for atis , using also word classes and character convolution as input .all these times are measured on a intel xeon e5 - 2620 at inlineform152 ghz , using 16 cores .\n\nresults: all the results shown in this section are averages over 6 runs .embeddings were learned once for all experiments .in this section we describe results obtained with incremental levels of information given as input to the models : i )only words ( previous labels are always given as input ) , indicated with words in the tables ; ii ) words and classes words+classes ; iii ) words and character convolution words+cc ; iv ) all possible inputs words+classes+cc .the results obtained on the atis task are shown in the table tabref47 , results on media are in table tabref48 .results in these tables show that models have a similar behavior on the two tasks .in particular on atis , adding the different level of information results improve progressively and the best performance is obtained integrating words , labels and character convolution , though some of the improvements do not seem statistically significant , taking into account the small size of this corpus .this observation is confirmed by results obtained on media , where adding the character level convolution leads to a slight degradation of performances .in order to understand the reason of this behavior we analyzed the training phase on the two tasks .we found out that the main problem was an hidden layer saturation : with the number of hidden neurons chosen in the preliminary optimization phase using only words ( and labels ) , the hidden layer was not able to model the whole information richness provided by all the inputs at the same time .we ran thus some experiments using a larger hidden layer with size 256 , which gave the results shown in the two tables with the model ld - rnn words+classes+cc .for lack of time we did not further optimized the size of the hidden layer .beyond all of that , results shown in the table tabref47 and tabref48 are very competitive , as we will discuss in the next section .in this section we compare our results with the best results found in the literature .in order to be fair , the comparison is made using the same input information : words and classes .in the tables we use e - rnn for elman rnn , j - rnn for jordan rnn , i - rnn for the improved rnn proposed by   .in order to give an idea of how our rnn variant compares to lstm+crf models like the one of   , we ran an experiment on the penn treebank   .with a similar data pre - processing , exactly the same data split , using a sigmoid activation function , and using only words as input , the ld - rnn variant achieves an accuracy of inlineform153 .this is comparable to the inlineform154 achieved by the lstm+crf model of   without pre - trained embeddings .results on the atis task are shown in table tabref52 .on this task we compare to results published in   and   .the results in the table tabref52 show that all models obtain a good performance on this task , always higher than inlineform155inlineform156 .this confirm what we anticipated in the previous section concerning how easy is this task .the gru rnns of   and our variant ld - rnn obtain equivalent results ( inlineform157 ) , which is slightly better than all the other models , in particular with the bidirectional models .this is a good outcome , as our variant of rnn obtains the same result as gru while using much less parameters (see section secref31 for rnns complexity ) .indeed lstm and gru are considered very effective models for learning very long contexts .the way they are used in   allows to learn long contexts on the input side ( words ) , they are not adapted however to learn also long label contexts , which is what we do in this paper with our variant .the fact that the best word context on this task is made of 11 words , show that this is the most important information to obtain good results on this task .it is thus not surprising that the gru rnn achieves such good performance .comparing our results on the atis task with those published in   with a jordan rnn , which uses the same label context as our models , we can conclude that the advantage in the variant ld - rnn is given by the use of label embeddings and their combination at the hidden layer .this conclusion is more evident if we compare results obtained with rnns using label embeddings with the other rnns on the media task .this comparison is shown in table tabref53 .as we mentioned in the section secref34 , this task is very challenging for several reason , but in the context of this paper we focus on the label dependencies that we claim we can effectively model with our rnn variant .in this context we note that a traditional jordan rnn , the j - rnn of   , which is the only traditional model to explicitly use previous label information as context , is more effective than the other traditional models , including lstm and gru( inlineform158 f1 with j - rnn ,inlineform159 with gru , second best model among traditional rnns ) .we note also that on media , crfs , which are models specifically designed for sequence labeling , are by far more effective than the traditional rnns ( inlineform160 f1 with the crf of   ) .the only models outperforming crfs on the media task are the i - rnn model of   and our ld - rnn variant , both using label embeddings .even if results on media discussed so far are very competitive , this task has been designed for spoken language understanding ( slu )   .in slu the goal is to extract a correct semantic representation of a sentence , allowing a correct interpretation of the user will by the spoken dialog system .while the f1 measure is strongly correlated with slu evaluation metrics , the evaluation measure used most often in the literature is the concept error rate ( cer ) .cer is defined exactly in the same way as word error rate in automatic speech recognition , where words are replaced by concepts .in order to place our results on an absolute ranking among models designed for the media task , we propose a comparison in terms of cer to the best models published in the literature , namely   ,   and   .this comparison is shown in table tabref54 .the best individual models published by   ,   and   are crfs , achieving a cer of inlineform161 , inlineform162 and inlineform163 , respectively .these models use both word and classes , and a rich set of lexical features such like word prefixes , suffixes , word capitalization information etc .we note that the large gap between these crf models is due to the fact that the crf of   is trained with an improved margin criterion , similar to the large margin principle of svm   .we note also that comparing significance tests published in   , a difference of inlineform164 in cer is already statistically significant .since results in this paper are higher , we hypothesize than even smaller gains are significant .our best ld - rnn model achieve a cer of inlineform165 .to the best of our knowledge this is the best cer obtained on the media task with an individual model .moreover , instead of taking the mean of cer of several experiments , following a strategy similar to   , one can run several experiments and keep the model obtaining the best cer on the development data of the target task .results obtained using this strategy are shown in table tabref54 between parenthesis .the best result obtained by our ld - rnn is a cer of inlineform166 , the best absolute result on this task so far , even better than the rover model   used in   , which combines 6 individual models , including the individual crf model achieving inlineform167 cer .\n\nresults discussion: in order to understand the high performances of the ld - rnn variant on the media task , we made some simple analyses on the model output , comparing them to the output of a jordan rnn trained with our own system in the same conditions as ld - rnn models .the main difference between these two models is the general tendency of the jordan rnn to split a single concept into two or more concepts , mainly for concepts instantiated by long surface forms , such like command - tache .this concept is used to mean the general user will in a dialog turn ( e.g. hotel reservation , price information etc . ) .the jordan rnn often split this concept into several concepts by introducing a void label , associated to a stop - word .this is due to the limitation of this model to take relatively long label context into account , even if it is the only traditional rnn using explicitly previous labels as context information .surprisingly , ld - rnn never makes this mistake and in general never makes segmentation errors ( concerning the bio formalism ) .this can be due to two reasons .the first is that label embeddings learns similar representations for semantically similar labels .this allows the model to correctly predict start - of - concept ( b ) even if the target word has been seen in the training set only as continuation - of - concept ( i ) , or viceversa , as the two labels acquire very similar representations .the second reason , which is not in mutual exclusion with the first , is that the model factorizes information acquired on similar words seen associated to start - of - concept labels .thus if a word has not been seen associated to start - of - concept labels , but similar words do , the model is still able to provide the correct annotation .this second reason is what made neural networks popular for learning word embeddings in earlier publications   .in any case , in our experience , we never observed such precise behavior even with crf models tuned for the media task .for this reason we believe ld - rnn deserves the name of label dependencies aware rnn .still ld - rnn makes mistakes , which means that once a label annotation starts for a target word , even if the label is not the correct one , the same label is kept even if the following words provide evidence that the correct label is another one .ld - rnn tends to be coherent with previous labeling decisions .this behavior is due to the use of a local decision function which definitely relies heavily on the label embedding context , but it does n't prevent the model from being very effective .interestingly , this behavior suggests that ld - rnn could still benefit from a crf neural layer like those used in   .we leave this as future work .\n\nconclusion: in this paper we proposed a new variant of rnn for sequence labeling using a wide context of label embeddings in addition to the word context to predict the next label in a sequence .we motivated our variant as being more effective at modeling label dependencies .results on two spoken language understanding tasks show that i ) on a simple task like atis our variant achieves the same performance as much more complex models such as lstm and gru , which are claimed the most effective rnns ; ii ) on the media task , where modeling label dependencies is crucial , our variant outperforms by a large margin all the other rnns , including lstm and gru .when compared to the best models of the literature in terms of concept error rate ( cer ) , our rnn variant results to be more effective , achieving a state - of - the - art cer of inlineform168 .\n\nacknowledgements: this work has been partially funded by the french anr project democrat anr-15-ce38 - 0008 .",
      "target_text": "in the last few years , recurrent neural networks ( rnns ) have proved effective on several nlp tasks .despite such great success , their ability to model \\emph{sequence labeling } is still limited .this lead research toward solutions where rnns are combined with models which already proved effective in this domain , such as crfs .in this work we propose a solution far simpler but very effective : an evolution of the simple jordan rnn , where labels are re - injected as input into the network , and converted into embeddings , in the same way as words .we compare this rnn variant to all the other rnn models , elman and jordan rnn , lstm and gru , on two well - known tasks of spoken language understanding ( slu ) .thanks to label embeddings and their combination at the hidden layer , the proposed variant , which uses more parameters than elman and jordan rnns , but far fewer than lstm and gru , is more effective than other rnns , but also outperforms sophisticated crf models .",
      "output_text": "a hybrid crf+lstm model .in this paper we propose a new hybrid model based on lstm and crf , which we call label - dependent recurrent networks ( ldrn ) .the main idea of this model is to integrate label dependency information into the lstm recurrent unit .the lstm unit is still used to predict the next position in the sequence , but it also takes into account the dependency between the current position and the previous one .this dependency is taken into account in the form of a weighted sum of the output of the previous position and of the current one .the weighting factor is computed based on the dependency relation between the two positions .the model is evaluated on a large corpus of english and german pos tagged data .the results show that this model outperforms all the previous models on both tasks .in addition , the model is able to handle longer contexts than previous models .in conclusion , this paper presents a novel hybrid recurrent network model that integrates label dependency into lstm , achieving state-of-the-art results on both pos - tagging and chunking tasks."
    },
    {
      "input_text": "Title: Coated inclusions of finite conductivity neutral to multiple fields in two dimensional conductivity or anti-plane elasticity\nDomains: Mathematics\n\nintroduction: the purpose of this paper is to prove that if a coated inclusion in two dimensions is neutral to multiple uniform fields , then the core and the shell are confocal ellipses .we begin by defining the neutral inclusions .let inlineform0 and inlineform1 be bounded domains with lipschitz boundaries in inlineform2such that inlineform3so that inlineform4 is the core and inlineform5is the shell .the conductivity is inlineform6 in the core , inlineform7 in the shell , and inlineform8 in the matrix ( inlineform9 ) .so the conductivity distribution is given by inlineform10where inlineform11 is the characteristic function .the conductivities inlineform12 and inlineform13 are assumed to be isotropic ( scalar ) , but we allow inlineform14 to be anisotropic , i.e. , a positive definite symmetric constant matrix .for a given function inlineform15 with inlineform16 in inlineform17 , we consider displayform0this problem can be regarded as a conductivity problem or an anti - plane elasticity problem .the inclusion inlineform18( or inlineform19 ) is said to be neutral to the field inlineform20if the solution inlineform21 to ( eqref1 ) satisfies inlineform22 in inlineform23 .so the neutral inclusion to the field inlineform24 does not perturb the field outside the inclusion .in the imaging point of view , it means that the field inlineform25 can not probe the neutral inclusion .a particular interest lies in the inclusions neutral to uniform fields , i.e. , inlineform26 for some constant vector inlineform27 .if inlineform28 and inlineform29 are concentric disks , say inlineform30 and inlineform31 , and inlineform32 is isotropic, then one can easily see that inlineform33 is neutral to all uniform fields if the following relation holds : displayform0where inlineform34 ( the volume fraction ) .much interest in neutral inclusions ( to uniform fields ) was aroused by the work of hashin   .he showed that since insertion of neutral inclusions does not perturb the outside uniform field , the effective conductivity of the assemblage filled with coated inclusions of many different scales is inlineform35 satisfying ( eqref2 ) .it is also proved that this effective conductivity is a bound of the hashin - shtrikman bounds of the effective conductivity of arbitrary two phase composite .we refer to a book of milton   for development on neutral inclusions in relation to theory of composites .another interest in neutral inclusions has aroused in relation to imaging and invisibility cloaking by transformation optics .in this regard , we first observe that in general the solution inlineform36 to ( eqref1 ) satisfies inlineform37 as inlineform38 .but , if the inclusion is neutral to all uniform fields , then the linear part of inlineform39 is unperturbed and one can show using multi - polar expansions that inlineform40 as inlineform41 for any inlineform42 ( not necessarily linear ) .it means that it is harder to probe the neutral inclusions using inlineform43 .recently , ammari et al   extend the idea of neutral inclusions to construct multi - coated circular structures which are neutral not only to uniform fields but also to fields of higher order up to inlineform44 for a given integer inlineform45 ( which is called the gpt - vanishing structure , gpt for generalized polarization tensor ) , so that the solution inlineform46 to ( eqref1 ) satisfies inlineform47 as inlineform48 for any inlineform49 .this structure has a strong connection to the cloaking by transformation optics .the transformation optics proposed by pendry et al transforms a punctured disk ( sphere ) to an annulus to achieve perfect cloaking( the same transform was used to show non - uniqueness of the calder\u00f3n 's problem by greenleaf etal   ) .kohn et al   showed that if one transforms a disk with a small hole , then one can avoid singularities of the conductivity which occur on the inner boundary of the annulus and achieve near - cloaking instead of perfect cloaking .in   it is shown that if we coat the hole by the gpt - vanishing structure before transformation , then near - cloaking is dramatically enhanced .see also   for further development to helmholtz and maxwell 's equations .there have been some work on neutral inclusions of general shape .non - elliptic inclusions neutral to a single uniform field have been constructed by milton and serkov   when the conductivity inlineform50 of the core is either 0 or inlineform51 , and by jarczyk and mityushev   when inlineform52 is finite .in   , it is also proved that if an inclusion is neutral to all uniform field ( or equivalently , to two linearly independent uniform fields ) , then the core and shell are confocal ellipses , when inlineform53 is 0 or inlineform54 .that the confocal ellipses ( and ellipsoids ) are neutral toall uniform fields was proved by kerker   .the purpose of this paper is to prove that confocal ellipses are the only inclusions which are neutral to two fields even when inlineform55 is finite .we emphasize that the method of   can not be applied to the case when inlineform56 is finite .there the conformal mapping from the shell ( inlineform57 ) onto an annulus was used .but , there is no conformal mapping from inlineform58 onto a disk which maps inlineform59 to a concentric disk , except for some very special cases .more precisely we prove the following theorem .we emphasize that the theorem holds for any conductivity inlineform60 of the core ( finite , 0 , or inlineform61 ) .theorem 1.1 let inlineform62 and inlineform63 be boundeddomains with lipschitz boundaries in inlineform64such thatinlineform65 .if inlineform66 is neutral to inlineform67 for inlineform68 , then inlineform69 and inlineform70 are confocal ellipses .the key observation in proving theorem secref3 is that if the inclusion is neutral to two fields , then the fields inside the core is also uniform .using this fact , we are able to set up a free boundary value problem .we then use a conformal mapping to show that the solution to the free boundary value problem is a pair of confocal ellipses .this paper is organized as follows : in the next section we review layer potential representation of the solution to ( eqref1 ) .in section 3 , we show that if the inclusion is neutral to two fields , then the fields inside the core is uniform , and derive the free boundary value problem .in the last section we show that the solution to the free boundary value problem is confocal ellipses , and hence prove theorem secref3 .\n\nlayer potential representations of solutions: let inlineform71 be a bounded domain in inlineform72 with the lipschitz boundary .the single layer potential inlineform73 of a density function inlineform74 is defined by displayform0it satisfies the jump relation displayform0where the operator inlineform75 is defined by displayform0and inlineform76 is its inlineform77 -adjoint .the subscripts inlineform78 and inlineform79 indicate the limits from outside and inside inlineform80 , respectively .suppose that inlineform81 is isotropic .it is known ( see , for example ,   ) that there is a pair inlineform82( the subscript 0 indicates the mean value zero ) such that the solution inlineform83 to ( eqref1 ) can be represented as displayform0the transmission conditions ( continuity of the potential and the flux ) on the interfaces inlineform84 and inlineform85 are equivalent to displayform0  where displayform0here and throughout this paper inlineform86 denotes the outward normal derivative on inlineform87 .the system of integral equations ( eqref8 ) and ( ) has a unique solution ( see   ) .we emphasize that the representation ( eqref7 ) is valid even if inlineform88 is 0 or inlineform89 , and the solution inlineform90 is defined in inlineform91 .if inlineform92 then inlineform93 , and if inlineform94 then inlineform95 .note from the jump relation ( eqref5 )that inlineform96  so , we have displayform0similarly one can show that displayform0so , if inlineform97 is neutral to the field inlineform98 , then inlineform99 in inlineform100 , and hence we have displayform0\n\nuniformity of the field in the core: suppose that inlineform101 is neutral to both inlineform102 and inlineform103 .after a rotation if necessary , we may assume that inlineform104 is given by displayform0let inlineform105 , inlineform106 , be the solution to ( eqref1 ) with inlineform107 .then inlineform108 is the solution to ( eqref1 ) with inlineform109 replaced by inlineform110 .so , we may represent it as displayform0let inlineform111 denote the outward unit normal to inlineform112 or inlineform113 and let displayform0then we have from ( eqref8 ) and( ) displayform0  and from ( eqref12 ) displayform0let inlineform114 be the harmonic conjugate of inlineform115 in each connected component of inlineform116 .we may choose inlineform117 in inlineform118 .we emphasize that even though inlineform119 is not simply connected , a harmonic conjugate of inlineform120 exists there .in fact , a harmonic conjugate of inlineform121 exists in inlineform122 , and since inlineform123 and inlineform124 , a harmonic conjugate of inlineform125 exists in inlineform126 .define inlineform127 by displayform0here constants inlineform128 and inlineform129 are chosen so that inlineform130 is continuous across inlineform131 and inlineform132 .then inlineform133 satisfies displayform0where displayform0so inlineform134 is neutral to inlineform135 .we represent inlineform136 as inlineform137since inlineform138the pair of potential inlineform139 satisfies displayform0  and displayform0it follows from ( eqref17 ) and( eqref22 ) that inlineform140and since inlineform141 outside inlineform142 for inlineform143 , we have displayform0since inlineform144 and inlineform145 are harmonic in inlineform146 , we have inlineform147note that if inlineform148 outside inlineform149 , then inlineform150 .so we conclude displayform0we now see that ( eqref21 ) can be written as inlineform151by comparing this formula with ( eqref16 ) , we deduce displayform0we then have from ( eqref10 ) inlineform152and hence displayform0for some constant inlineform153 .so inlineform154 is uniform in inlineform155 .by substituting ( eqref17 ) and ( eqref25 ) into ( eqref14 ) , we have displayform0it then follows from ( eqref26 ) that displayform0by the exactly same argument with switched roles of inlineform156and inlineform157 , one can show that displayform0let inlineform158 be the newtonian potential on inlineform159 , i.e. , displayform0then , we have displayform0it then follows from ( eqref28 ) and ( eqref29 )that inlineform160where inlineform161 and inlineform162 are constants and inlineform163  we may assume inlineform164 by translating inlineform165and inlineform166 .observe that inlineform167 behaves as inlineform168 as inlineform169 , where inlineform170 denotes the area of inlineform171 .so , we have inlineform172or displayform0where inlineform173 ( the volume fraction ) .it is worth mentioning that this relation shows that inlineform174 and inlineform175 have opposite signs .we finally have displayform0it is worth mentioning that if the newtonian potential of a simply connected domain is quadratic inside the domain , then the domain is an ellipse .this fact was proved by dive   and nikliborc   , and is the key ingredient in resolution of the eshelby 's conjecture and the p\u00f3lya - szeg\u00f6 conjecture by kang and milton  ( see also   ) .in the next section we show that ( eqref33 ) implies that inlineform176 and inlineform177 are confocal ellipses .\n\nthe free boundary value problem: let inlineform178note that inlineform179 for inlineform180 , inlineform181 for inlineform182 , and inlineform183 is continuous across inlineform184 .so , by ( eqref33 )inlineform185 satisfiesdisplayform0we now show that if the problem ( eqref34 ) admits a solution for some inlineform186 , then inlineform187and inlineform188 are confocal ellipses .let inlineform189 and let inlineform190 be a solution to ( eqref34 ) .define inlineform191then inlineform192 is holomorphic in inlineform193 ,inlineform194 on inlineform195 , and inlineform196 oninlineform197 .let inlineform198 be the conformal mapping from inlineform199 for some inlineform200 onto inlineform201 .since inlineform202 and inlineform203 are lipschitz , inlineform204 is continuous on inlineform205 .let inlineform206 .then inlineform207 is holomorphic in inlineform208 and satisfies inlineform209 on inlineform210 and inlineform211 on inlineform212 .suppose that inlineform213 admits the laurent series expansion displayform0then we have displayform0since the laurent series expansion of inlineform214 is unique , we have displayform0for any integerinlineform215 .replacing inlineform216 with inlineform217 and taking complex conjugates we also have displayform0above two identities imply displayform0for any integerinlineform218 .since inlineform219 takes different values for different positive integersinlineform220 , we know that there are only one positive inlineform221 with inlineform222 .by ( eqref37 ) , the possibly nonzero coefficients of inlineform223 are inlineform224and inlineform225and the univalence of inlineform226 implies inlineform227 .finally , inlineform228 and inlineform229 are confocal ellipses since they are images of concentric circles by the map inlineform230 .\n\nacknowledgement: we are grateful to habib ammari and graeme milton for very helpful discussions on neutral inclusions .we also thank g. milton for pointing out the reference   to us .",
      "target_text": "we consider the problem of neutral inclusions for two - dimensional conductivity and anti - plane elasticity .the neutral inclusion , when inserted in a matrix having a uniform field , does not disturb the field outside the inclusion .the inclusion consists of a core and a shell .we show that if the inclusion is neutral to two linearly independent fields , then the core and the shell are confocal ellipses .",
      "output_text": "ion of a neutral inclusion into an elastic medium does not change the elastic properties of the medium , it follows that the inclusion is neutral if and only if the medium is neutral .he also showed that if the neutral medium is a finite conductive medium , then its conductivity can be expressed in terms of its conductive core and shell .in this paper , we prove that the neutrality of the conductive inclusion is equivalent to the isotropy of the neutral core and neutral shell .moreover , we show that the core is confocal and that the shell is isotopic to the core .the paper is organized as follows .section 2 gives the definition of neutral conductive inclusions , section 3 gives the proof of the main theorem , and section 4 gives some applications of the theorem .in section 5 , we discuss the implications of our results for the theory of elastic inclusions and for the study of conductivity in elastic media .the author would like to thank the referees for their helpful comments and suggestions .\n\nkeywords: conductivity, elastic inclusion, neutrality, isotopy, isotropicity, neutral core, neutral shell, neutral inclusion\n\nsummary: this paper presents a new approach to the problem of determining the neutral conductivity of a conductive material. It is based on the observation that if an inclusion in a two-dimensional conductivity system is neutral, then its core is a confocal ellipse and its shell is an isotope of the core. The main theorem of the paper establishes that this is the case for any neutral inclusion. The proof is given in section 2. Section 3 presents the main application of this theorem, which is the determination of the neutrity of an elastically inclusive medium. The theorem is applied to the case of a finite-conductive medium, and its implications are discussed in sections 4 and 5. The paper concludes with a brief discussion of some of the applications of this result. The author thanks the reviewers for their suggestions and comments, which have greatly improved the paper."
    },
    {
      "input_text": "Title: Generalized Friendship Paradox: An Analytical Approach\nDomains: Computer science, Mathematics\n\nintroduction: the friendship paradox is a phenomenon observed in various social networks .the term was coined by feld   .it has been empirically observed that people 's perception of their own popularity is self - aggrandizing ; most people believe that they are more popular than their friends on average   .however , feld observed that in reality , most people have fewer friends than their friends do .in   , this phenomena is used for the early detection of flu outbreaks among college students .in   , it is utilized to efficiently sample early - warning sensors during catastrophic events such as hurricanes .in addition to degree , the same paradox has been observed about other individual attributes ( called the generalized friendship paradox   , or gfp ) .for example , in   it has been observed that on twitter , for most people , their friends share , on average , more viral content and also tweet more .in   , it has been observed that in scientific collaboration networks , one 's co - authors have , on average , more citations , more publications and more co - authors .in this paper , we consider a network growth model which is a generalization of the preferential attachment scheme   .in our model , nodes are endowed with ` qualities ' ( ak.a .` fitness ' or ` attractiveness ' in the literature   ) .qualities are discrete positive numbers drawn from a given distribution inlineform0 and assigned to a node upon its birth ( remaining the same thenafter ) .we assume that the probability that node inlineform1 with degree inlineform2 andquality inlineform3 receives a link from subsequent nodesis proportional to inlineform4 .we obtain two statistical measures of this model : one is the degree - quality joint distribution , which is the fraction of nodes that have degree inlineform5 and quality inlineform6 in the steady state .the second quantity is the nearest - neighbor distribution of quality and degree : it gives the fraction of nodes with degree inlineform7 and quality inlineform8 that are connected to a node with degree inlineform9 and quality inlineform10 .equipped with these distributions , we can quantify the paradox and study how it depends on the underlying quality distribution inlineform11 .to our knowledge , no similar theoretical result is available in the literature for any network growth model ( either purely preferential   , or fitness - based   ) .we show that employing the above scheme as the attachment mechanism renders the occurrence of the gfp contingent upon the underlying distribution of node qualities .we then employ measures defined in the literature for assessing the gfp on the network level , and we investigate the dependence of these measures on the model parameters and the quality distribution .we demonstrate that , in the proposed model , the network exhibits a quality paradox at the network level for any quality distribution .we contend that this is indicative of a positive correlation between degree and quality ; i.e. , those with higher qualities are more likely to have higher degrees , and vice versa .\n\nmodel, notation and terminology: in the growth model considered in this paper , nodes are added successively to the network .the initial network has inlineform12 nodes and inlineform13 links .at each time step , one new node is added to the network .we assume that each node has an intrinsic quality , which is drawn from a given distribution inlineform14 .the quality is assigned to each new incoming node upon birth , and will remain the same thenafter .the mean of the distribution inlineform15 is denoted by inlineform16 .a node of degree inlineform17 and quality inlineform18 is also referred to as a inlineform19 node throughout .each new incoming node attaches to inlineform20 existing nodes in the network .we consider the simplest additive model that incorporates both degree ( popularity ) and quality in the dynamics of connection formation : the probability that an existing node with degree inlineform21 and quality inlineform22 receives a link from the new node is proportional to inlineform23 .this means that , for example , a paper that is new and has very few citations can compensate for its small degree with having a high quality .or in the social context , a newcomer who does not have many friends in the new social milieu but is gregarious and sociable can elevate the chances of making new friends .the new node is called the child of the existing nodes that it connects to , and they are called its parents .by a inlineform24 - inlineform25 child - parent pair , we mean a node with degree inlineform26 and quality inlineform27 that is connected to a parent node of degree inlineform28 and quality inlineform29 .the probability that an existing node inlineform30 receives a new link is inlineform31 , where the normalization factor inlineform32 is given by inlineform33 .the sum over all node degrees at time inlineform34 , which equals twice the number of links at time inlineform35 , is equal to inlineform36 .for long times , the sum over the quality values of all the nodes will converge to the mean of the quality distributiontimes the number of nodes, that is , we can replace inlineform37 by inlineform38 .so at time inlineform39 , the probability that node inlineform40 receives a link equals inlineform41 .throughout the present paper , the steady - state joint distribution of quality and degree is denoted by inlineform42 .the expected number of nodes with degree inlineform43 and quality inlineform44at time inlineform45 is denoted by inlineform46 .we denote by inlineform47 the expected number of inlineform48 - inlineform49 child - parent pairs .\n\ndegree-quality joint distribution: we seek the steady - state fraction of nodes who have degree inlineform50 and qualityinlineform51 .in appendix secref8 we derive the following expression for this quantity : displayform0note that in the special case of a single permitted value for the quality ( that is , when inlineform52 ) this model reduces to the shifted - linear preferential attachment model analyzed , for example , in   .the solution in this special case simplifies to displayform0  this coincides with the degree distribution of shifted - linear kernels given in   and   .furthermore , when inlineform53 , all nodes will have zero quality and attachments will be purely degree - proportional , synonymous with the conventional preferential - attachment model proposed initially in   .for the special case of inlineform54we obtain displayform0  this is equal to the degree distribution of the conventional ba network ( see , e.g. ,   ,   ) .let us also examine the behavior of ( eqref2 ) in the limit of large inlineform55 .in this regime , we can use the asymptotic approximation that for large values of inlineform56 , the functioninlineform57 .then we replace inlineform58 with inlineform59 , independent of inlineform60 .therefore , the steady - state joint degree - quality distribution inlineform61 is proportional to inlineform62 .marginalizing out inlineform63 to recover the degree distribution , we obtain the well - known power law , inlineform64 .\n\nnearest-neighbor quality-degree distribution: to quantify how qualities and degrees of adjacent nodes correlate , we need to go beyond the quality - degree distribution obtained in the previous section .the closed - form expression for the nearest - neigbor correlations under the preferential attachment model is derived in   ; that work only considers degrees and does not address qualities .we would like to quantify the conditional distribution inlineform65 , the fraction of neighbours of a given node with degree inlineform66 and quality inlineform67 that have degree inlineform68 and quality inlineform69 .we refer to this as the nearest - neighbor quality - degree distribution ( nnqdd ) .in appendix secref9 we study the rate equation describing how the distributioninlineform70 evolves as nodes are added to the network .this gives rise to a system of difference equations which we solve to obtain that , in the steady - state , displayform0in order to obtain the nearest - neighbor quality distribution inlineform71 , one needs to perform the calculations inlineform72 , which requires knowledge of inlineform73 .in turn we have inlineform74 , which according to ( eqref2 ) , yields different sums for different quality distributions inlineform75 .\n\nquantifying the friendship and generalized friendship paradoxes: as discussed in section secref1 , gfp refers to an average alter superiority in arbitrary aspects ( e.g. , number of citations , exposure to viral online content ) .in this paper , we use the ` quality ' dimension that is incorporated in the model as the subject of the gfp .our objective is to compare the degrees and qualities of nodes with their neighbors .we say that a node experiences the friendship paradox if the degree of that node is less than the average of the degrees of its neighbors .similarly , we say that a node experiences the quality paradox if the quality of the node is less than the average of the qualities of its neighbors .the above - mentioned definitions characterize individual - level paradoxes .our primary interest is to what fraction of nodes experience the friendship and quality paradoxes .to this end , we compare the average degree of the nodes with the average degree of the neighbors of all nodes ( and similarly for quality ) .comparing these two average values yields a macro measure for the system , indicating whether it exhibits paradoxes on average .we call these as the network - level friendship paradox and network - level quality paradox .our measure of the network - level quality paradox is defined as inlineform76 .the summations are performed over all nodes in the network .note that the numerator of the first sum is actually the sum of the qualities of the neighbors of all nodes .node inlineform77 is repeated inlineform78 times in this sum , once for each of its neighbors .focusing on the limit as inlineform79 , we can use the law of large numbers and express the nqp as follows displayform0  the greater nqp becomes , the more strongly the paradox holds .negative nqp is indicative of the absence of a quality paradox at the network level .undertaking similar steps to above , we can measure the network - level friendship paradox via displayform0note that the numerator is the variance of the degree distribution , so it is positive .the denominator is the average degree and is also positive .so the nfp is always positive , which means that by this definition : any network exhibits the friendship paradox at the network level .so the task of the present paper with regard to the nfp is to investigate its magnitude , i.e. , to measure how strongly the paradox holds .for example , in the conventional barabasi - albert scale - free model , where the degree variance diverges , the nfp also diverges , which is a result of the presence of macro hubs .\n\nresults and discussion : to study the nfp and the nqp in concrete settings , we confine ourselves to two quality distributions inlineform80 for illustrative purposes .we consider a finite support for inlineform81 , so thatinlineform82 .for each distribution , we are going to consider four different values inlineform83 , and four different values of inlineform84 .the first distribution we consider is the bernoulli case , where nodes can either have quality zero or quality inlineform85 .the probability of quality zero is inlineform86and the probability of quality inlineform87 is inlineform88 ,where inlineform89 .the second distribution we consider is the discrete exponential distribution with decay factor inlineform90 .the probability that the quality is inlineform91 is proportional to inlineform92 .note that in the case of inlineform93 , one recovers a uniform distribution as a special case .we consider both inlineform94 and inlineform95 , yielding decreasing and increasing distributions in inlineform96 , respectively .these distributions are depicted in figure figref8 .the results for the bernoulli quality distribution are depicted in figure figref11 .as depicted in figure figref11 , for a fixed inlineform97 , the nqp decreases as inlineform98 ( the initial degree of nodes ) increases .also , it is observable that the sensitivity of the nqp to the variations of the quality distribution diminishes for larger values of inlineform99 .as illustrated in figure figref11 , the nfp increases as inlineform100 ( the initial degree of nodes ) increases .hence , according to ( eqref7 )the variance of the degree distribution grows faster than the mean degree , as inlineform101 increases .on the other hand , for a given inlineform102 , increasing inlineform103 ( which is tantamount to increasing inlineform104 ) , increases the nqp .this means that according to ( eqref6 ) as inlineform105 increases , the mean of the qualities of the neighbors increases faster than the mean of the qualities of the nodes .figure figref11 pertains to this case .observe that as inlineform106 increases , the nqp becomes more sensitive to the distribution of qualities .finally , figure figref11 represents the nfp for a fixed inlineform107 and different values of inlineform108 .from figures figref11 , figref11 , figref11 and figref11 , a general observable pattern is that as inlineform109 increases , the nfp increases ( monotonically for almost all values of inlineform110 ) , whereas the nqp is concave and unimodal ( it increases at first , achieves maximum , and then decreases ) .now we focus on the exponential quality distribution with the decay factor denoted by inlineform111 .as depicted in figure figref16 , for a given inlineform112 , the nqp decreases as inlineform113 increases .also , it is observed that as inlineform114 increases , the sensitivity of the nqp to the quality distribution diminishes .these are both similar to the results of the bernoulli distribution .as can be seen in figure figref16 , the nfp increases as inlineform115 increases .so similar to the bernoulli case , the variance of the degree distribution grows faster than the mean degree , as inlineform116 increases .from figure figref16 we observe that for a fixed inlineform117 , increasing inlineform118 increases the nqp .we observe that as inlineform119 increases , nqp becomes more sensitive to the changes in the decay factor .finally , figure figref16 represents the nfp for a fixed inlineform120 and different values of inlineform121 .we observe that increasing inlineform122 increases the nfp for positive decays .also , for very small decay factors ( which generate right - skewed distributions that are highly unequal ) , changing inlineform123 has scant effect on the nfp .this is reasonable because when the decay factor is small , all large values of inlineform124 have small chances of occurrence .consequently , changing inlineform125 minimally changes the shape of the distribution for small decay factors .a trend is discernible from figures figref16 , figref16 , figref16 and figref16 : as inlineform126 increases , the nfp decreases ( monotonically for all values of inlineform127 ) , whereas nqp is concave and increases up to a point around inlineform128 , and then decreases .since inlineform129 yields a uniform distribution , we can qualitatively conclude that the probability of the network - level quality paradox is higher when qualities are heterogeneous , as compared to when qualities are similar .finally , to verify our results , we run monte carlo simulations to synthesize networks that grow under the prescribed quality - based preferential attachment mechanism , and then calculate the desired quantities by averaging over nodes in the synthesized network .due to computational limitations , we restrict this validation to the case where inlineform130 and inlineform131 for the bernoulli quality distribution and the case where inlineform132 and inlineform133 for the exponential quality distribution .these results are shown in figures figref11 , figref11 , figref16 and figref16 .the markers show the results of simulations , averaging over 100 monte carlo trials , and the solid curves correspond to our theoretical expressions .we have tested the results on various other quality distributions and observed similar results ; these additional simulations not reported here due to space limitations .in general , we observe that for a fixed inlineform134 , increasinginlineform135 increases the nfp and decreases the nqp regardless of the quality distribution .also , for a fixed inlineform136 , increasing inlineform137 increases the nqp and decreases the nfp .note that in all cases the nqp is nonnegative .this has roots in the correlation between degree and quality of single nodes ( intra - node correlation , rather than inter - node correlation ) .let us denote the correlation between degree and quality for a node by inlineform138 , which is the pearson correlation coefficient obtained from the joint distributioninlineform139 .from ( eqref6 ) , we have : displayform0this implies that the sign of nqp is the same as the sign of inlineform140 ( since inlineform141 and inlineform142 are nonnegative ) .the observation that nqp is always nonegativeindicates that inlineform143 is also always nonegative .we conclude that the quality - dependent preferential attachment model generates networks in which degree and quality of a node are always positively correlated .this is what we intuitively expect the model to exhibit ; increasing quality increases degree .for example , in citation networks , papers with higher qualities receive more citations .conversely , a paper with many citations is more likely to have a high quality .in the case of friendship networks , a person that is more sociable ends up with more friends than an anti - social person , and conversely , a popular person is more likely to be friendly than an isolated person .we also observe that in all cases , inlineform144 ( equivalently , inlineform145 ) and inlineform146 have opposite effects on both the nfp and the nqp .that is , the effect of increasing inlineform147 is akin to that of decreasing inlineform148 , and vice versa .we observed similar trends for other quality distributions ; these results are omitted here due to space limitations .what causes this disparity is the following : as can be seen in ( eqref2 ) and ( eqref5 ) , inlineform149 only appears in the distributions in the form of inlineform150 .thus increasing inlineform151 and decreasing inlineform152 have the same effect on this variable , and consequently , on the distribution .\n\nsummary and future work: the aim of the present paper was to put in crisp theoretical focus the seemingly prevalent phenomena of the friendship paradox and the generalized friendship paradox .we proposed a network growth model that incorporates quality .in this model , the probability that a node receives a link increases with both its degree and quality .we analysed the model theoretically in the steady - state ( large size limit ) , and found two theoretical quantities that characterize the interrelation between quality and degree .the first quantity is inlineform153 , which is the joint degree - quality distribution , and equals the fraction of nodes who have degree inlineform154 and quality inlineform155 .the second quantity characterizes nearest - neighbor correlations , and is the nearest - neighbor quality - degree distribution , denoted by inlineform156 .we then defined two network - level measures for the quality and friendship paradoxes and computed them for two particular examples of quality distributions .we observed that for a fixed inlineform157 , increasing inlineform158 increases the nfp and decreases the nqp regardless of the quality distribution .we also observed that for a fixed inlineform159 , increasing inlineform160 increases the nqp and decreases the nfp .we also observed that inlineform161 and inlineform162 have opposite effects on the nfp and also on the nqp .we also tested these results on various other quality distributions , and they proved robust ; the effects of inlineform163 and inlineform164 on paradoxes are opposite regardless of the quality distribution .there are many interesting extensions of this work to pursue .in addition to the network - level paradox , we can also study the individual - level paradox , which would require the utilization of the nnqdd to compare the degrees and qualities of nodes with those of their neighbors .the individual - level paradox has empirical implications which enable us to assess the quality distribution of real networks .\n\nobtaining the joint distribution p(k,\u03b8)p(k,\\theta ): we seek the fraction of nodes who have degree inlineform165 and have quality inlineform166 .we begin by writing the rate equation which quantifies the temporal evolution of inlineform167 .suppose that a node with quality inlineform168 and degreeinlineform169at time inlineform170 , receives a link from the new incoming node .consequently , its degree will become inlineform171 and inlineform172 increments .conversely , if a node with quality inlineform173 and degree inlineform174 at time inlineform175 , receives a link from the new incoming node , inlineform176 decrements .finally , each new incoming node increments inlineform177 with probability inlineform178 .the rate equation thus reads displayform0replacing inlineform179 by inlineform180 , this can be expressed in terms of inlineform181 as follows :displayform0  in the limit as inlineform182 , the transients vanish .so , we drop the inlineform183 in the arguments and rewrite ( eqref23 ) as : displayform0  this can be rearranged and expressed equivalently as follows : displayform0  multiplying both sides by inlineform184 and rearranging the terms , this can be recast as follows displayform0  setting inlineform185 ,this yields inlineform186 .for all inlineform187 , the second term on the right hand side vanishes , and this equation reduces to a straightforward recursion inlineform188 , whose solution is displayform0\n\nobtaining the conditional distribution p(\u2113,\u03c6|k,\u03b8)p(\\ell ,\\phi |k,\\theta ): we begin by writing the rate equation to quantify the evolution of inlineform189 , which is the number of nodes with degree inlineform190 and quality inlineform191 who are connected to a parent node of degree inlineform192 and qualityinlineform193 .upon introduction of a new node , regardless of its quality , the following is true : if it attaches to a node of degree inlineform194 and quality inlineform195 who is the child of a parent of degree inlineform196 and quality inlineform197 , then the degree of the receiving node increments and consequently inlineform198 decrements .also , inlineform199 decrements if the new node attaches to the parent node in such a pair of nodes .another way that inlineform200 can increment is if either there is a child - parent pair of inlineform201 orinlineform202 .if the new node attaches to the child node in the former case or to the parent node in the latter case , then inlineform203 increments .finally , with probability inlineform204 , the new node will have quality inlineform205 , and if the new node attaches to an existing node of degree inlineform206 and qualityinlineform207 , theninlineform208 increments .the rate equation reads displayform0undertaking the same steps that let us transform ( eqref22 ) into ( eqref23 ) , and denoting the fraction inlineform209 by inlineform210 , this can be re - written in terms of inlineform211 instead ofinlineform212 .in the limit as inlineform213 , we can drop the inlineform214 subscript and obtain :displayform0let us define the new sequenceinlineform215 .using this substitution and applying the properties of the gamma function as well as the delta function , we can rewrite ( eqref29 ) equivalently as displayform0  using the expression in ( eqref2 ) to rewrite the last term on the right hand side of this equation , we can express it equivalently as follows displayform0  now define the generating functioninlineform216 .multiplying both sides of ( eqref30 ) by inlineform217 , summing over all values of inlineform218 and rearranging the terms , we arrive at displayform0  ( the lower bound of the sum is inlineform219 because inlineform220 is zero for inlineform221 . )the inverse transform of the factor inlineform222 in the summand can be taken through the following steps : displayform0  so we can invert ( eqref32 ) term by term .we get displayform0  from this , we readily obtain displayform0the last step is to abridge this quantity and the desired nnqdd distribution , that is , inlineform223 .remember that the nnqdd is the fraction of inlineform224 nodes among the neighbors of a inlineform225 node .to obtain this fraction , we first need to obtain the total number of neighbors of inlineform226 nodes , then find the number of inlineform227 nodes among these nodes , and divide the latter by the former .the total number of neighbors ofinlineform228nodes is simply inlineform229 .the number of inlineform230 nodes among them equals inlineform231 , because the inlineform232 node can both be the parent or the child of the a inlineform233 node to be connected to it .so we have inlineform234 .inserting the results of ( eqref35 ) and ( eqref2 ) into this expression and simplifying the results , we obtain displayform0",
      "target_text": "the friendship paradox refers to the sociological observation that , while the people 's assessment of their own popularity is typically self - aggrandizing , in reality they are less popular than their friends .the generalized friendship paradox is the average alter superiority observed empirically in social settings , scientific collaboration networks , as well as online social media .we posit a quality - based network growth model in which the chance for a node to receive new links depends both on its degree and a quality parameter .nodes are assigned qualities the first time they join the network , and these do not change over time .we analyse the model theoretically , finding expressions for the joint degree - quality distribution and nearest - neighbor distribution .we then demonstrate that this model exhibits both the friendship paradox and the generalized friendship paradox at the network level , regardless of the distribution of qualities .we also show that , in the proposed model , the degree and quality of each node are positively correlated regardless of how node qualities are distributed .",
      "output_text": "format11 .in particular , we find that the gfp depends on both the degree distribution and the quality distribution   .conclusion: in conclusion , we have presented a statistical model for the growth of scientific collaborations networks   .we have shown that this model can be used to quantify and study the generalized friend - ship paradoxes   .furthermore , this model has implications for the design and analysis of collaborative filtering algorithms   .\n\nkeywords: scientific collaboration, social network analysis, generalization, fitness, attractiveness, degree distribution, quality distribution, gfp\n\nreferences:\n\nfeld, s. (1996). Friendship and the social brain. Science, 272(5260), 1299-1302.\nfelds, s., & hofstede, g. J. (2001). Culture's consequences: Comparing values, behaviors, institutions, and organizations across nations (2nd ed.). Thousand oaks, ca: Sage.\nfiedler, l. E., & kelly, j. M. (Eds.). (in press). Social network analysis: Methods and applications (Vol. 2). New york: John wiley & sons, inc.\nkleinberg, m. J., & barab\u00e1si, a. L. R. (In press). The dynamics of complex networks. Annual review of physics, 67(1), 417-454."
    },
    {
      "input_text": "Title: Universe consisting of diffusive dark fluids: thermodynamics and stability analysis\nDomains: Physics\n\nintroduction: the greatest challenge of standard cosmology today is to accommodate the recent observational predictions   .the modern cosmology is facing the challenging issue of explaining the present accelerated expansion of the universe .in the framework of einstein gravity , cosmologists are speculating some hypothetical exotic matter ( known as dark energy ( de ) having large negative pressure ) to explain this accelerating phase .it is estimated  that about 70 percent of the cosmic fluid consists of this unknown de component .the simplest as well as the common candidate for this dark fluid is the cosmological constant ( the zero point energy of the quantum fields ) .although a large number of available observational data are in support of this cosmological parameter as a de candidate but there are severe drawback of it at the interface of cosmology and particle physics :the cosmological constant problem   ,   and the coincidence problem   .as a result there are several alternative proposed dynamical de models into the picture .these de models have been studied for the last several years   , yet the cosmological constant is still the best observationally supported de candidate .however , these different dynamic de models can not be compared from observational view point as these models try to adjust the data seamlessly .as a result , cosmologists have been trying with interacting de model to have a better understanding of the mechanism of this cosmic acceleration .from recent past , interacting dark fluid models have been receiving much attention as they can provide small value of the cosmological constant and due to their ability of explaining the cosmic coincidence problem   .moreover , recent observed data   favor interacting dark fluid modelsand it is possible to have an estimate of the coupling parameter in the interaction term by various observations   .further , the cosmologists are of the opinion that these interacting dark fluid models may have the solution to the current tensions on inlineform0 and the local value of the hubble constant inlineform1   .moreover , it is speculated that cosmological perturbation analysis may be affected by the interaction terms and consequently , the lowest multipoles of the cmb spectrum   ,   should have an imprint of it .on the other hand , the unknown nature of de may have some clue from the thermodynamic laws which are applicable to all types of macroscopic systems and are based on experimental evidence .however , unlike classical mechanics or electromagnetism , thermodynamical analysis can not predict any definite value for observables , it may only give limit on physical processes .so it is reasonable to believe that thermodynamical study of dark cosmic fluid may indicate some unknown character of it .investigation in this direction has been initiated recently by barbozaetal   .but their stability conditions demand that the de should have constant ( -ve ) equation of state and it is not supported by observation .subsequently , chakraborty and collaborators   in a series of works have shown the stability criteria for different type of dark fluids and have presented the stability conditions ( in tabular form ) for different ranges of the equation of state parameter .the present work is an extension of the interacting dark fluid model .here a particular realization of the non - conservation of the energy momentum tensor is used with a diffusion of dark matter in a fluid of dark energy .the change of the energy - density is proportional to the particle density .the resulting non - equilibrium thermodynamics is studied and stability conditions are explicitly determined .the paper is organized as follows : section secref3 deals with thermodynamical analysis of non - interacting cosmic fluids with constant equation of state .the stability criteria for non - interacting cosmic fluids with variable equation of state has been organized in section secref4 .finally , the paper ends with a brief discussion and the conclusion from the result in dark energy range in section secref5 .\n\nthermodynamic analysis of non-interacting diffusive cosmic fluids having constant equation of state parameter: the universe is assumed to have different types of non - interacting cosmic fluids ( including dark energy and dark matter ) .here it will be examined whether all kinds of diffusive fluids are thermodynamically stable or not in an adiabatic universe .let the equation of state of these cosmic fluids are barotropic in nature having explicit form ( for i - th fluid )displayform0where inlineform2 , a constant , is the barotropic index of the fluid and inlineform3 and inlineform4 are the pressure and energy density of the fluid respectively .so the friedmann equations for the whole system take the form displayform0where inlineform5 is the hubble parameter , inlineform6 is called the scale factor of the universe as all physical distance is scaled with same factor \u201c inlineform7 \" due to homogeneity and isotropy of space - time .now due to the diffusive nature of the fluids , they do not obey the matter conservation equation ( inlineform8 ) , rather they follow , displayform0where inlineform9 is the current of diffusion corresponding to that fluid and inlineform10 is a constant .but for the whole universe , the total stress - energy tensor is conserved i.e. ( inlineform11 )displayform0in simplest form , the conservation equation(non conservation ) takes the form for flrw universe  as , displayform0where , inlineform12 is a constant for a particular fluidbut it is different for different fluids with inlineform13 .now , in the context of classical thermodynamics , the contribution to the energy of the universe by i - th fluid is given by displayform0where , inlineform14 is the physical volume of universe at given time inlineform15and at present time inlineform16 , the physical volume is inlineform17 with inlineform18 .according to the 1st law of thermodynamics(which is an energy conservation equation ) , displayform0integrating equation ( eqref8 )one can easily find the expression for energy density of the i - th fluid as , displayform0where inlineform19 is the value of inlineform20 at inlineform21 i.e. at the present time .theenergy density of i - th fluid , from equation ( eqref11 ) can be arranged as displayform0where inlineform22 .now , taking entropy inlineform23 as a function of two independent thermodynamic variables namely volume ( inlineform24 ) and temperature ( inlineform25 ) and also considering inlineform26 to be an exact differential , one obtains from equation ( eqref10 ) , displayform0now combining equations ( eqref12 ) and ( eqref13 ) , a new relation among energy density , temperature and time can be written as displayform0where inlineform27 is an integration constant .effectively at present time inlineform28 , displayform0now equations ( eqref14 ) and ( eqref15 ) imply the evolution of energy of the i - th fluid with time and temperature as , displayform0this can be termed as the modified equation of state of this fluid where as before inlineform29 and inlineform30 .\n\n determination of thermodynamic derivatives : c p ,c v ,k s ,k t c_p,c_v,k_s,k_t : now , the motivation of the present work is to find the criteria of thermodynamic stability of the universe .so the conditions which may be satisfied by the parameters , indicate the thermodynamic features of the evolution of the expanding universe .for any system the thermodynamic derivatives i.e. the heat capacities , compressibility and isobaric expansibility determine whether the system is stable or not .so it will be very important to analyze these parameters for each fluid in the present context .from the 1st law of thermodynamics in equation ( eqref10 ) , one can determine the two heat capacities : heat capacity at constant volume inlineform31 and heat capacity at constant pressure inlineform32 by the relations , displayform0where inlineform33 , is called the enthalpy of the system .now the relation between temperature of a system at a constant volume inlineform34 and the physical equilibrium temperature is given by ( according to  ) displayform0the temperature at a constant volume inlineform35 also evolves as displayform0so from equations ( eqref19 ) and ( eqref20 ) , displayform0now from equations ( eqref18 ) and ( eqref21 ) one obtains , displayform0and equations ( eqref4 ) , ( ) and ( eqref21 ) yield ( using the definition of enthalpy )displayform0also equation ( eqref23 ) can be rewritten ( using eqref19 ) as displayform0further assuming temperature and pressure as independent thermodynamic variables , the variation of volume can be expressed as ( see ref .  and   ) displayform0where displayform0is familiar as thermal expansibility .the isothermal compressibility inlineform36 is given by displayform0similarly the adiabatic compressibility is displayform0in isothermal process , displayform0also one has the well established relation amongst heat capacities and compressibilities as   displayform0so one can find the expression for isothermal expansibility inlineform37 from equation ( eqref13 ) as , displayform0now equations ( eqref29 ) and ( eqref30 ) yield displayform0hence one obtains the expressions for compressibilities from equations ( eqref31 ) , ( eqref32 ) and ( )containing the dependence of diffusion parameter inlineform38 as , displayform0\n\nstability conditions for cosmic fluids :: for thermodynamic stability of any fluid , it must follow the conditions   ,   namely inlineform39 .for the present work , using the expressions of these thermodynamical parameters , the stability conditions are presented in the following table tabref35 :\n\nstability criteria with variable equation of state parameter: so far we have examined the conditions for stability of cosmic fluids with constant equation of state parameters .in the present section the stability conditions will be discussed for cosmic fluids having variable equation of state parameters .the fluids are diffusive as before with no interaction amongst them .in such context , the solution of the conservation equation ( eqref8 ) yields , displayform0where , displayform0taking inlineform40one can write equation ( eqref37 ) as displayform0\n\nderivation of the relation between physical equilibrium temperature (t) and temperature at constant volume (t a )(t_a):: from 1st law of thermodynamics ( i.e. equation ( eqref10 ) ) , by choosing entropy ( s ) as a function of two independent variables volume ( v ) and temperature ( t ) , the condition for ds to be an exact differential gives displayform0now , from equation ( ) one obtains the energy density as a function of temperature as displayform0again , combining equations ( ) and ( eqref42 )the expression for entropy can be written as , displayform0now , as for an adiabatic system inlineform41 , so one can determine from equation ( eqref43 ) , the relation between inlineform42 and inlineform43 ( i.e. evolution of inlineform44 ) as displayform0now combining equations ( eqref38 ) , ( eqref39 ) and ( eqref44 ) one obtains , displayform0or equivalently displayform0  inlineform45 .now as the adiabatic contribution of entropy for the i - th fluid ( excluding the diffusive entropy inlineform46 namely , displayform0does not vary ( i.e. inlineform47 ) , so temperature can be written as , displayform0where , inlineform48 is a constant .now combining ( eqref47 ) and ( eqref48 ) yields displayform0with inlineform49 , a constant .\n\nthermodynamic derivatives : similar to the above section , one can determine the heat capacities and compressibilities of the present thermodynamical system as follows : now the solution of equation ( eqref8 ) , ( or equivalently equation ( eqref37 ) ) can be expressed as displayform0again from equation ( ) , one finds displayform0combining the above equations ( eqref51 ) and ( eqref52 ) one can write , displayform0now imposing the initial conditions , one can formulate the modified equation of state in terms of evolution of energy with time and temperature as displayform0the above equation ( eqref54 ) can be written according to equation ( eqref49 ) as displayform0so using equations ( eqref18 ) , ( ) , ( eqref49 ) and ( eqref54 ) , one can easily express the heat capacities as displayform0and hence one obtains the relation displayform0again equations ( eqref51 ) and ( eqref52 ) yield displayform0which implies along with equation ( eqref49 ) that displayform0so from equations ( eqref29 ) , ( eqref56 ) , ( eqref57 ) and ( eqref59 )one writes displayform0and from ( eqref30 ) , one obtains displayform0now , using equation ( eqref58 ) the expression for inlineform50 takes the form displayform0and the expressions for inlineform51 and inlineform52 are given by ( using equations ( eqref60 ) , ( eqref61 ) and ( eqref62 ) ) displayform0now according to the conditions of thermodynamic stability , we analyze the equations ( eqref56 ) , ( ) , ( eqref63 )and ( ) to find the restrictions of thermodynamic stability in different ranges of inlineform53 in the following table tabref64 .\n\nbrief discussions: a detailed thermodynamic study of non - interacting cosmic fluids having diffusive nature has been organized in the present work .as a result , individual fluid does not obey the energy conservation relation ,rather the non - conservation is proportional to the corresponding diffusive current .each component of the cosmic fluids is assumed to have barotropic equation of state with constant or variable equation of state parameter .the stability conditions are expressed in the form of inequalities for different ranges of equation of state parameter .also , the stability conditions for both constant ( table tabref35 ) and variable ( table tabref64 ) equation of state parameter in the range inlineform54 ( i.e. for dark energy region ) have been presented graphically in figure figref36 and figref65 respectively .from figure figref65 , different restrictions on diffusion parameter inlineform55 are found depending on whether the values of inlineform56 ( i.e. relative variation of inlineform57 with respect to the temperature t ) belong to region -i or region - ii .however due to expanding nature of the universe , the isobaric expansibility ( inlineform58 ) should always be positive .this condition restricts the function inlineform59only in region - ii , which is acceptable for expanding universe ( table tabref66 ) .further , it is interesting to note that , for constant equation of state parameter , ( i.e. table tabref35 ) , the system can not be thermodynamically stable for inlineform60 .this result is very much similar to that of   .however , the present work is thermodynamically stable in phantom region in contrary with non - diffusive cosmic fluids   .finally , it is found that diffusive fluid with variable equation of state parameter is thermodynamically stable for all possible values of inlineform61 under some restrictions on the diffusion parameter inlineform62 and nature of variation of inlineform63 with respect to temperature .\n\nacknowledgement: the authors are thankful to iucaa , pune , india for research facilities at library .the author sm acknowledges ugc - jrf and pb acknowledges dst - inspire ( fileno : if160086 ) for awarding research fellowship .also sc acknowledges the ugc - drs program in the department of mathematics , jadavpur university ..",
      "target_text": "the present work deals with homogeneous and isotropic flrw model of the universe having a system of non - interacting diffusive cosmic fluids with barotropic equation of state ( constant or variable equation of state parameter ) .due to diffusive nature of the cosmic fluids , the divergence of the energy momentum tensor is chosen to be proportional to the diffusive current .the thermodynamic stability analysis of individual fluids is done and the stability conditions are expressed as restrictions on the equation of state parameter .",
      "output_text": "odynamic point of view   .in this article , we will study the thermo-dynamics of universe consisting of diffuse dark fluid   .\n\nmethods: we will use the first order perturbation theory to study the dynamics of this universe   .we will also study the stability of this model by using the Lyapunov stability theory   .first order perturbations will be considered in this study   .this perturbation approach will be used to understand the behavior of the dark fluid and its interaction with the background cosmological fluid.the stability analysis will be done by using Lyapounov stability theorem   .it will be shown that this model is stable in the long wavelength limit and it will be found that there is no instability in this model   .conclusion: the interacting dynamical dark fluid model is a promising candidate to explain the current cosmic accelerated phase   .its stability analysis shows that it is a stable model and it can explain the observed cosmological data   .therefore , this model can be considered as a viable alternative to the standard cosmological model.furthermore , it can be used as a tool to investigate the nature of dark matter and dark energy   .keywords: cosmology, dark energy, dark fluid, interacting fluid, cosmological coincidence, cosmic microwave background radiation, perturbation, stability analysis."
    },
    {
      "input_text": "Title: Pixel-Level Domain Transfer\nDomains: Computer science\n\nintroduction: every morning , we agonize in front of the closet over what to wear , how to dress up , and imagine ourselves with different clothes on .to generate mental images   of ourselves wearing clothes on a hanger is an effortless work for our brain .in our daily lives , we ceaselessly perceive visual scene or objects , and often transfer them to different forms by the mental imagery .our focus of this paper lies on the problem ; to enable a machine to transfer a visual input into different forms and to visualize the various forms by generating a pixel - level image .image generation has been attempted by a long line of works   but generating realistic images has been challenging since an image itself is high dimensional and has complex relations between pixels .however , several recent works have succeeded in generating realistic images with the drastic advances of deep learning .although these works are similar to ours in terms of image generation , ours is distinct in terms of image - conditioned image generation .we take an image as a conditioned input lying in a domain , and re - draw a target image lying on another .in this work , we define two domains ; a source domain and a target domain .the two domains are connected by a semantic meaning .for instance , if we define an image of a dressed person as a source domain , a piece of the person 's clothing is defined as the target domain .transferring an image domain into a different image domain has been proposed in computer vision but all these adaptations take place in the feature space , i.e. the model parameters are adapted .however , our method directly produces target images .we transfer a knowledge in a source domain to a pixel - level target image while overcoming the semantic gap between the two domains .transferred image should look realistic yet preserving the semantic meaning .to do so , we present a pixel - level domain converter composed of an encoder for semantic embedding of a source and a decoder to produce a target image .however , training the converter is not straightforward because the target is not deterministic   .given a source image , the number of possible targets is unlimited as the examples in fig .figref1 show .to challenge this problem , we introduce two strategies as follows .to train our converter , we first place a separate network named domain discriminator on top of the converter .the domain discriminator takes a pair of a source image and a target image , and is trained to make a binary decision whether the input pair is associated or not .the domain discriminator then supervises the converter to produce associated images .both of the networks are jointly optimized by the adversarial training method , which goodfellow et al .  propose for generating realistic images .such binary supervision solves the problem of non - deterministic property of the target domain and enables us to train the semantic relation between the domains .secondly , in addition to the domain discriminator , we also employ the discriminator of   , which is supervised by the labels of \u201c real \u201d or \u201c fake \u201d , to produce realistic images .our framework deals with the three networks that play distinct roles .labels are given to the two discriminators , and they supervise the converter to produce images that are realistic yet keeping the semantic meaning .those two discriminators become unnecessary after the training stage and the converter is our ultimate goal .we verify our method by quite challenging settings ; the source domain is a natural human image and the target domain is a product image of the person 's top .to do so , we have made a large dataset named lookbook , which contains in total of 84k images , where 75khuman images are associated with 10k top product images .with this dataset , our model succeeds in generating decent target images , and the evaluation result verifies the effectiveness of our domain discriminator to train the converter .\n\nrelated work: our work is highly related with the image - generative models since our final result from an input image is also an image .the image - generative models can be grouped into two families ; generative parametric approaches   and adversarial approaches   .the generative parametric approaches often have troubles in training complexities , which results in a low rate of success in generating realistic natural images .the adversarial approaches originate from generative adversarial nets ( gan ) proposed by goodfellow et al .   .gan framework introduces a generator ( i.e. a decoder ) , which generates images , and a discriminator , which distinguishes between generated samples and real images .the two networks are optimized to go against each other ; the discriminator is trained to distinguish between real and fake samples while the generator is trained to confuse the discriminator .mirza and osindero   extend gan to a class conditional version , and denton et al .  improve the image resolution in a coarse - to - fine fashion .however , gan is known to be unstable due to the adversarial training , often resulting in incomprehensible or noisy images .quite recently , radford et al .  have proposed architectures named deep convolutional gans , which is relatively more stable to be trained , and have succeeded in generating high quality images .as approaches focusing on different network architectures , a recurrent network based model   and a deconvolutional network based model   have also been proposed .the recent improvements of gan framework and its successful results motivate us to adopt the networks .we replace the generator with our converter which is an image - conditioned model , while   is class - conditional and   is attribute - conditional .the generator of mathieu et al .  is similar to ours in that it is conditioned with video frames to produce next frames .they add a mean square loss to the generator to strongly relate the input frames to the next frames .however , we can not use such loss due to the non - deterministic property of the target domain .we therefore introduce a novel discriminator named domain discriminator .our work is also related with the transfer learning , also called as the domain adaptation .this aims to transfer the model parameter trained on a source domain to a different domain .for visual recognition , many methods to adapt domains   have been proposed .especially for the recent use of the deep convolutional neural network   , it has been common to pre - train a large network   over imagenet   and transfer the parameters to a target domain   .similar to our clothing domains , chen et al .  and huang et al .  address a gap between fashion shopping mall images and unconstrained human images for the clothing attribute recognition   and the product retrieval   .ganin and lempitsky   also learns domain - invariant features by the adversarial training method .however , all these methods are different from ours in respect of cross - domain image generation .the adaptation of these works takes place in the feature space , while we directly produce target images from the source images .\n\nreview of generative adversarial nets: generative adversarial nets ( gan )   is a generalized framework for generative models which  and we utilize for visual data .in this section , we briefly review gan in the context of image data .gan is formed by an adversarial setting of two networks ; a generator and a discriminator .the eventual goal of the generator is to map a small dimensional space inlineform0 to a pixel - level image space , i.e. , to enable the generator to produce a realistic image from an input random vector inlineform1 .to train such a generator , a discriminator is introduced .the discriminator takes either a real image or a fake image drawn by the generator , and distinguishes whether its input is real or fake .the training procedure can be intuitively described as follows .given an initialized generator inlineform2 , an initial discriminator inlineform3 is firstly trained with real training images inlineform4 and fake imagesinlineform5 drawn by the generator .after that , we freeze the updated discriminator inlineform6 and train the generator inlineform7 to produce better images , which would lead the discriminator inlineform8 to misjudge as real images .these two procedures are repeated until they converge .the objective function can be represented as a minimax objective as , displayform0where inlineform9 and inlineform10 indicate the model parameters of the generator and the discriminator respectively .here , the discriminator produces a scalar probability that is high when the input inlineform11 is real but otherwise low .the discriminator loss function inlineform12 is defined as the binary cross entropy , displayform0one interesting fact in the gan framework is that the model is trained under the lowest level of supervision ; real or fake .without strong and fine supervisions( e.g. mean square error between images ) , this framework succeeds in generating realistic images .this motivates us to raise the following question .under such a low - level supervision , would it be possible to train a connection between distinct image domains ?if so , could we transform an image lying in a domain to a realistic image lying on another ?through this study , we have succeeded in doing so , and the method is to be presented in sec .secref4 .\n\npixel-level domain transfer: in this section , we introduce the pixel - level domain transfer problem .let us define a source image domain inlineform13 and a target image domain inlineform14 .given a transfer function named a converter inlineform15 , our task is to transfer a source image inlineform16 to a target image inlineform17 such as displayform0where inlineform18 is the model parameter of the converter .note that the inference inlineform19 is not a feature vector but itself a target image of inlineform20 size .to do so , we employ a convolutional network model for the converter inlineform21 , and adopt a supervised learning to optimize the model parameter inlineform22 .in the training data , each source image inlineform23 should be associated with a ground - truth target image inlineform24 .\n\nconverter network: our target output is a pixel - level image .furthermore , the two domains are connected by a semantic meaning .pixel - level generation itself is challenging but the semantic transfer makes the problem even more difficult .a converter should selectively summarize the semantic attributes from a source image and then produce a transformed pixel - level image .the top network in fig .figref10 shows the architecture of the converter we propose .the converter is a unified network that is end - to - end trainablebut we can divide it into the two parts ; an encoder and a decoder .the encoder part is composed of five convolutional layers to abstract the source into a semantic 64-dimensional code .this abstraction procedure is significant since our source domain ( e.g. natural fashion image ) and target domain ( e.g. product image ) are paired in a semantic content ( e.g. the product ) .the 64-dimensional code should capture the semantic attributes ( e.g. category , color , etc . )of a source to be well decoded into a target .the code is then fed by the decoder , which constructs a relevant target through the five decoding layers .each decoding layer conducts the fractional - strided convolutions , where the convolution operates in the opposite direction .the reader is referred to table tabref11 for more details about the architectures of the encoder and the decoder .\n\ndiscriminator networks: given the converter , a simple choice of a loss function to train it is the mean - square error ( mse ) such as inlineform25 .however , mse may not be a proper choice due to critical mismatches between mse and our problem .firstly , mse is not suitable for pixel - level supervision for natural images .it has been well known that mse is prone to produce blurry images because it inherently assumes that the pixels are drawn from gaussian distribution   .pixels in natural images are actually drawn from complex multi - modal distributions .besides its intrinsic limitation , it causes another critical problem especially for the pixel - level domain transfer as follows .given a source image , the target is actually not unique in our problem .our target domain is the lowest pixel - level image space , not the high - level semantic feature space .thus , the number of possible targets from a source is infinite .fig .figref1is a typical example showing that the target is not unique .the clothing in the target domain is captured in various shapes , and all of the targets are true .besides the shapes , the target image can be captured from various viewpoints , which results in geometric transformations .however , minimizing mse always forces the converter to fit into one of them .image - to - image training with mse never allows a small geometric miss - alignment as well as various shapes .thus , training the converter with mse is not a proper use for this problem .it would be better to introduce a new loss function which is tolerant to the diversity of the pixel - level target domain .in this paper , on top of the converter , we place a discriminator network which plays a role as a loss function .as in the discriminator network guides the converter to produce realistic target under the supervision of real / fake .however , this is not the only role that our discriminator plays .if we simply use the original discriminator replacing mse , a produced target could look realistic but its contents may not be relevant to the source .this is because there is no pairwise supervision such as mse .only real / fake supervision exists .given arbitrary image triplets ( inlineform26 ) in the source domain inlineform27 , where inlineform28 and inlineform29 are about the same object while inlineform30 is not , a converter transfers them into the images ( inlineform31 ) in the target domain inlineform32 .let us assume that these transferred images look realistic due to the real / fake discriminator .beyond the realistic results , the best converter inlineform33 should satisfy the following condition , displayform0where inlineform34 ( inlineform35 ) is a semantic similarity function .this condition means that an estimated target should be semantically associated with the source .one supervision candidate to let the converter inlineform36 meet the condition is the combined use of mse with the real / fake loss .however , again , it is not the best option for our problem because the ground - truth inlineform37 is not unique .thus , we propose a novel discriminator , named domain discriminator , to take the pairwise supervision into consideration .the domain discriminator inlineform38 is the lowest network illustrated in fig .figref10 .to enable pairwise supervision while being tolerant to the target diversity , we significantly loosen the level of supervision compared to mse .the network inlineform39 takes a pair of source and target as input , and produces a scalar probability of whether the input pair is associated or not .let us assume that we have a source inlineform40 , its ground truth target inlineform41 and an irrelevant target inlineform42 .we also have an inference inlineform43 from the converter inlineform44 .we then define the loss inlineform45 of the domain discriminator inlineform46 as , displayform0the source inlineform47 is always fed by the network as one of the input pair while the other inlineform48 is chosen among ( inlineform49 , inlineform50 , inlineform51 ) with equal probability .only when the source inlineform52 and its ground - truth inlineform53 is paired as input , the domain discriminator is trained to produce high probability whereas it minimizes the probability in other cases .here , let us pay more attention to the input case of ( inlineform54 , inlineform55 ) .the produced target inlineform56 comes from the sourcebut we regard it as an unassociated pair ( inlineform57 =0 )when we train the domain discriminator .our intention of doing so is for adversarial training of the converter and the domain discriminator .the domain discriminator loss is minimized for training the domain discriminator while it is maximized for training the converter .the better the domain discriminator distinguishes a ground - truth inlineform58 and an inference inlineform59 , the better the converter transfers the source into a relevant target .in summary , we employ both of the real / fake discriminator and the domain discriminator for adversarial training .these two networks play a role as a loss to optimize the converter , but have different objectives .the real / fake discriminator penalizes an unrealistic target while the domain discriminator penalizes a target being irrelevant to a source .the architecture of the real / fake discriminator is identical to that of   as illustrated in fig .figref10 .the domain discriminator also has the same architecture except for the input filter size since our input pair is stacked across the channel axis .several architecture families have been proposed to feed a pair of images to compare them but a simple stack across the channel axis has shown the best performance as studied in   .the reader is referred to table tabref11 for more details about the discriminator architectures .\n\nadversarial training: in this section , we present the method for training the converter inlineform60 , the real / fake discriminator inlineform61 and the domain discriminator inlineform62 .because we have the two discriminators , the two loss functions have been defined .the real / fake discriminator loss inlineform63 is eq .( eqref7 ) , and the domain discriminator loss inlineform64 is eq .( eqref14 ) .with the two loss functions , we follow the adversarial training procedure of   .given a paired image set for training , let us assume that we get a source batch inlineform65 and a target batch inlineform66 where a target sample inlineform67 is stochastically chosen from inlineform68 with an equal probability .at first , we train the discriminators .we train the real / fake discriminator inlineform69 with the target batch to reduce the loss of eq .( eqref7 ) .the domain discriminator inlineform70 is trained with both of source and target batches to reduce the loss of eq .( eqref14 ) .after that , we freeze the updated discriminator parameters inlineform71 , and optimize the converter parameters inlineform72 to increase the losses of both discriminators .the loss function of the converter can be represented as , displayform0where sel ( inlineform73 ) is a random selection function with equal probability .the reader is referred to algorithm secref15 for more details of the training procedures .[ t ] set the learning rate inlineform74 and the batch size inlineform75 .initialize each network parameters inlineform76 ,paired image set inlineform77 .not converged get a source batch inlineform78 and a target batch inlineform79 ,  inlineform80where inlineform81 is a target sample randomly chosen from inlineform82 .update the real / fake discriminator inlineform83 :  inlineform84update the domain discriminator inlineform85 :  inlineform86update the converter inlineform87 :  inlineform88  adversarial training for the pixel - level domain transfer .\n\nevaluation: in this section , we verify our pixel - level domain transfer by a challenging task ; a natural human image belongs to the source domain , and a product image of that person 's top belongs to the target domain .we first give a description on the dataset in sec .secref17 .we then provide details on the experimental setting in sec .secref20 , and we demonstrate and discuss the results in sec .secref21 inlineform89 secref28 .\n\nlookbook dataset: we make a dataset named lookbook that covers two fashion domains .images of one domain contain fashion models , and those of the other domain contain top products with a clean background .real examples are shown in fig .figref19 .we manually associate each product image with corresponding images of a fashion model fitting the product , so each pair is accurately connected with the same product .lookbook contains 84,748 images where 9,732 top product images are associated with 75,016 fashion model images .it means that a product has around 8 fashion model images in average .we collect the images from five on - line fashion shopping malls where a product image and its fashion model images are provided .although we utilize lookbook for the pixel - level domain transfer , we believe that it can contribute to a wide range of domain adaptation researches .chen et al .  also has presented a similar fashion dataset dealing with two domains .however , it is not suitable for our task since the domains are differently defined in details .they separate the domain into user taken images and on - line shopping mall images so that both domains include humans .\n\nexperiment details: before training , we rescale all images in lookbook to have 64 pixels at a longer side while keeping the aspect ratio , and fill the margins of both ends with 255s .pixels are normalized to a range of inlineform90 according to the tanh activation layer of the converter .we then randomly select 5 % images to define a validation set , and also 5 % images for a test set .since lookbook has 9,732 products , each of the validation set and the test set is composed of 487 product images and their fashion model images .the remaining images compose a training set .the filters of the three networks are randomly initialized from a zero mean gaussian distribution with a standard deviation of 0.02 .the leak slope of the leakyrelu in table tabref11 -(a ) is 0.2 .all models were trained with stochastic gradient descent with mini - batch of 128 size .we also follow the learning rate of 0.0002 and the momentum of 0.5 suggested by   .after 25 epochs , we lessen the learning rate to 0.00002 for 5 more epochs .table tabref22 shows the notations and the descriptions of the 4 baselines and our method .the training details of all the baselines are identical to those of ours .\n\nqualitative evaluation: first , we show qualitative results in fig .figref30 , where the examples are chosen from the test set .our results look more relevant to the source image and more realistic compared to those of baselines .boundaries of products are sharp , and small details such as stripes , patterns are well described in general .the results of \u201c c+rf \u201d look realistic but irrelevant to the source image , and those of \u201c c+mse \u201d are quite blurry .fig .figref29verifieshow well the encoder of the converter encodes clothing attributes under the various conditions of source images .the source images significantly vary in terms of backgrounds , viewpoints , human poses and self - occlusions .despite these variations , our converter generates less varying targets while reflecting the clothing attributes and categories of the source images .these results imply that the encoder robustly summarizes the source information in a semantic level .\n\nquantitative evaluation by user study: since the target domain is not deterministic , it is difficult to quantitatively analyze the performance .thus , we conduct a user study on our generation results as a primary evaluation .we compare our method with the top two baselines in table tabref22 .for this study , we created a sub - test set composed of 100 source images randomly chosen from the test set .for each source image , we showed users three target images generated by the two baselines and our method .users were asked to rate them three times in accordance with three different evaluation criteria as follows .a total of 25 users participated in this study .how realistic is each result ?give a score from 0 to 2 .how well does each result capture the attributes ( color , texture , logos , etc . )of the source image ?give a score from 0 to 2 .is the category of each result identical to that of the source image ?give a binary score of 0 or 1 .the left part of table tabref23 shows the user study results .in the \u201c realistic \u201d criteria , it is not surprising that \u201c c+mse \u201d shows the worst performance due to the intrinsic limitation of the mean square loss for image generation .its assumption of gaussian distribution results in blurry images as shown in fig .figref30 .however , the strong pairwise supervision of the mean square loss relatively succeeds in representing the category and attributes of a product .when the converter is supervised with the real / fake discriminator only , the generated images are more realistic than those of \u201c c+mse \u201d .however , it fails to produce targets relevant to inputs and yields low attribute and category scores .the user study results demonstrate the effectiveness of the proposed method .for all valuation criteria , our method outperforms the baselines .especially , the ability to capture attributes and categories is better than that of \u201c c+mse \u201d .this result verifies the effectiveness of our domain discriminator .another interesting observation is that our score of \u201c realistic \u201d criteria is higher than that of \u201c c+rf \u201d .both of the methods include the real / fake discriminator but demonstrate distinct results .the difference may be caused by the domain discriminator which is added to the adversarial training in our method .when we train the domain discriminator , we regard all produced targets as \u201c unassociated \u201d .this setting makes the the converter better transfer a source image into a more realistic and relevant target image .\n\nquantitative evaluation by pixel-level (dis)similarity: for each method , we measure a pixel - level dissimilarity by root mean square error ( rmse ) between a generated image and a target image over the test set .we also measure a pixel - level similarity by structural similarity ( ssim ) , since ssim is known to be more consistent with human perception than rmse .we use a color version of ssim by averaging ssims for each channel .the right part of table tabref23 shows the results .as we can expect , \u201c c+mse \u201d shows the lowest rmse value because the converter is trained by minimizing the mean square loss .however , in case of ssim , our method outperforms all the baselines .to verify the effectiveness of the \u201c associated / unassociated \u201d supervision when we train the domain discriminator , we compare ours with \u201c c+rf+dd inlineform91 neg \u201d .in table tabref23 , our method outperforms this method .without the irrelevant input pairs , the generation results could look realistic , but relatively fail to describe the attributes of items .this is why we added the irrelevant input pairs into supervision to encourage our model to capture discriminative attributes .to verify the generalization capability of our model , we also compare ours with \u201c retrieval by dd - score \u201d .if our model fails in generalization ( i.e. just memorizes and copies training items which are similar to query ) , our generation results could not be better than the retrieved items which are real .however , our method outperforms the retrieval method .it verifies the capability of our model to draw unseen items .fig .figref31 shows the results of \u201c product to human \u201d setting .since generating human is a more complex task , 65 epochs for initial training and 5 more epochs for fine - tuning are required for these results .all the other details are identical to those of the original setting .\n\nconclusion: we have presented pixel - level domain transfer based on generative adversarial nets framework .the proposed domain discriminator enables us to train the semantic relation between the domains , and the converter has succeeded in generating decent target images .also , we have presented a large dataset that could contribute to domain adaptation researches .since our framework is not constrained to specific problems , we expect to extend it to other types of pixel - level domain transfer problems from low - level image processing to high - level synthesis .",
      "target_text": "we present an image - conditional image generation model .the model transfers an input domain to a target domain in semantic level , and generates the target image in pixel level .to generate realistic target images , we employ the real / fake - discriminator as in generative adversarial nets , but also introduce a novel domain - discriminator to make the generated image relevant to the input image .we verify our model through a challenging task of generating a piece of clothing from an input image of a dressed person .we present a high quality clothing dataset containing the two domains , and succeed in demonstrating decent results .",
      "output_text": "the source and target domains in the same feature space and train the encoder and the decoder separately .the encoder is trained to map the source image to a low dimensional feature space .the decoder is then trained to re - map the low dimensional space to a high dimensional target space .in the second strategy , we place the target and source domains in different feature spaces and train them jointly .the joint training of the encoders and decoders leads to a better representation of the semantic meanings of the domains .in summary , our paper proposes a pixel-level domain transfer method that directly transfers knowledge from one domain to another while preserving semantic meaning.the method is trained jointly in two domains and achieves state-of-the-art results on several benchmarks."
    },
    {
      "input_text": "Title: The quantum $H_3$ integrable system\nDomains: Physics\n\nintroduction: about 30 years ago , olshanetsky and perelomov developed the hamiltonian reduction method , later known as the projection method ( for a review , see   ) .this method provides an opportunity to construct on a regular basis the non - trivial multidimensional quantum ( and classical ) hamiltonians , which are associated to the crystallographic root spaces of the classical ( inlineform0 ) and exceptional ( inlineform1 )lie algebras .all these systems are symmetric with respect to the corresponding weyl group transformations .the olshanetsky \u2013 perelomov hamiltonians have the property of complete integrability ( the number of integrals of motion in involution is equal to the dimension of the configuration space ) .there are three types of the hamiltonians with rational , trigonometric and elliptic potentials , respectively .the hamiltonians with rational and trigonometric potentials are exactly solvable ( the spectrum can be found explicitly , in a form of a first- or second - degree polynomial in the quantum numbers , respectively ) .a hamiltonian with rational potential associated to a lie algebra inlineform2 of rank inlineform3 with root space inlineform4 has a form displayform0where inlineform5 is the set of positive roots , inlineform6 is a real parameter , inlineform7 are coupling constants depending only on the root length , and inlineform8 is the coordinate vector .the configuration space is the principal weyl chamber of the root space ( see   ) .the ground state eigenfunction and its eigenvalue are given by displayform0and its eigenvalue displayform0where inlineform9 is the invariant of the degree two ( for definition see below ) .it is indicated in   that the hamiltonian ( eqref1 ) with the property ( 2)-(3 ) can be introduced for the non - crystallographic root systems inlineform10 , inlineform11 and dihedral inlineform12 with a coxeter group as a symmetry of the system .all that is not true for the inlineform13 , inlineform14 and inlineform15 hamiltonians with trigonometric or elliptic potential .the complete integrability of ( 1 ) for the case of non - crystallographic root systems has been proven in   using the formalism of quantum lax pairs .following   , we make three definitions .definition 1 .a multivariate linear differential operator is said to be in algebraic form if its coefficients are polynomials in the independent variable(s ) .it is called algebraic if by an appropriate change of the independent variable(s ) , it can be written in an algebraic form .definition 2 . consider a finite - dimensional ( linear ) space of multivariate polynomials defined as a linear space spanned in the following way : inlineform16where the inlineform17 's are positive integers and inlineform18 .it represents the newton polytope in a form of a rectangular pyramid .its characteristic vector is the inlineform19 -dimensional vector with components inlineform20 : displayform0for some characteristic vectors , the corresponding polynomial spaces may have a lie - algebraic interpretation , in that they are the finite - dimensional representation spaces for some lie algebra of differential operators .the smallest characteristic vector is inlineform21 .it corresponds to the finite - dimensional representation space for the lie algebra inlineform22 of the first order differential operators acting in inlineform23   .we will call such a space the basic space as well as the associated flag will be called the basic flag .definition 3 .take the infinite set of spaces of multivariate polynomials inlineform24 , inlineform25 , defined as above , and order them by inclusion : inlineform26such an object is called an infinite flag ( or filtration ) , and is denoted inlineform27 .if a linear differential operator preserves such an infinite flag , it is said to be exactly - solvable .it is evident that every such operator is algebraic ( see   ) .if the spaces inlineform28 can be viewed as the finite - dimensional representation spaces of some ( lie ) algebra inlineform29 , then inlineform30 is called the hidden algebra of the exactly - solvable operator .if a linear operator preserves several flags and among them there is a flag for which inlineform31 is maximal for any given inlineform32 , such a flag is called minimal .every flag can be characterized by a normal vector inlineform33 to the hyperplane inlineform34 of the base of the newton polytope .this normal vector is , in fact , the characteristic vector .it is clear that for minimal characteristic vector the angle with basic characteristic vector inlineform35 is minimal .for any root system inlineform36 there exist inlineform37 rank inlineform38homogeneous , algebraically independent polynomials which are invariant with respect to the coxeter group .they are called the invariants .the lowest possible degrees inlineform39 of these invariants are the degrees of the coxeter group .each invariant is defined ambiguously , up to a non - linear combination of the invariants of the lower degrees .one of the ways to find an invariant of degree inlineform40 ( denoted as inlineform41 ) is to make averaging over an orbit inlineform42 , displayform0( see e.g.   ) , where inlineform43 's are some formal variables which can be identified with the cartesian coordinates .it is worth mentioning that for any coxeter group there exists a second degree invariant inlineform44 , this invariant does not depend on the chosen orbit .later on we will use the invariants ( eqref5 ) as new variables .we will call them the orbit variables .for all the crystallographic root systems algebraic representations of all quantum hamiltonians , both rational and trigonometric , have been found (   -   ) .the general strategy which was used to find a minimal flag for the rational hamiltonians is the following : ( i ) as a first step we consider the similarity - transformed version of ( eqref1 ) , namely inlineform45 , ( ii )then , we choose a certain orbit to construct a particular set of variables which lead to an algebraic form of the transformed hamiltonian inlineform46 , ( ii ) finally , exploiting the ambiguity in the definition of polynomial invariants of the fixed degrees we search for variables for which the flag of invariant subspaces of ( 1 ) is minimal flag .a primary goal of this paper is to show that the same strategy can be applied for a study of the rational inlineform47 hamiltonian ( 1 ) .we find the algebraic form of the rational inlineform48 hamiltonian and a minimal flag of its invariant subspaces .furthermore , we demonstrate that any ( invariant ) subspace from the minimal flag is a representation space of a finite - dimensional representation of a certain infinite - dimensional , finitely - generated algebra .this algebra is the hidden algebra of the inlineform49 system .a similar analysis is done for one of the integrals of the inlineform50 system .another goal of the paper is to find a quasi - exactly - solvable generalization of the inlineform51 rational model .by definition a linear differential operator is quasi - exactly - solvable ( qes ) if it preserves a finite - dimensional functional space with an explicitly indicated basis ( see e.g.   ) .thus , it implies that the qes operator has a finite - dimensional invariant subspace spanned by known functions .furthermore , one can indicate explicitly a basis where the operator being written in the matrix form has a block - triangular form .in practice , for all known examples of the qes operatorsthe finite - dimensional invariant subspace is a space of inhomogeneous polynomials in one or several variables .in many cases the space of polynomials can be identified with a finite dimensional representation space of a lie algebra of differential operators of the first order .in the case of crystallographic root systems a certain qes generalization has been found for each particular rational hamiltonian   .all those examples are related with the existence of the hidden inlineform52 algebra .we show that a similar inlineform53 -quasi - exactly - solvable generalization of the inlineform54 model exists .finally , we show that in the inlineform55 orbit space ( in the space of the inlineform56 invariants inlineform57 ) there exists a discrete model defined on three - dimensional uniform lattice with polynomial eigenfunctions which is isospectral to the rational inlineform58 model and integrable .we will call this model the \" discrete inlineform59 rational model \" .\n\nthe hamiltonian: the hamiltonian of the rational inlineform60 model ( see ( eqref1 ) ) is invariant wrt the inlineform61 coxeter group , which is the full symmetry group of the icosahedron .this discrete group is subgroup of inlineform62 and its dimension is 120 ( see e.g.   ) .in the cartesian coordinates inlineform63the hamiltonian has the form displayform0where inlineform64 and its even permutations .here inlineform65 is the coupling constant , inlineform66the golden ratio and its algebraic conjugate .we choose as the configuration space the fundamental domain of the inlineform67 group \u2013 the space bounded by three planes displayform0for inlineform68 .the ground state eigenfunction and its eigenvalue are displayform0where displayform0the ground state eigenfunction ( eqref8 ) does not vanish in the configuration space ( eqref7 ) .the main object of our study is the gauge - rotated hamiltonian ( eqref6 ) with the ground state eigenfunction ( eqref8 ) taken as a factor , displayform0where inlineform69 is given by ( eqref8 ) .the gauge rotated operator ( eqref10 ) is the second - order differential operator without free term .by construction its lowest eigenfunction is a constant and the lowest eigenvalue is equal to zero .now let us introduce new variables in ( eqref10 ) .the inlineform70 root space is characterized by three fundamental weights inlineform71 ( see e.g.   ) .taking action of all group elements on fundamental weight inlineform72we generate orbit inlineform73 of a certain length ( length inlineform74 # elements of the orbit ) .the results are summarized asin order to find inlineform75 -invariants ( eqref5 )we choose for simplicity the shortest orbit inlineform76 and make averaging , displayform0where inlineform77 are the degrees of the inlineform78 group .these invariants are defined ambiguously , up to a non - linear combination of the invariants of the lower degrees displayform0where inlineform79 are parameters .now we can make a change of variables in the gauge - rotated hamiltonian ( eqref10 ):inlineform80the first observation is that the transformed hamiltonian inlineform81 ( eqref10 ) takes on an algebraic form for any value of the parameters inlineform82 invariables inlineform83 's ( eqref12 ) .the second observation is that for any value of the parameters inlineform84there exists a flag of invariant subspaces in polynomials of the hamiltonian inlineform85 .our goal is to find the parameters for which inlineform86 preserves the minimal flag .after some analysis we found such a set of parameters displayform0the inlineform87 -variables ( eqref12 ) for such values of parameters , which we denote as inlineform88 -variables , are displayform0the hamiltonian inlineform89 has infinitely - many finite - dimensional invariant subspaces displayform0which form the minimal flag .its characteristic vector is displayform0it is worth noting that each particular space inlineform90 ( eqref15 ) as well as the whole flag are invariant with respect to a weighted projective transformation displayform0where inlineform91 are parameters .it manifests a hidden invariance of the hamiltonian ( eqref6 ) .it is seen in a clear way in the space of orbits only .finally , the gauge - rotated hamiltonian ( eqref10 ) in the inlineform92 -coordinates is written as displayform0with the coefficient functions displayform0it can be easily checked that the operator ( eqref18 ) is triangular with respect to action on monomials inlineform93 .one can find the spectrum of ( eqref18 ) inlineform94explicitly displayform0where inlineform95 .degeneracy of the spectrum is related to the number of solutions of the equation inlineform96 for inlineform97 in non - negative numbers inlineform98 .the spectrum inlineform99 does not depend on the coupling constant inlineform100 and it is equidistant .it coincides to the spectrum of inlineform101 anisotropic harmonic oscillator with frequenciesinlineform102 .the energies of the original rational inlineform103 hamiltonian ( eqref6 ) are inlineform104 .the boundary of the configuration space of the rational inlineform105 model ( eqref6 ) in the inlineform106 variables is determined by the zeros of the ground state eigenfunction , hence , by pre - exponential factor in ( eqref8 ) .it is the algebraic surface of degree 15 in cartesian coordinates being a product of monomials .in inlineform107 -coordinates it can be written as displayform0which is the algebraic surface of degree seven ; the equation contains monomials of the degrees 7 , 5 and 3 .it is worth mentioning that l.h.s . of ( eqref21 ) is proportional to the square of jacobian , inlineform108 .\n\nintegral: the hamiltonian ( eqref6 ) being written in spherical coordinatesinlineform109 takes a very simple form displayform0where inlineform110 is the inlineform111 laplacian and the angular function displayform0here , for the sake of simplicity we denoted inlineform112 , inlineform113 .it is seen immediately , that the schroedinger equation ( eqref22 ) admits a separation of radial variableinlineform114: any solution can be written in factorized form displayform0functions inlineform115 and inlineform116 are the solutions of the equations displayform0 displayform1respectively , while inlineform117 is the constant of separation .the operatorinlineform118 has the form displayform0where inlineform119 is the angular momentum operator : inlineform120it can be immediately checked that the hamiltonian inlineform121 and inlineform122 commute , displayform0hence , inlineform123 is an integral of motion .thus , it has common eigenfunctions with the hamiltonian inlineform124 .let us make a gauge rotation of the operatorinlineform125 ( eqref27 ) with the ground state functioninlineform126 as a gauge factor , displayform0where inlineform127 is the lowest eigenvalue of inlineform128 , and make a change of variables to the inlineform129 variables ( eqref14 ) .the operator inlineform130 has an algebraic form , displayform0where displayform0it is worth noting that in the operator inlineform131 the variable inlineform132 appears as a parameter .it implies that any eigenfunction of inlineform133 which depends on inlineform134 only ( see below ch.v for a discussion ) is the eigenfunction of the integral inlineform135 with zero eigenvalue .it can be also shown that the operator inlineform136 has infinitely many finite - dimensional invariant subspaces in polynomials displayform0which form a flag with characteristic vector inlineform137 .the spectrum of the integral inlineform138 can be found in a closed form , displayform0where inlineform139 and inlineform140 is given by ( 29 ) .it can be shown that the hamiltonian inlineform141 has a certain degeneracy \u2013 it preserves two different flags : one with minimal characteristic vector ( 1,2,3 ) and another one with characteristic vector ( 1,3,5 ) .the fact that the operator inlineform142 with coefficients ( eqref19 ) commutes with inlineform143 given by ( eqref30 ) implies that common eigenfunctions of the operatorsinlineform144 and inlineform145 are elements of the flag of spaces inlineform146 .let us denote inlineform147 the common eigenfunctions of inlineform148 and inlineform149 which are elements of the invariant space inlineform150 and their respectful eigenvalues inlineform151 .the index inlineform152 numerates these eigenfunction for given inlineform153 starting from 0 .the function inlineform154 is related to the eigenfunction of the hamiltonian inlineform155 ( eqref6 )( and the integralinlineform156 ) through inlineform157 .thus , the eigenfunctions inlineform158 are orthogonal with the weight factor inlineform159 .as an illustration let us give explicit expressions for several eigenfunctions inlineform160 and their respectful eigenvalues ,as stated before , the hamiltonian inlineform161 preserves two flags with characteristic vectors inlineform162 and inlineform163 , respectively .the angle between the normal vectors of the minimal flag inlineform164 and of the basic one inlineform165 is given inlineform166while between the vectors inlineform167and inlineform168 inlineform169it seems evident that if one or more extra integrals exist they will take an algebraic form in inlineform170 -variables after the gauge rotation .\n\ndiscrete uniform h 3 h_3 system: the existence of the algebraic form of the inlineform171 hamiltonian in the space of invariants allows us to construct a discrete system with a remarkable property of isospectrality .this construction is based on employment of a quantum canonical transformation as a basis to perform a discretization of a continuous system   .such a procedure was called a lie - algebraic discretization .it was already used in the past to construct the isospectral discrete model of the harmonic oscillator ( the inlineform172 system in the hamiltonian reduction nomenclature ) in the space of inlineform173   .let us introduce a set of the finite - difference operatorsdisplayform0where inlineform174 are spacings ; here no summation over repeated indexes is implied .the operator inlineform175 is the finite - difference derivative or discrete momentum ; sometimes , it is called the norlund derivative .the operator inlineform176 is a discrete analogue of the multiplication operator .the operators inlineform177 and inlineform178 form a canonical pair , displayform0for inlineform179 .hence , the operators ( eqref38 ) span the 7-dimensional heisenberg algebra realizing a three - parametric quantum canonical transformation with parametersinlineform180 .in the limit when all inlineform181 tend to zero the operators ( eqref38 ) gives rise to a standard coordinate - momentum representation , inlineform182take a linear differential operator inlineform183 .consider the eigenvalue problemdisplayform0and assume it has polynomial eigenfunctions .performing the canonical transformation ( eqref38 ) we arrive at displayform0in order to make sense to this equation one should introduce the vacuum inlineform184 : displayform0then the equation ( eqref41 ) has a meaning of an operator eigenvalue problem in the fock space with vacuum ( eqref42 ) .now let us show that the eigenvalue problem ( eqref41 ) has polynomial eigenfunctions and their eigenvalues are the same eigenvalues as for the polynomial eigenfunctions as the original ( continuous ) problem ( eqref40 ) .in order to exploit the representation ( eqref38 ) let us first define the vacuum inlineform185 .the condition ( eqref42 ) in explicit form is f(1 + 1,2,3)=f(1,2,3 ) ,f(1,2 + 2,3)=f(1,2,3 ) ,f(1,2,3 + 3)=f(1,2,3 ) .any periodic function with periods inlineform186 in the coordinatesinlineform187 is the solution of these equations ; however , without loss of generality , we can make the choice displayform0let us now define the quasi - monomial displayform0taking into account the relationinlineform188and choosing of vacuum ( eqref43 ) , it is easy to check that displayform0now we can relate the solutions of ( eqref41 ) with the solutions of ( eqref40 ) .let us assume that displayform0is a polynomial solution of the equation ( eqref40 ) .the canonical transformation ( eqref38 ) implies the replacement of inlineform189 by inlineform190 .taking in account (eqref45 )we come to the conclusion that each monomial in ( eqref46 ) should be replaced by a quasi - monomial .hence , the corresponding polynomial solution of ( eqref41 ) is displayform0with the same expansion coefficients inlineform191 as in ( eqref46 ) and the same eigenvalue .performing the procedure of canonical discretization ( eqref40 )inlineform192 ( eqref41 ) for the inlineform193 hamiltonian in the algebraic forminlineform194 ( eqref18 ) , we arrive at the following ( isospectral ) finite - difference operator : displayform0with the following non - vanishing coefficients displayform0 displayform1the corresponding eigenvalue problem is displayform0which is in the explicit form displayform0inlineform195it defines the discrete uniform inlineform196 system .it is worth noting that , although we started from a second - order differential operator , the 22-point finite - difference operator occurs \u2013 it connects the function in 22 different points in the lattice space : four points in inlineform197 -direction , six points in inlineform198 -direction , four points in inlineform199-direction .the structure of the operator is shown in fig .figref53 .the spectrum of the discrete operatorinlineform200 ( eqref48 ) for polynomial eigenfunctions coincides to the spectrum of the continuous operatorinlineform201 ( eqref18 )where all eigenfunctions are polynomial ones : displayform0where the inlineform202 's are non - negative integers .the eigenfunctions of ( eqref48 ) are related to the eigenfunctions of the continuous operator inlineform203 by replacing each monomial with a quasi - monomial in each variable .such a phenomenon can be called partial or polynomial isospectrality .we can not exclude the existence of other eigenstates of the discrete operator inlineform204 than those given by polynomial eigenfunctions .these eigenstates can correspond to non - normalizable eigenfunctions of inlineform205 .as a particular case let us consider the unit spacing inlineform206 .this case corresponds to the discretization in a cubic lattice the space of orbits ( in inlineform207 -space ) with unit lattice vector .the equation ( eqref52 ) is reduced to the equationinlineform208displayform0a similar procedure of discretization can be applied to the integral inlineform209 .instead of the continuous algebraic operatorinlineform210 we get its discrete counterpartdisplayform0with the following coefficients displayform0 displayform1we end up with the 22-point finite - difference operator occurs \u2013 it connects the function in 22 different points in the lattice space : four points in inlineform211 -direction , six points in inlineform212 -direction , five points in inlineform213-direction .the structure of the operator is shown in fig .figref59 .it is surprising that both discrete operators inlineform214and inlineform215 have the same structure connecting 22 points .it is evident that the discrete operators inlineform216 and inlineform217 continue to commute .such a procedure of discretization preserves the property of integrability .\n\nquasi-exactly-solvable generalization: among the eigenfunctions of the hamiltonian inlineform218 ( eqref18 ) there is an infinite family of eigenfunctions depending on the single variable inlineform219 .these eigenstates are solutions of the eigenvalue problem displayform0corresponding eigenfunctions are given by the laguerre polynomials and the eigenvalues are linear in quantum number displayform0the operator in the l.h.s . of ( eqref60 ) can be rewritten in terms of the generators inlineform220 of the cartan subalgebra of the algebra inlineform221 of the first order differential operators : displayform0( see   ) .for integer inlineform222 the generators ( eqref62 ) have a common invariant subspace in polynomials of degree not higher than inlineform223 , displayform0where inlineform224 .the operator ( eqref60 ) takes the inlineform225 -lie - algebraic form displayform0it is easy to check that the operator inlineform226 preserves an infinite flag of spaces of polynomials ( eqref63 ) , displayform0and , in particular , any eigenfunction is an element of the flag .let us proceed to construct a qes generalization of ( eqref6 ) .we look for the qes hamiltonian in a certain form displayform0where inlineform227 is a potential .let us make a gauge rotation of ( eqref66 ) of the form ( eqref10 ) .we impose the requirement that the resulting operator possesses a inlineform228 -depending family of eigenfunctions .we obtain the following equation : displayform0our aim is to find inlineform229 for which the operator inlineform230 is inlineform231 -lie - algebraic \u2013 can be rewritten in terms of the generators ( eqref62 ) .following   , let us gauge rotate the operator ( eqref67 ) , displayform0if the corresponding potential inlineform232 is chosen of the form displayform0the operator inlineform233 has the lie - algebraic form displayform0where inlineform234 and inlineform235 are parameters , here the constant terms are dropped off .it can be seen that the operator inlineform236 ( see ( eqref70 ) ) has the space inlineform237 as the invariant subspace , but it does not preserve the flag of spaces ( eqref65 ) .hence , ( eqref64 ) has ( k+1 )polynomial eigenfunctions of the form of polynomials of the degree inlineform238 , inlineform239while other eigenfunctions are not polynomials .now we can give the final expression of the inlineform240 -quasi - exactly - solvable hamiltonian associated with the root spaceinlineform241: displayform0where inlineform242 and its even permutations , andinlineform243 .for this hamiltonian we knowinlineform244 eigenstates explicitly .their eigenfunctions are of the form displayform0where inlineform245 is a polynomial of degree inlineform246 ,the coupling constant inlineform247 and inlineform248 are given by ( eqref9 ) .it is worth presenting several inlineform249 explicitly , displayform0the solutions for inlineform250 are related through analytic continuation in one of the parameters inlineform251 keeping other parameters fixed .they form two - sheeted riemann surface .the qes hamiltonian ( eqref71 ) is integrable \u2013 the integral inlineform252 ( eqref27 ) remains to commute with the hamiltonian .\n\nhidden algebra: we have shown that the hamiltonian in the algebraic form ( eqref18 ) acts on the finite - dimensional spaces of multivariate polynomialsinlineform253 ( see ( eqref15 ) ) .a goal of this section is to show that each one of these subspaces is a representation space of an infinite - dimensional algebra of differential operators which we call inlineform254 and to study this algebra .the algebrainlineform255 is infinite - dimensional but finitely - generated .their generating elements can be split into two classes .the first class of generators ( lowering and cartan operators ) act in inlineform256 for any inlineform257 and therefore they preserve the flag inlineform258 .the second class operators ( raising operators ) act on the space inlineform259 for a certain value of inlineform260 only ; they do not act on a space at other inlineform261 ' s.let us introduce the following notation for the derivatives : inlineform262the first class of generating elements consist of the 22 generators where 13 of them are the first order operators displayform0the 6 are of the second order displayform0and 2 are of the third orderdisplayform0the generators of the second class consist of 8 operators where 1 of them is of the first order displayform04 are of the second order displayform0and 3 are of the third orderdisplayform0where we have introduced the diagonal operator displayform0for a convenience .in fact , this operator is identity operator , it is of the zeroth order and , hence , it belongs to the first class .before to proceed to study the commutation relations between generators we introduce a notion of conjugation .let inlineform263and inlineform264 be operators acting on a monomial .we say that inlineform265 is a conjugate to inlineform266 if the operatorinlineform267 leaves the monomial unchanged .there is a certain ambiguity related with the central operator inlineform268 ( eqref80 ) .formally , it seems self - conjugated .from another side , the operator inlineform269 is , in fact , the unit operator .thus , one can define a conjugate to inlineform270 to be equal to 1 and visa versa : a conjugate to 1 is equal inlineform271 .>from this point of view any operator is defined up to a multiplicative factor of inlineform272 .we resolve this ambiguity by defining the generators ( eqref74 ) -( eqref80 ) in a way for supporting below - presented commutation relations and eventually a structure of algebra .in particular , inlineform273 is conjugated to inlineform274 , inlineform275and inlineform276 is conjugated to inlineform277 , inlineform278except for this ambiguity , the conjugation coincides with the fourier transform .a certain number of generating operators ( eqref74 ) -( eqref79 ) span ten abelian subalgebras : displayform0the remaining generators span a non - commutative algebra isomorphic to inlineform279 , where inlineform280 is the abelian algebra of dimension 2 , displayform0the arrow in ( eqref81 ) means that the corresponding operators are related by conjugation ( for example , inlineform281 and inlineform282 ) .the subalgebrainlineform283 is the unique algebra those operators are self - conjugated .decomposition ( eqref81 ) , ( eqref82 ) allows us to give a compact representation of the commutation relations relating the generating elements .as first we can show that the commutators between the abelian algebras from the l.h.s . ( r.h.s . ) of ( eqref81 ) are closed \u2013 they are either zero or written in terms of generators of one of the algebras froml.h.s .( r.h.s . )plus from the algebrainlineform284 [ l , r]=0 , [ l , r]=0 ,[ l , f]=0 , [ l , f]=0 ,[ l , e]=p2(r ) , [ l , e]=p2(r ) ,[ l , g]=0 , [ l , g]=0 ,[ r , f]=l , [ r , f]=l ,[ r , e]=0 , [ r , e]=0 ,[ r , g]=p2(f ) , [ r , g]=p2(f ) ,[ f , e]=p2(rb ) , [ f , e]=p2(rb ) ,[ f , g]=0 , [ f , g]=0 ,[ e , g]=p3(fb ) , [ e , g]=p3(fb ) , here inlineform285 means that the commutator is given by a polynomial of the inlineform286 -th degree in the generators of inlineform287 .it turns out all commutators are symmetric under conjugation .this property also holds for cross commutators of the algebras from the l.h.s . and the r.h.s .in ( eqref81 ) , [ l , r]=p2(fb ) , [ l , r]=p2(fb ) ,[ l , f]=p2(rb ) , [ l , f]=p2(rb ) ,[ l , e]=p2(f ) , [ l , e]=p2(f ) ,[ l , g]=p2(re ) , [ l , g]=p2(re ) ,[ r , f]=e , [ r , f]=e ,[ r , e]=p2(fb ) , [ r , e]=p2(fb ) ,[ r , g]=0 , [ r , g]=0 ,[ f , e]=g , [ f , e]=g ,[ f , g]=p2(eb ) , [ f , g]=p2(eb ) ,[ e , g]=0 , [ e , g]=0 , the commutator between any abelian algebra from ( eqref81 ) and the algebrainlineform288 is of the type of a semidirect product : [ l , b]=l , [ r , b]=r , [f , b]=f , [ e , b]=e , [ g , b]=g ,l , b= l , [ r , b]=r , [ f , b]=f , [ e , b]=e , [ g , b]=g , at last , let us indicate commutators between conjugated algebras in ( eqref81 )- all of them are polynomials in generators of inlineform289 : [ l , l]=p3(b ) , [ r , r]=p2(b ) , [ f , f]=p2(b ) ,[ e , e]=p3(b ) , [ g , g]=p4(b ) .  latter two types of relations are represented by triangular diagrams , see for example , fig.3 .in general , the commutation relations between two operators are characterized by a non - linear combination of the generators in r.h.s .. calculating double , triple , etc .commutators one can see that the commutation relations can not be closed at any order and the order of the r.h.s . is increasing .hence , the inlineform290 algebra is not a polynomial algebra .it is the infinite dimensional algebra of ordered monomials in the 30 generating operators ( eqref74 ) -( eqref79 ) shown above .since inlineform291 is the algebra of differential operators acting on inlineform292 it should be possible to write the inlineform293 hamiltonian ( eqref18 ) as a combination of the ( flag - preserving ) generating elements ( eqref74 ) - ( eqref76 ) of inlineform294 .the inlineform295 -algebraic form of the inlineform296 model ( eqref6 ) is the following : displayform0\n\nconclusions: we have shown that the inlineform297 rational system related to the non - crystallographic root system inlineform298 is exactly solvable with the characteristic vector inlineform299 .this work complements the previous studies of the rational ( and trigonometric ) models , related with crystallographic root systems( e.g.   -   ) .a certain significance of exploration of the inlineform300 rational system is due to a fact that this model is defined in three - dimensional euclidian ( physical ) space .there are very few known exactly - solvable systems in this space \u2013 the coulomb problem , four - body calogero - sutherland inlineform301 and inlineform302 rational - trigonometric models among them .surprisingly , all of them are integrable while the coulomb , inlineform303 and inlineform304 rational problems are superintegrable .the same is correct for all known two - dimensional exactly - solvable problems in the euclidean space : all of them are integrable .taking coxeter invariants of inlineform305 as coordinates provided us a way to reduce the rational inlineform306 hamiltonian to algebraic form .it gave us a chance to find the eigenfunctions of the rational inlineform307 hamiltonian which are proportional to polynomials in these invariant coordinates .it seems correct that these eigenfunctions exhaust all eigenfunctions in the hilbert space .it is worth noting that the matrix inlineform308 which appears in front of the second derivatives after changing variables in laplacian from cartesian to the inlineform309 coxeter invariant coordinates ( see eqs .( eqref19 ) ) has polynomial entries corresponding to flat space metric , hence the riemann tensor vanishes .we call metric the arnold metric .it should be stressed that it was stated that the hamiltonian of the inlineform310 rational system ( eqref1 ) is completely integrable   .this implies the existence of two mutually - commuted operators ( the ` higher hamiltonians ' ) which commute with the hamiltonian forming a commutative algebra .it is known ( see   ) for the crystallographic systems that these higher hamiltonians are the differential operators of the degrees which coincide to the minimal degrees of the root space ( the lie algebra ) or their squares for the inlineform311 case .it may suggest that for the inlineform312 rational system the commuting integrals might be differential operators of the orders six and ten .their explicit forms are not known so far .it is evident that these commuting operators should take on an algebraic form after a gauge rotation ( with the ground state function as a gauge factor ) , and a change of variables from cartesian coordinates to the coxeter invariantvariables inlineform313 ' s. following the experience with different integrable systems, it seems the integral(s ) related with separation of variables do not enter to the commutative algebra .therefore , the integral inlineform314 is out of the commutative algebra of integrals .it might serve as an indication to a superintegrability of the inlineform315 rational system .an analysis similar to the analysis of this paper has not yet been presented for the case of the rational systems related to the non - crystallographic root spaces inlineform316 .a study in progress indicates that the characteristic vector for the quantum inlineform317 integrable system is inlineform318 .in the case of dihedral group inlineform319 the rational model has the characteristic vectorinlineform320  .it should be pointed out that unlike the rational models it is not possible to construct integrable ( and exactly - solvable )trigonometric systems related to the non - crystallographic root spaces as a natural generalization of the hamiltonian reduction method   .the existence of algebraic form of the inlineform321 rational olshanetsky - perelomov hamiltonian makes possible the study of their polynomial perturbations which areinvariant wrtthe inlineform322 coxeter group by purely algebraic means : one can develop a perturbation theory in which all corrections are found by linear algebra methods   .in particular , it gives a chance to calculate the inlineform323 coxeter - invariant , polynomial correlation functions by algebraic means .another important property of the existence of algebraic form of the inlineform324 rational hamiltonian is a chance to perform a canonical , lie - algebraic discretization to uniform ( see ch.iv ) and exponential   lattices .in the case of both lattices such a discretization preserves a property of integrability , polynomiality of the eigenfunctions remains and it is isospectral .although it does not give a hint how to introduce a scalar product for a discrete model .making the weighted projective transformation ( eqref17 ) of the inlineform325 algebraic form ( eqref18 )we arrive at different algebraic form of the inlineform326 hamiltonian .making then the lie - algebraic discretization we arrive at a discrete model related to an original discrete model via change of variables .it can be considered as a definition of a polynomial change of variables for discrete operators .we found the inlineform327 -quasi - exactly - solvable generalization of the inlineform328 model which remains integrable .this is the first example of quasi - exact - solvability related to non - crystallographic root systems .it complements the results obtained previously for all rational models related to crystallographic systems ( see   ) and for the inlineform329 rational model   \u2013 each of these models admit a certain inlineform330 -qes generalization .thank to the explicit knowledge of the ground state function ( eqref8 )supersymmetric inlineform331 model can be constructed following a procedure realized in   for inlineform332 rational model , in   for the inlineform333 rational model and in   for the inlineform334 rational model .it can be done elsewhere .acknowledgements .the computations in this paper were performed on maple 8 and maple 11 with the packages coxeter and weyl created by j. stembridge .",
      "target_text": "the quantum $ h_3 $ integrable system is a 3d system with rational potential related to the non - crystallographic root system $ h_3$.it is shown that the gauge - rotated $ h_3 $ hamiltonian as well as one of the integrals , when written in terms of the invariants of the coxeter group $ h_3 $ , is in algebraic form : it has polynomial coefficients in front of derivatives .the hamiltonian has infinitely - many finite - dimensional invariant subspaces in polynomials , they form the infinite flag with the characteristic vector $ \\vec \\al\\= \\( 1,2,3)$.one among possible integrals is found ( of the second order ) as well as its algebraic form .a hidden algebra of the $ h_3 $ hamiltonian is determined .it is an infinite - dimensional , finitely - generated algebra of differential operators possessing finite - dimensional representations characterized by a generalized gauss decomposition property .a quasi - exactly - solvable integrable generalization of the model is obtained .a discrete integrable model on the uniform lattice in a space of $ h_3$-invariants\"polynomially\"-isospectral to the quantum $ h_3 $ model is defined .",
      "output_text": "\u2013 crystalline root systems is proved in   .\n\nkeywords: quantum integrable systems, crystal logarithm, trigonometry, elliptic functions, Lie algebras, weyl chambers, configuration space, ground state, eigenfunction, eigenvalue\n\nmethods: quantum Hamiltonian reduction, integrable Hamiltonian systems, Lie symmetries, Lie algebra, configuration spaces, ground states, eigenfunctions, eigenvalues\n\nresults: exact solvability, complete integrabilty, trigonal and elliptical potentials, rational potentials\n\nconclusion: the quantum H3 system is an excellent example of the integrable quantum Hamiltonian system with a rational potential .it can be used as a tool for the study of the symmetry properties of crystals and for the development of new methods for the construction of integrable Hamiltonians .furthermore , it can be applied to the investigation of the phase transitions and the properties of the ground states in the context of quantum field theory and condensed matter physics .in particular , it is interesting to note that the ground state of the H3 model can be expressed in terms of the hypergeometric function , which is a fundamental object in the theory of orthogonal polynomials ( see , e.g. ,   and   ).\n\nabstract: this article presents a detailed study of an integrable classical and quantum system, the quantum Hamiltonian H3. The Hamiltonian is constructed using the Hamiltonian reduction method, which allows one to construct non-trivial, non-symmetric, and non-integrable systems on regular domains. The H3 Hamiltonian is symmetric, and its ground state can be written in the form H3(x,y,z) = x^2 + y^2 - z^2. This ground state has a crystal-logarithmic singularity at the origin, which is related to the existence of a non-zero eigenvalue of the Hamiltonian. This singularity is a consequence of the fact that the Hamiltonian is invariant under the action of a Lie symmetry group. The ground state is also integrable, and the Hamiltonian can be reduced to a set of quadratic Hamiltonians, each of which is completely integrable. These Hamiltonians have rational potential functions, and their ground states can be obtained explicitly. In addition, the Hamiltonian has a trigonal potential, which can be represented as a sum of rational functions of x, y, and z. The trigonal Hamiltonian is integrable and has a unique ground state. The quantum Hamiltonian is also constructed using projection methods, and it is shown that it has a complete set of eigenfunctions and eigenvalues. The configuration space of the quantum system is a principal Weyl chamber, which corresponds to the roots of the Lie algebra. The eigenvalue and eigenfunction of the trigonal quantum Hamiltonian are given explicitly. The results of this study suggest the possibility of using the quantum Hamiltonians H3 and trigonal H3 as tools for studying the symmetry and properties of quantum systems, as well as for investigating the behavior of quantum fields in curved spacetimes. In particular, the use of these Hamiltonians can lead to new insights into the properties and behavior of non-perturbative quantum field theories."
    },
    {
      "input_text": "Title: Effect of Peculiar Motion in Weak Lensing\nDomains: Physics\n\nintroduction: mapping the large - scale structure of the universe is one of the most important current challenges for cosmology .weak gravitational lensing represents a promising tool to achieve this goal , since it is directly sensitive to the distribution of matter in the universe , independent of its nature ( baryon , dark matter ... ) .gravitational lensing describes indeed the deflection of light rays from distant sources by the gravitational potential along the line of sight .it induces consequently a modification of the shape of the sources .this distortion of images contains information about the evolution of large - scale structure , i.e. about the geometry and dynamics of the universe ( see e.g.   ,   and references therein ) .weak gravitational lensing can be divided in two parts : the shear , that distorts the shape of the source ; and the convergence , that magnifies or demagnifies it .both of these effects have already been measured .cosmic shear is detected through the correlations it induces on the ellipticity of galaxies .it was measured for the first time in 2000 , by four independent teams   .since then , many other experiments have detected cosmic shear in random patches of the sky   .in the next few years , weak lensing surveys , like cfhtls   , the dark energy survey   and pan - starrs   will deliver accurate measurements ( inlineform0 level ) over large parts of the sky .in the further future , even more challenging experiments like euclid   , lsst   and snap   are planned .the other component of weak lensing , the convergence , can be detected through the modifications it induces on the galaxy ( or quasar ) number density over a given flux threshold   .the convergence ( or more precisely the magnification ) has already been robustly detected using quasar - galaxy correlations ( see e.g.   and references therein ) .moreover , recently   has highlighted the possibility to measure accurately the magnification autocorrelations with the square kilometer array ( ska )   .a precision of inlineform1 is expected at the beginning and inlineform2 later on .hence the convergence provides an additional precise observational quantity , useful to constrain cosmology .in order to make optimal use of this observational information , one needs to understand the underlying theory of weak lensing accurately .in this paper , we present a fully relativistic description of weak gravitational lensing .more precisely , we calculate the jacobi map , that relates the surface of a galaxy to its angular image at the observer position , following the formalism presented in   .this map describes the distortion of a light beam by density perturbations along the geodesic between the source and the observer .the shear and the convergence are then extracted from this application .our derivation differs from the standard one in two points .first , in the usual derivation the inlineform3 jacobi map is reduced to a inlineform4 matrix , called the magnification matrix , by assuming that the source and the image belong to the same two - dimensional subspace , normal to the photon direction and to the observer four - velocity .the convergence is then defined as the trace of the magnification matrix and the shear as the traceless part .however , the source four - velocity differs generally from the observer four - velocity .as a consequence the source and the image do not belong to the same two - dimensional subspace .in this paper we take into account this difference .we show that the jacobi map can not be reduced to a inlineform5 matrix but only to a inlineform6 matrix , the third line describing the projection of the source plane into the observer plane .we establish that this generates an additional shear component .however since this effect is second order in the peculiar velocity of the source , it is not large enough to be observed .secondly , in the usual derivation the shear and the convergence are expressed as functions of the source conformal time .however conformal time is not an observable quantity .hence , in this paper we calculate the shear and the convergence as functions of the source redshift , which is observable .we show that this modification generates new contributions to the convergence .whereas most of those terms can be safely neglected with respect to the standard one , we establish that the contribution of the source peculiar velocity is important , especially for redshifts inlineform7 .more particularly , for surveys in which the sources are situated at redshift inlineform8 , we expect a modification of order inlineform9 relative to the standard results .for larger redshifts of the source the effect of peculiar motion decreases , whereas the standard term increases .however at redshift 1 , we still expect the velocity term to be inlineform10 of the standard term , i.e. measurable by the ska .furthermore , we show that the transformation from conformal time to redshift does not affect the shear component .as a consequence , the relation between the shear and the convergence is modified by peculiar velocities .the paper is organized as follows : in sec .secref2we derive a general formula for the magnification matrix valid in ( nearly ) arbitrary geometries .in sec .secref3 we apply this formula to a perturbed friedmann universe .in sec .secref4 , we investigate in detail the shear component of the magnification matrix .finally , in sec .secref5we calculate the convergence component and we determine its angular power spectrum .we investigate also the relation between cosmic shear and convergence .notation :we denote four - vectors with greek indices , inlineform11 .three - dimensional vectors are denoted bold face inlineform12 , or with latin indices inlineform13 .we use the metric signature inlineform14 .\n\nmagnification matrix: we consider an inhomogeneous and anisotropic universe with geometry inlineform15 .we are interested in the propagation of a light beam in this arbitrary spacetime .we follow the derivation presented in   .we denote by inlineform16 the phase of the light beam .the wave vector is then given by inlineform17 .we construct the deviation vector field inlineform18 connecting two neighboring rays .since all the rays of the beam have the same phase , the deviation vector satisfiesinlineform19 .furthermore it obeys the geodesic deviation equation  displayform0where inlineform20 is an affine parameter along the geodesics , inlineform21 represents the covariant derivative along geodesics , and inlineform22 is the riemann tensor associated with the metric inlineform23 .we consider the case of a light beam emitted by a galaxy at spacetime position inlineform24 and received by an observer at inlineform25( see fig . figref2 ) .we denote by inlineform26 the observer velocity and inlineform27 the source velocity .the photon energy measured at the source , respectively at the observer is displayform0the solution of equation ( eqref1 ) is then given by   displayform0 displayform1here inlineform28 is the jacobi map , that relates the deviation vector at the source inlineform29 to the angular vector at the observerinlineform30 .as we shall see , these two four - vectors belong to two different two - dimensional planes , orthogonal to the source peculiar velocity ( respectively the observer peculiar velocity ) and the photon direction at the source ( respectively at the observer ) .each ray can be parameterized by its affine parameter inlineform31 and three other parameters inlineform32 that label the ray .this parameterization is not unique and one can therefore make changes of the form displayform0under this reparameterization the connection vector inlineform33 transforms as   displayform0at the source , we can therefore choose a parameterization such thatinlineform34 .moreover , inlineform35 induces inlineform36 , where inlineform37 is the photon direction at the source : inlineform38 .hence inlineform39 lives in a two - dimensional subspace orthogonal to the source velocity and to the photon direction .it lies consequently in the plane of the galaxy .in addition to the choice of inlineform40 and inlineform41 in equation ( eqref6 ) , there is another degree of freedom corresponding to the scales of the affine parameter on the different rays .we can therefore require that at inlineform42 , inlineform43 , for all rays .with this choice , we get inlineform44 , which gives inlineform45 .furthermore , we can easily show that inlineform46 , which implies inlineform47 , where inlineform48 is the photon direction at the observer : inlineform49 .hence inlineform50 lives in a two - dimensional subspace orthogonal to the observer velocity and to the photon direction .it lies consequently in the plane of the observer .therefore the jacobi map inlineform51 in equation ( eqref4 ) determines how the surface of the galaxy represented by inlineform52 , is deformed into the observer angular vector inlineform53 , during propagation in an arbitrary spacetime .it maps hence the surface of the galaxy to its angular image at the observer .we now want to relate this map to the magnification matrix defined in   .at the observer we construct an orthonormal basis inlineform54 .we parallel transport this basis along the geodesic .the subspace defined by inlineform55 is called the screen adapted to inlineform56 and inlineform57 .we can write the deviation vector inlineform58 and the angular vector inlineform59 in this basis .using the fact that inlineform60 , we have displayform0moreover , inlineform61 implies displayform0in this basis equation ( eqref4 ) becomes then displayform0where displayform0  inlineform62 is proportional to the magnification matrix of lens theory , i.e. the gradient of the lens map .indeed , the lens map relates angles at the observer inlineform63 to angles at the source inlineform64 displayform0the gradient of this map , inlineform65 is called the magnification matrix displayform0for small angles , we can write inlineform66 , and consequently displayform0this implies displayform0usually , the component inlineform67 of the connection vector is neglected , and equation ( eqref10 ) becomes displayform0where inlineform68 is the inlineform69 submatrix of inlineform70 .the shear and the convergence are then extracted from inlineform71 ( see e.g.   ) .however , in general inlineform72 is not sufficient to relate inlineform73( or equivalently inlineform74 ) to inlineform75 .the third line of the matrix inlineform76 does indeed not vanish and therefore it plays a role in the deformation of the source plane .this is due to the fact that even if the connection vector inlineform77 at the source and the angular vector inlineform78 at the observer are both two - dimensional , they do not live in parallel planes .the connection vector inlineform79 belongs indeed to the plane normal to inlineform80 and inlineform81 , whereas the angular vector inlineform82 belongs to the plane normal to inlineform83 and inlineform84 .if inlineform85 , these two planes are different .hence if we choose inlineform86 as a basis on the observer plane , the parallel transported vectors inlineform87do not form a basis of the source plane .the connection vector inlineform88 will then have a component along inlineform89 , that we have to take into account when calculating the shear and convergence of galaxies .the difference between the two - dimensional plane of the source and the one of the observer comes mainly from the difference between the peculiar velocity of the source and the observer .there is an additional effect , due to parallel transport , which is however very small .hence , if inlineform90 , we can approximate the two planes as equal and we recover the inlineform91 magnification matrix inlineform92 .in section secref3 , we calculate explicitly the full matrix inlineform93 in a perturbed friedmann universe ( where in general inlineform94 ) and we show that the third line of the matrix inlineform95 induces an additional shear effect , which is however negligible since its amplitude is of second order in the source velocity .\n\nthe magnification matrix in a perturbed friedmann universe: we now calculate explicitly the magnification matrix in a friedmann universe with scalar perturbations .in longitudinal ( or newtonian ) gauge the metric is given by displayform0for perfect fluids like ordinary matter , dark matter and radiation , the metric perturbations inlineform96 and inlineform97 are equal .hence we assume in the sequelinlineform98 .we restrict ourselves to a spatially flat universe ( inlineform99 ) , so that inlineform100 .furthermore , since lightlike geodesics are not affected by conformal transformations , we perform the calculation in the metric displayform0we can then easily relate the magnification matrix in the two metrics by remembering that angles are not affected by conformal transformations , but distances scale with the conformal factor inlineform101 .hence displayform0we calculate therefore the magnification matrix related to the metric displayform0and then we simply multiply the result by inlineform102 to obtain the correct magnification matrix in a perturbed friedmann universe .in   , we have calculated the jacobi map associated with the luminosity distance in a perturbed friedmann universe , which relates angles at the source inlineform103 to distances at the observerinlineform104 displayform0this situation is the mirror of the lensing situation considered here ( see equation ( eqref4 ) and fig . figref23 ) .the two maps can therefore easily be related   by displayform0using inlineform105 from   , we find displayform0with displayform0here inlineform106 is the transverse laplacian .note that a similar derivation of inlineform107 and inlineform108 in the context of cmb lensing is presented in   .we have written here the magnification matrix as a function of conformal timeinlineform109 .however , inlineform110 is not an observable quantity .what we do measure is the redshift of the galaxy , which is also affected by perturbations , inlineform111 .now displayform0furthermore , displayform0and ( see   )displayform0hence inlineform112 becomes displayform0and inlineform113 and inlineform114 are not affected .the complete relativistic magnification matrix in a perturbed friedmann universe defined in equations ( eqref24 ) - ( ) , ( ) and ( eqref29 ) contains therefore additional terms to the standard one .in the next section , we investigate the effect of the third line of the matrix on the shape of a galaxy , and more particularly on the shear .and in section secref5 , we discuss in more detail the different contributions to the convergence inlineform115 .we determine that the only term which can be relevant is the one involving the galaxy peculiar velocity .\n\nthe shear: in this section , we study the effect of the third line of the magnification matrix on the shape of a galaxy .in order to simplify the calculation , we restrict ourselves to the peculiar velocity contribution .this means that we consider a homogeneous and isotropic friedmann universe , but we allow for nonzero peculiar velocity of the source inlineform116 and of the observer inlineform117 .the magnification matrix becomes then displayform0where displayform0the usual shear components inlineform118 and inlineform119 vanish , but as we will see the third line generates an additional shear deformation .from equation ( eqref10 ) and ( eqref30 ) , we find displayform0where inlineform120 and inlineform121 .at first order in inlineform122 and inlineform123 , equation ( eqref32 ) becomes displayform0that represents the equation of a two - dimensional plane .this reflects directly the fact that the galaxy , described by inlineform124 does not belong to the parallel transported observer plane :inlineform125 , but it rather belongs to the plane defined by equation ( eqref33 ) .we now assume that the galaxy is a disc of radius inlineform126 .hence in spherical coordinate displayform0combined with equation ( eqref33 ) , this gives displayform0 displayform1the inlineform127 sign is for inlineform128 and the inlineform129 sign for inlineform130 .the observer measures displayform0where we have already removed the monopole contribution inlineform131 .we now show that inlineform132 describes an ellipse , and we determine its semiaxis inlineform133 and inlineform134 .we consider , without loss of generality , the case where inlineform135 .this simply means that we align inlineform136 on inlineform137 .we then determine inlineform138 and inlineform139such that displayform0using equation ( eqref37 ) for inlineform140 , we find displayform0hence we see that the third line of the magnification matrix inlineform141 deforms a disc into an ellipse and consequently it induces an additional shear effect .since this new contribution does not derive from a scalar potential , as the usual component , it can generate b - modes .peculiar motion constitutes therefore an intrinsic source of b - modes in cosmic shear .moreover , contrary to the b - modes ' contribution from source redshift clustering  that peaks at small scales , the velocity contribution is expected to peak at rather large scales , where peculiar velocity correlations are larger .however , this effect is second order in the velocity differenceinlineform142 .it is therefore too small to be detected by current and future experiments and consequently to be responsible for the observed b - modes   .in the following we can therefore safely neglect it with respect to the standard shear components inlineform143 and inlineform144 and reduce the magnification matrix to the usually considered inlineform145 submatrix .note that in this calculation we did not take into account the effect of the potential , which induces an integrated sachs - wolf term , inlineform146 in equation ( ) .however , this term is much smaller than the peculiar velocity contribution( see e.g.   ) and can be neglected .hence , the effect of the third line on the shape of the galaxy reduces to a purely kinematic effect , which can also be understood as length contraction of the galaxy in the velocity direction .\n\nthe velocity contribution to the convergence.: we evaluate now the convergence inlineform147 .the various terms in equation ( eqref29 ) are very similar to the one affecting the luminosity distance perturbations .in   , we have estimated all these terms and we found two dominant contributions : the lensing term and the source peculiar velocity term .we neglect hence the other terms here .among them , one finds the effect of peculiar velocity of the lenses , which corresponds to the gradient of the potential in equations ( ) and ( eqref28 ) .those terms which may be relevant in intermediate lensing ( see e.g.   and references therein ) are completely subdominant in weak lensing .therefore in the following we restrict our calculations to the two componentsdisplayform0where displayform0the convergence can be measured through the modifications it induces on the galaxy number density at a given flux .let us introduce the magnification displayform0the magnification modifies the size of an observed source :inlineform148 , where inlineform149 is the true angular size of the source and inlineform150 is the solid angle measured by the observer , i.e. the size of the image .the lensing term inlineform151 is always positive and consequently it always magnifies the source .on the contrary , the velocity term inlineform152 can be either positive or negativeand it therefore either magnifies or demagnifies the source .the sign of inlineform153 depends on the sign of inlineform154 and on the sign of inlineform155 .to fix the ideas , let us consider a galaxy moving toward us .then inlineform156 , since inlineform157 represents the photon direction , which points to the observer .moreover , the sign of inlineform158 depends on the redshift of the sourceinlineform159 .in a inlineform160 cdm universe with inlineform161and inlineform162 , we have inlineform163 for inlineform164 and inlineform165 for inlineform166 .hence for small inlineform167 the surface is demagnified ( inlineform168 ) and for large inlineform169 it is magnified ( inlineform170 ) .this is caused by the change in redshift induced by the source peculiar velocity .indeed , for a fixed redshift , a source moving toward us is more distant ( in conformal time for example ) than a source with null peculiar velocity .this generates two opposite effects on the observed solid angle .on one hand , a distant galaxy is observed under a smaller solid angle .and on the other hand , since its conformal time is smaller , its scale factor is also smaller .consequently , the image experiences more expansion when coming to us .at small redshift the first effect dominates , leading to a demagnification of the source , whereas at large redshift the second effect dominates and the source is magnified .at inlineform171 , both effects compensate , leaving the size of the source unchanged .the situation is then simply reversed for a source moving away from us .we evaluate now the effect of magnification ( or demagnification ) on the galaxy number density .we consider inlineform172 unlensed galaxies per unit solid angle at a redshift inlineform173 and with a flux in the rangeinlineform174 .the magnification modifies the flux measured by the observer , since it modifies the observed galaxy surface .it modifies also the solid angle of observation and hence the number of galaxy per unit of solid angle .these two effects combine to give a galaxy number overdensity   displayform0here inlineform175 , where inlineform176 is the number of galaxies brighter than inlineform177 and inlineform178 is the flux limit adopted .hence inlineform179 is an observable quantity   .recent measurements of the galaxy number overdensity inlineform180 are reported in   .the challenge in those measurements is to eliminate intrinsic clustering of galaxies , which induces an overdensity inlineform181 much larger than inlineform182 .one possibility to separate these two effects is to correlate galaxy number overdensities at widely separated redshifts .one can then measure inlineform183 , where inlineform184 is the redshift of the sources and inlineform185 is the redshift of the lenses .recently , the authors of   proposed to remove close pairs of galaxies at the same redshift from the signal in order to eliminate inlineform186 .this allows then to measure inlineform187 , either for inlineform188 , or for inlineform189 , i.e. for galaxies situated at the same redshift but in different directions .this method requires of course to know precisely the redshift of the galaxies .the velocity contribution inlineform190 has only an effect on inlineform191 .the correlations between inlineform192 and inlineform193 are indeed completely negligible and hence the source peculiar velocity does not affect inlineform194 .in the following we study in detail the contribution of peculiar motion to inlineform195 .the two components of the convergence inlineform196 and inlineform197( and consequently the galaxy number overdensity ) are functions of redshift inlineform198 and direction of observation inlineform199 .we can therefore determine the angular power spectrum displayform0the coefficients inlineform200 contain two kinds of terms induced by inlineform201and inlineform202 .the cross - term inlineform203 vanishes since inlineform204 contains only fourier modes with a wave vector inlineform205 perpendicular to the line of sight ( see eq .( eqref42 ) ), whereas inlineform206 selects modes with wave vector along the line of sight ( eq .( ) ) .the velocity contribution is displayform0here we neglect the peculiar velocity of the observer inlineform207 which gives rise only to a dipole .we use the fourier transform convention displayform0with the solution of the continuity equation   displayform0where inlineform208 is the density contrast , inlineform209 is the growth function , and inlineform210 its derivative with respect to inlineform211, we find displayform0here inlineform212 is the density contrast at horizon and inlineform213 is the transfer function defined through   displayform0where inlineform214 is the primordial power spectrum .we want to compare this contribution with the usual contribution coming from the potentialinlineform215 displayform0where inlineform216 is the lensing kernel .we evaluate inlineform217 and inlineform218 in a inlineform219 cdm universe with inlineform220 , inlineform221 and inlineform222 .inlineform223 can be measured from the sachs - wolf plateau   .we find inlineform224   .we use the bbks transfer function   ( see also   which proposes a similar fit ) .in fig .figref52 - figref55 , we plot inlineform225 and inlineform226 for different redshifts , but with inlineform227 .the amplitude of inlineform228 and inlineform229 depends on inlineform230 , which varies with the redshift of the source , the flux threshold adopted , and the sky coverage of the experiment   .since this term influences inlineform231 and inlineform232 in the same way we do not include it in our plot .generally , at small redshifts , inlineform233 is smaller than 1 and consequently the amplitude of both inlineform234and inlineform235 is slightly reduced , whereas at large redshifts inlineform236 tends to be larger than 1 and to amplify inlineform237and inlineform238   .however , the general features of the curves and more importantly the ratio between inlineform239 and inlineform240 are not affected by inlineform241 .figures figref52 and figref53 show that inlineform242 peaks at rather small inlineform243 , between 30 and 150 depending on the redshift .the behavior of inlineform244 is different , since it increases with inlineform245 ( fig . figref54 and figref55 ) .hence , peculiar motion of galaxies generates additional correlations that peak at relatively large angleinlineform246 arcmin .it is therefore important to have large sky surveys to detect this effect .the relative importance of inlineform247 and inlineform248 depends strongly on the redshift of the source .at small redshift , inlineform249 , the velocity contribution is about inlineform250 and is hence larger than the lensing contribution which reaches inlineform251 .at redshift inlineform252 , inlineform253 is about 50 inlineform254 of inlineform255 , whereas at redshift inlineform256 , it is about 1 inlineform257 of inlineform258 .then at redshift inlineform259 and above , inlineform260 becomes very small with respect to inlineform261 : inlineform262 .this fast decrease of inlineform263 is a consequence of the behavior of inlineform264 plotted in fig .figref56 .we see that at redshift inlineform265 ,inlineform266 vanishes , due to the fact that inlineform267 , as explained above .finally , for inlineform268 , inlineform269 and consequently inlineform270 start to increase as a function of inlineform271 ( fig . figref53 ) .however , the lensing term inlineform272 increases faster than the velocity term and hence the ratioinlineform273stays small , even at redshift 4 where it reaches a few inlineform274 .we have also calculated inlineform275 for inlineform276 .we found that it decreases very rapidly with the redshift difference , and hence it gives a negligible contribution to correlations between different redshift bins .on the contrary , inlineform277 is not very sensitive to the redshift difference and induces therefore correlations at different redshifts .to summarize , we see from fig .figref52 and figref53that a lensing survey must satisfy three criteria in order to detect the velocity contributioninlineform278 .first it has to cover a rather large part of the sky , since the velocity contribution peaks at angles between 70 arcmin and 6 degrees (depending on the redshift of the source ) .ongoing and future surveys fulfill this requirement .for example , the cfhtls wide survey has already spanned 57 square degrees of the sky ( over three independent fields ) and allowed consequently to measure the two - point shear statistics from 1 arcmin to 4 degrees .and in the near future , measurements will be extended up to 8 degrees   .future surveys are even more ambitious .for example , euclid and the ska plan to cover up to inlineform279 square degrees .the requirement of a wide field survey is also of great importance for shear measurements .it is necessary in order to , on one hand , beat cosmic variance , and on the other hand probe accurately the linear regime of perturbations .second , in order to measure precisely the galaxy number overdensity , one needs to remove intrinsic clustering .one way to perform this , consists simply of removing from the signal close pairs of galaxies at the same redshift , as proposed in   .this requires one to measure the redshift of the galaxies .the ska offers here a great advantage , since it can measure with high precision the redshift of galaxies from 21 cm emission line wavelength .most other future lensing surveys will deliver photometric redshift measurements of the observed galaxies .this is indeed also crucial for cosmic shear observation .first it allows , as for magnification measurements , to remove close pairs of galaxies , in order to reduce the systematic noise due to intrinsic alignment of galaxies in the same cluster   .second , redshift information permits one to perform 3d cosmic shear analysis .finally , fig .figref52 shows that the velocity contribution is mainly important at redshift inlineform280 .hence an ideal survey should cover redshifts from 0.2 to 1 .this is well within the range of ongoing and future experiments .the accuracy with which the velocity contribution can actually be measured as well as the exact redshifts range where it is detectable depend of course of the precision of the survey .in   , measurements of the magnification autocorrelations by the ska are discussed in detail .the autocorrelations are calculated for redshifts inlineform281 .since at redshift 1 , our velocity contribution is of order inlineform282 of the standard term , it should be measurable by the ska if , as expected , an accuracy of inlineform283 is reached .at larger redshifts , the velocity contribution decreases quickly and will hence not be detectable .however , the ska should be able to measure the velocity contribution at smaller redshifts .indeed , at small redshift inlineform284 , the velocity contribution is rather large , of the order inlineform285 .hence between redshiftinlineform286 , the velocity contribution should be measurable .between redshiftinlineform287 , a large number of galaxies ( inlineform288 ) are expected to be detected by the ska, hence good statistic should be achieved in this redshift range .of course , the amplitude of the signal is weighted by inlineform289 , which is not included in fig .figref52 and figref53 .at very small redshift , inlineform290 can be small , and even negative .if inlineform291 , the amplitude is for example reduced by 4 .the value of inlineform292 depends on the features of the survey : sky coverage , selection threshold , redshift of the galaxies , etc ...hence one can optimize this value to detect the velocity contribution .\n\nnonlinear contribution: until here , we have only considered peculiar velocities from linear theory , where equation ( eqref48 ) holds .however , on small scales , galaxies ' peculiar velocities do not obey linear theory anymore .typically , galaxies in a cluster can have peculiar velocities of the orderinlineform293 km / s  .equation ( eqref46 ) becomes then displayform0the amplitude depends on the prefactor inlineform294 plotted in fig .figref56 , and on inlineform295 .hence the nonlinear contribution is large up to redshift inlineform296 , where it is still of the order of inlineform297 , if we take inlineform298 .then between inlineform299 and inlineform300it becomes very small .but for inlineform301 the signal is again non - negligible and reaches even inlineform302 at inlineform303 .however at those redshifts , we do not expect to find clusters of galaxies .moreover , the nonlinear velocity contribution is large only on very small scales and it should become negligible when one removes close pairs of galaxies at the same redshift from the signal , as proposed in   .\n\nthe reduced shear: in section secref4 we have established that peculiar motion contributes at second order to the shear and is therefore too small to be detected .however , since what is actually observed is not the shear , but the reduced shear   displayform0it is necessary to investigate the effect of peculiar motion on inlineform304 .the reduced shear correlations are given by displayform0the corrections inlineform305 have been computed in   .they are large enough to impact on cosmological parameter estimation from future experiments .however , one can show that the velocity induced corrections inlineform306 vanish .indeed inlineform307 contains only fourier modes with a wave vector inlineform308 perpendicular to the line of sight ( see eq .( eqref25 )and ( ) ) .on the other handinlineform309 selects modes with wave vector along the line of sight ( eq .( ) ) . hence correlations between inlineform310 and inlineform311 vanish and we have displayform0therefore peculiar motion does not affect the reduced shear correlations at first order in inlineform312 .\n\nrelation between shear and convergence: in the usual description of weak lensing , the shear and the convergence satisfy a functional relation .they are indeed both related to second order derivatives of the potential along the line of sight .in the flat sky approximation , we have displayform0where displayform0here inlineform313 is a two - dimensional angular vector describing the position of the source in the flat sky approximation , and inlineform314 is the associated two - dimensional gradient .equation ( eqref64 ) can be solved to express inlineform315 as a function of inlineform316 .inserting the result into equations ( ) and ( ) leads to the following relation between inlineform317 and inlineform318( see e.g.   )displayform0where displayform0the two - dimensional fourier transform of the shear and the convergence are therefore related through inlineform319 , where inlineform320 is the polar angle of inlineform321 .consequently , the two - dimensional power spectrum of the convergence , inlineform322 and of the shear , inlineform323 are equal .a similar relation holds in the all sky calculation , where the angular power spectra satisfy   displayform0these relations are modified by the velocity contribution .galaxies ' peculiar velocities generate indeed a new contribution to the convergence , inlineform324 that is not related to the potential inlineform325 .on the other hand , it does not change the shear at first order .hence , in the flat sky approximationthe measured shear inlineform326 and convergence inlineform327 obey displayform0since the correlations between inlineform328 and inlineform329 vanish , the power spectra satisfy displayform0similarly in the all sky calculation , we have displayform0where we have used equation ( eqref44 ) for the second equality sign .consequently , if one measures both the shear inlineform330 and the magnificationinlineform331 as functions of the redshift , equations ( eqref71 ) allows one to extract the peculiar velocity contributioninlineform332 .this provides a new way to measure directly peculiar velocities of galaxies .future surveys , like euclid and the ska should be able to deliver measurements of both the shear and the magnification in the redshift range inlineform333 .since at those redshifts the difference between the velocity contribution and the potential contribution is at least of the percent level , it seems feasible to extract peculiar velocities from the measurements of inlineform334 and inlineform335 .a direct measure of the peculiar motion of galaxies would be extremely interesting , since it allows one to determine the underlying matter power spectrum .moreover , since the velocity contribution inlineform336 peaks at rather large angles , it provides a measurement of the velocity field well inside the linear regime , where the relation between peculiar velocity and matter overdensity is simply given by equation ( eqref48 ) .a more careful analysis is of course necessary to determine if this method can compete with actual or future observations of peculiar velocities , from galaxy surveys ( see e.g.   and references therein ) , supernova surveys   or from the kinetic sunyaev - zel'dovich effect in the cosmic microwave background( see e.g.   ,   and references therein ) .\n\nconclusions: in this work we have studied the effect of peculiar velocity on weak gravitational lensing .we have derived a general formula for the shear and the convergence , that takes into account all relativistic effects of linear perturbation theory .we have identified a new important contribution generated by the peculiar motion of galaxies .we have shown that the shear component is affected only at second order by peculiar velocity .consequently this contribution does not affect cosmic shear in a measurable way .however , we have found that the effect of peculiar velocity on the convergence is important and can not be neglected , especially for redshiftinlineform337 .at small redshifts inlineform338 , the peculiar velocity contribution is even larger than the lensing contribution .hence measurements of the convergence ( or more particularly of the magnification ) at small and intermediate redshifts are affected by the peculiar motion of galaxies .in the redshift range inlineform339 we expect an effect large enough to be detected by future galaxy surveys , like , for example , the ska and euclid .we have also shown that peculiar motion modifies the relation between cosmic shear and convergence .one way to measure the effect of peculiar velocity would hence consist in measuring both the shear and the convergence at the same redshifts , and in comparing them to extract the velocity contribution .this provides hence a new way of measuring the velocity field directly .finally , we have found that the redshift dependence of the velocity term is mainly given by the prefactor inlineform340 , plotted in fig .figref56 .since this function depends directly on cosmological parameters , it would be very interesting to find a way to extract it from the data , in order to constrain cosmological models .i would like to thank marc - olivier bettler , ruth durrer , pedro ferreira , and antony lewis for useful and stimulating discussions and comments on the first draft of this manuscript .this work was supported by the swiss national science foundation .",
      "target_text": "we study the effect of peculiar motion in weak gravitational lensing .we derive a fully relativistic formula for the cosmic shear and the convergence in a perturbed friedmann universe .we find a new contribution related to galaxies peculiar velocity .this contribution does not affect cosmic shear in a measurable way , since it is of second order in the velocity .however , its effect on the convergence ( and consequently on the magnification , which is a measurable quantity ) is important , especially for redshifts z<1 .as a consequence , peculiar motion modifies alsothe relation between the shear and the convergence .",
      "output_text": "a direct probe of the large-scale structure and its evolution over cosmic time .in this article , we summarize the recent progress in the measurement of the cosmic convergence , focusing in particular on the recent results from the european cosmic survey ( euclid ) and the large sky area telescope ( lsst ) .\n\nmethodology: the convergence can be measured in two ways : through the correlation function of galaxies and quasars , and through the auto-correlation function of galaxy number density .the correlation function is the Fourier transform of the convergence field , and it provides a measure of the correlation between galaxies and their environment .the auto - correlation function measures the correlation of the number density of galaxies with its environment .these two measurements are complementary and can be used to constrain cosmological parameters , such as the matter density , the baryonic density , and the cosmological constant .the recent results of the eusclid and lsst surveys are summarized in inlineform3 .in inlineform4 , we provide a summary of the main results of these surveys and their implications for the cosmology of dark matter and dark energy .\nconclusion: the measurement and characterization of cosmic lens convergence is a powerful tool to probe the structure and evolution of the dark matter , dark energy , and large scale structure .the upcoming european and american cosmic surveys will provide a wealth of information on these topics , and they will be crucial for the development of cosmology in the next decade .\nabstract: cosmic dark matter is the dominant component of the matter content of our universe , but its nature is still not fully understood .dark energy , on the other hand , is a mysterious force that is responsible for the acceleration of the expansion of the observable universe .the cosmic microwave background radiation ( cmb ) is the most direct and well - measured tracer of these two phenomena .the cmb is the remnant radiation left over from the big bang , and its temperature and polarization are directly related to the energy density and the expansion rate of the early universe .in recent years , cosmologists have been able to use the cmb as a tool to study the properties of dark energy and dark matter .cosmological measurements of the cmsb have provided important constraints on the equation of state ( eos ) of the cosmologically relevant dark energy component , as well as on the nature of the primordial density fluctuations that gave rise to the large scale structures that we observe today .\nhowever , cosmic expansion is not homogeneous and is characterized by a non - trivial distribution of mass and energy .this distribution is determined by the evolution history of the underlying matter content , which in turn is shaped by the interaction between dark matter ( dm ) and baryons ( b ) .the dm - b interaction is mediated by dark matter haloes , which are defined as the regions where the density of dm exceeds a certain threshold .the halo mass function ( hmf ) describes the probability distribution of halo masses as a function of redshift and halo virial mass .the virial radius of a halo is the radius at which the halo density is equal to the critical density of the Universe at the redshift of its formation .the mass function describes the number of halos of a given mass within a given redshift interval .\nin the last decade , the study of the mass function has become increasingly important in cosmology , as it provides important information on the evolution and properties of the dm halo population .in particular , it has been used to infer the mass of the present-day dm , and to estimate the fraction of the total mass in dm that is currently in the form of cold dark matter  ( cdm ) .this fraction is known as the cold dm fraction ( cdf ) and is a crucial ingredient in the determination of the density parameter , \u03a9m , of the standard model ( sm ) of particle physics .\nthe cdf has been measured using a variety of methods , including halo occupation distribution ( hod ) , halo abundance matching ( hamm ) , and semi-analytic models ( sams ) .in lineform5 , we present the latest results from these and other methods , and we discuss the implications of these measurements for the dark - matter content and evolution .we also provide a brief overview of the ongoing efforts to measure the cdf directly , using the large halo finder ( lhf ) , the weakly interacting massive particle ( wimps ) halo model ( whm ), and other techniques ."
    },
    {
      "input_text": "Title: Viscosities and shift in a chiral superfluid: a holographic study\nDomains: Physics\n\nintroduction: the promise of providing a framework to construct majoranna fermions and its potential application to fault tolerant quantum computing has made high temperature chiral superfluids an attractive subject of study in recent years   .while traditional superconductivity is well understood via the bcs pairing mechanism , high temperature superconductivity can not be explained by conventional electron - phonon interactions that dominate the pairing mechanism in bcs .there has been much advancement in the understanding of these systems however a universal understanding which can explain different physical aspects is not currently in hand .as an example , the stress response at finite temperature has not been fully explored .given the possible practical application of these systems in quantum computing , it is important that their tensile properties be fully analyzed and understood .one possible venue for arriving at universal predictions is by considering the effective field theory ( eft ) that governs the dynamics at very low temperature and energies .the main guiding principle of this approach is the underlying symmetries of the system .for example , if we consider consider a superfluid system controlled mainly by a quantum critical point with lorentz invariance , the eft must also be lorentz invariant .these symmetries are often not powerful enough to completely constrain the low energy dynamics of the system , however , in some cases when combined with topological data they can provide predictions that are either universal or can relate various transport coefficients .this approach was applied to superfluid systems at zero temperature in   .in particular it was shown that the ratio of hall viscosity to the superfluid density can be determined by topological considerations , i.e. it is given by the superfluid shift , which relates the ground state vortex number of the system to the spatial topology .specifically , the ratio of hall viscosity to superfluid density is equal to inlineform0 for inlineform1 superfluid .however , by their very essence , these analyses are not expected to be valid at finite temperature and since they rely on an action principle , they also can not describe any dissipative physics .traditionally , in areas of condensed matter physics where a careful first principle analysis is not available or difficult , holography has stepped in to provide valuable intuition by providing access to a very different set of universality classes than that of weakly interacting quasiparticles .since these systems are the result of deforming conformal theories , the inherited conformal symmetry further constrains the transport properties of the system .in this paper we use a holographic model to compute the stress response of relativistic chiral superfluids .the model we consider is einstein - yang - mills with group inlineform2 where , after breaking inlineform3 the w - bosons in the bulk provide a charged vector operator in the boundary .studying stress response requires looking at the system away from the probe limit ( where the charged and neutral sectors decouple )and so we must allow for backreaction .we also analyze the electronic responses that were previously computed in the probe limit and discuss how they change .the main result of this analysis is that the ratio of hall viscosity to superfluid density derived in the efts persists at finite temperature all the way to inlineform4 .the outline of the paper is as follows .in section 2 , we review the main results of the effective field theory that governs the dynamics of the system at zero temperature .in section 3 , we discuss the background geometry of the system and analyze the behavior of various background quantities .at low temperatures the system develops a new scaling symmetry with nontrivial dynamical critical exponent inlineform5 .in section 4 , we calculate hall and shear viscosities and conductivities .we conclude in section 5 .\n\nreview of effective field theory predictions: in this section we review some of the results from the effective theory description of chiral superfluids that holds at zero temperature   .we work in inlineform6 dimensions .defining the dual gauge field inlineform7 as the hodge dual of the superfluid current inlineform8 , the action up to first order in derivative expansion is : displayform0where inlineform9 is the electromagnetic potential , the number density inlineform10 is defined as inlineform11 , inlineform12 gives the energy density and inlineform13 is an undetermined function of the number density .finally , the current inlineform14 is the euler current   ,   : displayform0where inlineform15 is the normalized direction of the superfluid current inlineform16 .we note that the total charge associated to the euler current on a spatial section is a half of the euler characteristic of the surface   .it is important to note that since inlineform17 is the dual of the superfluid current , its charge counts the vortex number in the superfluid .by taking a variation of the action ( eqref2 ) with respect to inlineform18 , we can see that there is a relationship between the vortex number , the total flux and the euler characteristic of the space : displayform0this is in fact a constraint built into the effective action from topological considerations   ,   and in the case of a inlineform19 superfluid , it can be summarized as the necessary relaionship between the flux and the topology such that the vector order parameter can be smoothly defined on the entire manifold .in terms of the effective theory parameters , this means : displayform0defining the superfluid shift inlineform20 as the net flux required to have no vortices when the superfluid is placed on a sphere , we see that inlineform21 for inlineform22 .of particular interest are the predictions of this effective action with regards to the hall conductivity and viscosity at zero frequency .for the inlineform23 case , displayform0  while the prediction for the hall viscosity is universal , the hall conductivity depends on the non - universal function inlineform24 .requiring the action to be weyl invariant fixes the this function to be linearinlineform25and we get :displayform0in what follows , we verify these predictions in the holographic setup and find that the hall viscosity result is in fact robust at finite temperature .\n\nholographic chiral superfluids: in this section we review the standard construction of holographic chiral superfluids   .the bulk theory is einstein - yang - mills with group inlineform26 , where by turning on a chemical potential for a generator inlineform27 we explicitly break the global symmetry group of the boundary theory to inlineform28 .the w - bosons in the bulk provide us with natural charged vector operators in the boundary theory , which we use to construct a inlineform29 order parameter spontaneously breaking the remaining inlineform30 .this spontaneous symmetry breaking is vector - like and breaks parity and time reversal .\n\nthe superconducting phase: consider einstein - yang - mills theory in asymptotically inlineform31 space : displayform0where inlineform32and we chose inlineform33einstein 's equations are simply displayform0and the yang - mills equation is displayform0in what follows it will be advantageous to work with complex coordinates and generators , displayform0our normal phase is the standard reissner - nordstrom black hole , displayform0in this normal phase , the non - normalizable chemical potential explicitly breaks inlineform34 down to inlineform35 .at low enough temperature and large enough charge there may be a dynamical instability to developing vector hair .consider the following ansatz : displayform0this is invariant under a combined rotation and gauge transformation displayform0the equations of motion for the background fields are independent of chirality and reduce to displayform0 displayform1note that our ansatz has two scaling symmetries   , displayform0 displayform1by considering perturbations of inlineform36 on the reissner - nordstrom background and looking for normalizable solutions we can extract the critical temperature as a function of inlineform37 , which we show in figure figref24 .we find that there is a critical value of the coupling inlineform38 where the critical temperature vanishes .when considering the system at finite temperature we look for solutions with a regular horizon corresponding to inlineform39 vanishing linearly at inlineform40 and we will pick a gauge where inlineform41 as well .asymptotically the fields behave as displayform0 displayform1following the standard holographic dictionary we interpret inlineform42 as the chemical potential and inlineform43 corresponds to an external source for the nonabelian current whose expectation value is displayform0to have spontaneous inlineform44breakingwe consider only solutions with inlineform45 the entropy , temperature , energy density and total charge density are displayform0we can define the normal fluid charge density via the flux on the horizon and similarly the superfluid charge density as the difference between the total and the normal fluid charge   , displayform0plots of the superfluid density are given in figure figref30 .as expected , the ratio of superfluid to total charge goes to one at zero temperature and vanishes linearly at inlineform46 as in mean field theory .we should note that defining the superfluid density through the residue of the zero frequency pole of various correlators can be misleading .for example the inlineform47 pole only agrees with our definition at zero temperature , and even above inlineform48 the pole is nonzero as our system is exactly translationally invariantso there is infinite dc conductivity .while we strongly suspect that the definition we use for superfluid density will agree with the normalization of the goldstone two - point function , we leave confirming this to future work .\n\nlow temperature and the lifshitz throat: at very low temperatures the geometry develops a lifshitz throat .we can most easily see this after noticing that at low temperatures the solutions behaves very similarly to an s - wave holographic superconductor , where most of the electric charge in the solution is carried in the hair outside of the black hole and not on the horizon itself   .in the zero temperature limit , the degenerate horizon carries no charge and has vanishing area .in the extreme near - horizon limit , we expect a scaling solution with inlineform49 .examining the equations of motion with inlineform50 and again using the dimensionless coupling inlineform51we find the solution displayform0where inlineform52 is the real root of the cubic equation displayform0and should not be confused with the complex coordinate on the plane .note that a positive root exists for any real inlineform53 and inlineform54 .one can also check that the coefficient in front of inlineform55 in ( eqref34 ) is always positive .we plot inlineform56 in figure figref37 .this throat has an anisotropic lifshitz scaling symmetry   , displayform0from this lifshitz throat we can turn on a perturbation in inlineform57 , which ( at zero frequency and momentum ) can have scaling behavior displayform0the inlineform58 mode diverges at small inlineform59 and vanishes at large inlineform60 , while the inlineform61 mode vanishes at small inlineform62 and diverges at large inlineform63 .we can therefore turn on a inlineform64 -type perturbation and its backreaction will flow us to inlineform65 at large inlineform66 .we can also consider relevant perturbations in the other background field modes .there are normalizable static perturbations of inlineform67 which have the following behavior at large radius : displayform0such an asymptotically lifshitz solution has a mass density displayform0if we consider an asymptotically lifshitz black hole at finite temperature , it must have inlineform68 , and we can use the scaling symmetry ( eqref23 ) to argue that displayform0which can be repackaged into a more familiar form displayform0as expected for a fixed point with dynamical critical exponent inlineform69 .the numerical evaluation of these quantities is given in plot figref43 and matches this scaling .we note that due to numerical difficulty , the smallest value of inlineform70 that we considered was inlineform71 .\n\nsuperfluid on a sphere: the superfluid shift , defined in   for relativistic superfluids in 2 + 1 dimensions , is the net flux required to have no vortices when the superfluid is placed on a sphere .for a chiral p - wave superfluid with charge equal to 1 , the shift is related to the chirality : displayform0as the holographic model under consideration is meant to describe a inlineform72 superfluid , we may ask whether or not it can reproduce this result .the answer it that it indeed does .first , as the arguments for this constraint are purely topological they would straight - forwardly apply to the holographic setup as well .however , putting this system on a sphere , one finds the constraint is also embedded in the bulk equations of motion .to see this , we look for vortex - free solutions in asymptotically global ads .parts of the calculation are simpler in projective coordinates , where the sphere metric is given by : displayform0we also need to turn on a constant magnetic flux through the sphere given ( in the upper hemisphere ) by : displayform0we generalize the ansatz ( eqref16 ) for the sphere such that it retains the same rotation properties about the north pole as flat space : displayform0the full ansatz for vortex free solutions is displayform0plugging this into the equations of motion , we find that the bulk yang - mills equations constrain both inlineform73 and inlineform74 .first , looking at the inlineform75 component , we find the constraint displayform0and from the inlineform76 component we find displayform0which gives the nontrivial constraint displayform0verifying our prediction from more general efts ( eqref47 ) , as well as a functional form for inlineform77 , displayform0in terms of spherical coordinates and standard generators , the ansatz is ( again only valid in the upper patch ) : displayform0viewed from above , this corresponds to an order parameter configuration which is pointing in the same direction across the entire patch .with this ansatz one can work out the background equations of motion as a set of odes .they are similar to those in planar coordinates with additional terms coming from the radial slicing curvature and the magnetic field .solutions with spontaneous symmetry breaking still exist below a critical temperature and at large enough chemical potential .note that due to the magnetic field at low temperatures on the sphere the system will develop a inlineform78 near horizon geometry instead of a lifshitz throat .\n\ntransport: to study transport properties we look at perturbations on top of the background discussed in the previous section .we will only consider finite frequency but zero spatial momentum perturbations of the form inlineform79 .this will allow us to separate the scalar , vector and tensor sectors following the mode decomposition of   .for the sake of brevity , we restrict to the case of inlineform80 .since time reversal switches the chirality of the vev , the results for inlineform81 can be readily derived from what follows by taking inlineform82 and taking the complex conjugate of the fields .\n\nviscosity and tensor perturbations: in this section we calculate the shear and hall viscosity of our system ( conformal symmetry causes the bulk viscosity to vanish ) .to caclulate the stress viscosity transport coefficients , we look at metric perturbations which give us boundary stress response   .more explicitly , metric fluctuations behave asymptotically as displayform0here we have picked the gauge inlineform83and so inlineform84 runs over inlineform85 .when inlineform86 is the only nonnormalizable component that is nonzero we have the stress response , displayform0to measure the hall and shear viscosities , consider a tensor perturbation where the only nonnormalizable perturbation turned on is inlineform87displayform0  how do such perturbations behave in the superfluid phase ?the tensor modes on the inlineform88 background are displayform0the linearized equations take the form displayform0where displayform0 displayform1consider the solution which behaves asymptotically as : displayform0the final formulae for the viscosities are displayform0we first look at the hall viscosity , which we compute by numerically integrating the equations of motion and using the formulae ( eqref66 ) .the hall viscosity vs temperature results are given in plot figref68 a.we see that its magnitude increases as we approach zero temperature .normalizing hall viscosity value by the superfluid density( figure figref68 b ) , we see that the ratio equal to inlineform89 ( inlineform90 , within the numerical error we work at ) over the entire temperature range and for all values of the coupling constant .this is the behavior that was predicted at zero tempereature from an effective field theory ( eqref7 ) .here we see that its validity is more general and implies that at finite temperature , there is no contribution to hall viscosity coming from the normal fluid sector .this is not surprising , as our normal fluid does not break parity ( see   for a holographic model of a normal relativistic fluid which exhibits hall viscosity ) .we do not have an analytic proof that inlineform91but suspect that it should be possible , likely in a manner similar to the proof of the shear viscosity bound   .a possible way of understanding this ratio is to note that the ratio of the hall viscosity to the \u201c orbital angular momentum per particle \u201d has been shown to be equal to 1/2 in gapped or topological phases at zero temperature   .however , if we consider the fact that the vector - like order parameter carries angular momentum equal to one , then the superfluid density would be equal to the orbital angular momentum per particle and our numerical resultcan be considered as a generalization of the viscosity - angular momentum relationship .the plots for shear viscosity vs. temperature at various values of the coupling constant can be seen in figure figref72 a. as expected this dissipative effect vanishes in the zero temperature limit .near inlineform92 , where the background geometry is reissner - nordstrom , we know that the ratio inlineform93 .the plot of this ratio at other temperatures is given in figure figref72b.we see that as the temperature is reduced , this ratio increases , satisfying the bound   .however , very close to the zero temperature limit the ratio starts to decrease again .we do not understand the origin of this dip .however , we can deduce that it must be coming from subleading terms as the shear viscosity and entropy must have the same scaling behavior in the ir lifshitz fixed point .\n\nconductivity and vector perturbations: we consider the six following vector modes with harmonic time dependence : displayform0where we have gauged away the other vector modes .we are interested in calculating the electric conductivity , defined by displayform0it is useful to work in the chiral / antichiral basis as these modes decouple from eachother .displayform0this allows us to directly compute the eigenvalues of the conductivity matrix , displayform0our bulk modes are similarly organized as displayform0defining displayform0the inlineform94 and inlineform95 modes are completely decoupled .in what follows , we restrict the discussion to the inlineform96 modes .the linearized equations for the inlineform97 modes are given by : displayform0where displayform0where displayform0 displayform1at large radius , the fields ( eqref81 ) will be of the form displayform0 displayform1it is important with these perturbationsdo not only turn on a linearized non - normalizable inlineform98 by way of inlineform99 but alsopossibly inlineform100 and inlineform101 .these may be removed by a linearized gauge transformation   and diffeomorphism and do not change the equations of motion .however , they affect the formulae for conductivity .consider a linearized gauge transformation followed by a diffeomorphism displayform0which we fix by requiring after the gauge transformationinlineform102 .this is done via displayform0after this fixing we find the conductivity is displayform0where we have normalized by the value of the conductivity at inlineform103 , displayform0since we are interested in backgrounds with spontaneous symmetry breaking where inlineform104 , these formulae simplify andwe have : displayform0the conductivity for the anti - chiral modes is derived from this by complex conjugation and taking inlineform105 : displayform0the typical plots for the spectral densities can be seen in figure figref96 .we note that these are qualitatively the same as their strict probe counterparts in   .we see that there is a pseudogap , i.e. a depletion of states as we approach zero temperature , which is a characteristic of holographic superconductors .the respective plots for the conductivities can be seen in figure figref100 .near inlineform106 , where the order parameter vanishes , parity is restored , which implies inlineform107 and inlineform108 are equal .this implies that the dc conductivity must vanish .by comparing the values of inlineform109 to the superfluid density in the zero temperature limit , we can read off the coefficient of the non - universal inlineform110 term in the effective field theory ( eq .( eqref8 ) ) .in the probe limit , this ratio is exactly equal to one .turning on the back reaction of the geometry , we see that for large values of inlineform111 , the deviation from probe goes as inlineform112 .a fit to the ratio for various inlineform113 reveals that inlineform114 .as expected , this coefficient is non - universal and depends on the details of the theory and can also vary by temperature .we suspect that this is the reason why unlike the ratio of hall viscosity to superfluid density which is independent of temperature , the same can not be said for hall conductivity .\n\nconclusions and outlook: in this paper we analyzed a chiral superfluid model and computed response functions away from the probe limit .while some characteristics of the system ( e.g. shape of electric conductivity plots ) remain the same , there are some quantities that can only be calculated away from the probe limit .due to the emergent lifshitz geometry that governs the infrared dynamics , many of the thermodynamic variables are quantitatively different .looking at the viscosity response of the system , we found that the hall viscosity to superfluid density ratio matches the zero temperature eft prediction even at finite temperature , as does the superfluid shift .we also computed the shear viscosity and found that the viscosity - entropy ratio respects the holographic bound , but has a feature near zero temperature where it decreases .our results for transport are numerical only and it would be interesting to understand them from a first principle approach .unlike the low energy eft analysis which only kept track of the goldstone degree of freedom , this holographic model has the capacity to describe vortices .while these have been studied in the probe limit near critical magnetic fields   it would be very interesting to study them with back reaction .it would also be interesting to study the structure of bound states that arise on different topologies either due to the vortices created from a mismatch in the magnetic flux or in the presence of boundaries .\n\nacknowledgments: it is a pleasure to thank kathryn levin , eun - gook moon and dam t. son for insightful discussions .this work is supported , in part , by doe grant de - fg02 - 13er41958 .s.g . is supported in part by nsf mrsec grant dmr-1420709 .tocsectionbibliography",
      "target_text": "we consider a holographic model of chiral superfluidity whose bulk is einstein yang - mills and compute viscosity and conductivity responses away from the probe limit .we calculate hall viscosity and analyze its relationship to the superfluid density and the shift .we find that the relationship between these quantities derived from effective field theory at zero temperature persists for all temperatures : for $ p\\pm ip$their ratio is equal to $ \\mp1/2$. at low temperatures the system develops a lifshitz throat , indicating an anisotropic scaling symmetry in the infrared dynamics .",
      "output_text": "rams have been used to provide a framework for understanding the behavior of systems .in this case , the hologram is a 3d space-time geometry that describes the geometry of the space in which the system is embedded .in the context of chiral condensates , the geometry is that of a 4d manifold , which can be embedded in a 5d spacetime .this embedding is determined by the chirality of the condensate and the topology of the manifold .the geometry is described by a metric tensor and a volume form .the volume form can be decomposed into a volume element and a torsion tensor , which is related to the curvature of the spacetime manifold .in chiral systems , the volume form has a non-vanishing torsional component , which describes the rotation of the volume element with respect to the tetrad field .the torsionic component of the metric tensor can be expressed in terms of the chiral order parameter and the topological charge density .the topological density is a measure of the number of zero modes of the order parameter , which are associated with chiral symmetry breaking .the ratio of the topological density to the area of the surface on which it is defined determines the order of the phase transition .the chiral phase transition is characterized by a first order phase transition with a critical exponents that depend on the topological order parameter .the order parameter can be identified with the superposition of vortex and anti-vortex states .the vortex states have a nonzero topological charge , while the anti-vortices have a zero topological charge .thus , the vortex-antivortex pairing can be understood as a pairing of the two components of the supercurrent .the supercurrent is a vector field that couples to the order parameters .the pairing is mediated by the exchange interaction between the two supercurrent components .the exchange interaction can be described by the hamiltonian of a spin-1/2 particle in a magnetic field , which has the same form as the spin Hamiltonian in the presence of an external magnetic field .therefore , the exchange coupling between the supercurrents can be interpreted as a coupling of the spin degrees of freedom to the vector field .in summary , the superconduction system considered in this paper can be viewed as an example of a chirally ordered phase in which vortex pairs are formed and the exchange couplings are mediated through the spin-spin interaction .the existence of a vortex pair is a manifestation of the existence of topological defects in the system."
    },
    {
      "input_text": "Title: Adiabatic mixed-field orientation of ground-state-selected carbonyl sulfide molecules\nDomains: \n\nintroduction: molecular samples with directional order , , oriented molecules , enable the extraction of information directly in the molecular frame , for instance , from photoelectron angular distributions high - order harmonic generation electron and x - ray diffractive imaging and stereochemistry experiments   .for diffraction experiments , data has often to be recorded and averaged over many shots .if the molecules in an ensemble have directional order , a molecular - frame diffraction pattern corresponding to the single - molecule signal above noise can be obtained   .various approaches have been developed to generate oriented molecules , including brute - force orientation using strong dc electric   and magnetic   fields , shaped   ,   and two - color   near - infrared laser pulses , terahertz pulses multi - pulse schemes and mixed laser and dc electric field orientation   .in mixed - field orientation , the non - resonant laser field creates near degenerate doublets that are efficiently oriented by the dc electric field   .however , for the two components of the doublet the dipole moments , and thus the molecules, point in opposite directions , resulting in a reduced or vanishing macroscopic orientation depending on the populations of the two components   .quantum - state selection allows for the preparation of ensembles of molecules all in a single rovibronic state   .strong orientation can be achieved if these populations can be adiabatically transferred to the oriented field - dressed states .according to the adiabaticity theorem   , the field - dressed dynamics are adiabatic if a molecule remains in its eigenstate as the field strength , , the laser intensity , is changed .this condition can be fulfilled for most quantum mechanical systems , including non - resonant adiabatic alignment   , when the hamiltonian evolves sufficiently slowly in time .however , in contrast to adiabatic alignment , adiabatic mixed - field orientation tends to be more challenging , because the energy - spacing within the doublets becomes very small inside the laser field   .here , we present a combined experimental and computational investigation of the degree of orientation of rovibronic - ground - state - selected ocs molecules for various laser intensities and dc electric field strengths .the presented experimental setup allows for the use of comparably strong dc electric fields of 20 kv / cm .the experimental findings are compared to the theoretical description obtained by solving the time - dependent schr\u00f6dinger equation for the mixed - field orientation of the populated states within the state - selected molecular beam .\n\nexperiment: the experimental setup is depicted in fig : experimentalsetup .a supersonic molecular beam was generated by expanding a mixture of 500 ppm ocs seeded in 50 of helium into vacuum through an even - lavie - valve   at a repetition rate of 250 .the beam was collimated by two skimmers , 7.4 and 23.1 downstream from the nozzle .an electrostatic deflector placed 25.9 downstream from the nozzle , dispersed the molecular beam according to its quantum states   .a cross section of the deflector and its electric field are shown in fig :experimentalsetup b. a third skimmer was positioned 1.4 behind the deflector for further differential pumping .the molecules are oriented and probed inside a velocity map imaging spectrometer ( vmi ) consisting of two electrodes   .the control and probe laser pulses with a central wavelength of 800 were provided by an amplified femtosecond laser system   .the temporal profile of the control laser pulse had a sawtooth shape with a slow rising edge ( inlineform0 , 2.5 - 97.5 % ) and a fast falling edge ( inlineform1 ) .we measured the spatial beam profile , in intensity , with a beam profiler ( spiricon sp620u ) , which yields inlineform2 and inlineform3 along the two principal axes of the profile ; the first ( short ) axis is rotated 17 away from the laboratory inlineform4 axis .this resulted in a peak intensity up to inlineform5 .the intensity was controlled by a half - wave plate mounted on a rotation stage in combination with a polarization filter .the degree of orientation was probed through coulomb explosion imaging following multiple ionization of ocs by a 30 fs laser pulse focused down to inlineform6 , which resulted in a peak intensity of inlineform7 .the first principal axis is rotated by 43 towards the laboratoryinlineform8 axis .the relative timing between the control and probe laser pulses was varied with a delay stage positioned in the laser beam path of the probe laser .both laser pulses were linearly polarized with polarization vectors perpendicular to each other .the orientation of both polarization vectors around the laboratory fixed inlineform9 -axis , and , therefore , the angle inlineform10 between the ac and the dc electric fields were simultaneously controlled by a half wave plate .at inlineform11 we achieved the best compromise between the strongest orientation , with its maximum at inlineform12 , and the ideal detection efficiency , with its maximum at inlineform13 .for inlineform14 , the component of the dc electric field parallel to the polarization axis of the controllaser is reduced to inlineform15 .the temporal intensity profile of the chirped control laser pulse has been determined as described in appendix secref7 and is shown in fig :hv - pico - time c. for use in computationswe applied a fourier - transform - based low - pass filter to remove frequencies above 81 ghz in the temporal profile of the pulse , which correspond to the limit of the pixel size of the ccd within the spectrometer ; the resulting pulse is depicted by the blue area in fig : delay a.the deflection of the molecular beam was characterized by vertically scanning the inlineform16 position of the focus of the probe laser pulse across the molecular beam using a corresponding translation of the focusing lens .the integrated ion signal at each position is proportional to the column density at the corresponding inlineform17 position in the molecular beam .fig :deflection shows the measured normalized density profiles of the deflected ( rhombuses ) and the undeflected ( squares )molecular beams .the molecules are deflected to positive inlineform18 values by the interaction of their quantum - state - specific dipole moment with the inhomogeneous electric field .the solid lines represent numerical simulations   ,   of the density profiles for the undeflected ( blue ) and deflected ( green ) molecular beams as well as the individual contributions to the deflected beam by the inlineform19 , 1,0 ,1,1 states in red , brown , and purple , respectively .from these simulations we obtain a rotational temperature of 2 k for the original molecular beam ; this fairly high temperature   is ascribed to the low stagnation pressure and not fully optimized operation conditions of the valve , but is not critical for the investigation performed here .the yellow bar at 0.95 in fig: deflection indicates the position where the orientation experiments were performed .the estimated ground state population at this position was inlineform20 , with the remaining population in the 1,1 state .it was predicted that dc field strengths on the order of inlineform21 are required to achieve adiabatic orientation with 500 ps pulses   .in order to achieve such strong fieldsa two plate velocity map imaging spectrometer  was set up .a sectional view of the electrodes and typical potentials are shown in fig :experimentalsetup c.the two - plate design allows for a much stronger field for a given repeller - electrode potential than for the classical three - plate vmi inlineform22 at inlineform23 80 .in addition , as the magnification of the velocity map scales with inlineform24 , the measured detector images are larger compared to a classical vmi operated at the same electric field strength .velocity - focusing conditions were obtained by positioning the laser focus at a specific inlineform25 position between the two electrodes .this position is independent of the applied repeller voltage , which allows for continuous tuning of without a change of the vmi focusing conditions .the velocity maps are detected by a position sensitive detector , a combination of two multi - channel plates ( mcps ) in chevron configuration and a phosphor screen .a cmos camera ( optronis cl600x2 ) with a repetition rate of 1 was used to film the screen .the positions of individual ions were determined via a centroiding algorithm   .gating the detector by a fast high - voltage switch ( behlke hts 31 - 03-gsm ) allowed to distinguish ionic fragments by their time of flight and to record vmis for individual fragments .fig :experimentalsetup d shows a typical s inlineform26 -position histogram .red circles indicate the area between inlineform27 and inlineform28 ; this range was used to determine the degree of orientation in all measurements .ions recorded in this area originate from the coulomb fragmentation channel inlineform29 , which is a directional fragmentation along the c - s bond of the molecule .slower fragmentation channels with velocities inlineform30 , resulting from singly - ionized molecules , are much more intense and not shown   .the degree of orientation is characterized by the ratio inlineform31 of s inlineform32ions hitting the detector on the upper half inlineform33 divided by the total number of s inlineform34 ions inlineform35 .\n\ntheory: to obtain physical insight into the experimental orientation , a theoretical description of the rotational dynamics of ocs in the experimental field configuration was performed .the dc electric field is always turned on adiabatically , which was computationally checked to be valid for the current experimental parameters , and the adiabatic pendular states of the dc - field configuration were taken as the initial states in these calculations .then , the time - dependent schr\u00f6dinger equation was solved for a constant dc field using the temporal profile of the experimental control laser pulses .to compare with the experimental observations , the theoretical orientation ratio was computed including the volume effect , which took into account the spatial intensity profiles of the control and the probe laser pulses ( vide supra ) and the experimental velocity distribution of the ions after the coulomb explosion in the rangeinlineform36   .if the mixed - field dynamics was adiabatic , the molecule remained in the same pendular eigenstate as the laser pulse is turned on and the hamiltonian evolves with time   .the rotational dynamics were analyzed by projecting the time - dependent wave function on the basis formed by the adiabatic pendular states , which was obtained by solving the time - independent schr\u00f6dinger equation for the instantaneous hamiltonian at time inlineform37 , including both , the interactions with the ac and dc fields .these projections onto the adiabatic pendular basis allowed us to disentangle the field - dressed dynamics for each state of the molecular beam as well as to identify the sources of non - adiabatic effects .\n\nexperimental results: fig : intensity-35 shows the experimental degree of orientation inlineform38 as a function of the peak control laser intensity for experimental dc electric field strengths inlineform39kv / cm , 10.4 kv / cm , 15.6 kv / cm , and 20.7 kv / cm .a small degree of anti - orientation at zero and weak controllaser intensities was observed .this is due to the combined effect of \u201c brute - force \u201d orientation , generated by the static electric field of the vmi spectrometer , and geometric alignment , , selective ionization of ocs by the probe laser , which results in preferred ionization of anti - oriented molecules .for all four electric field strengths , the degree of orientation increased with increasing peak control laser intensity up to inlineform40 .the slope of the experimental degree of orientation was the same for inlineform41 , 15.6 , and 20.7 , while it was slightly lower for 5.2 .for inlineform42 , the degree of orientation was nearly constant with further increasing laser intensities .in this plateau region the degree of orientation was , within error estimates , independent of the dc field strengths for inlineform43 kv / cm , while it was reduced for 5.2 .the inset of fig :intensity-35 shows the experimental and theoretical mean degree of orientation in the plateau region as a function of the dc field strength .all data points between inlineform44 and 6.4e11 , indicated by the blue area in the main figure , were taken into account .the experimentally obtained orientation was inlineform45 for dc field strengths of 10.4 and above , indicating nearly adiabatic orientation for the ground state .for 5.2 , we had a 7 % smaller degree of orientation of inlineform46 .\n\ndiscussion: to understand the saturation of the degree of orientation as a function of the dc field strength the eigenenergies of the adiabatic pendular states of ocs were examined .fig : theorya shows the eigenenergies for inlineform47 ( dashed lines ) and 20.7 ( solid lines ) as a function of the control laser intensity .as the laser intensity increases , the two pendular states inlineform48 and inlineform49 form a near - degenerate doublet ; their energy spacing in the strong - ac - field limit is given by inlineform50 with the permanent dipole momentinlineform51 .in order to ensure adiabatic orientation , any time scale contained in the temporal envelope of the control laser pulse has to be longer than the time scale that corresponds to the instantaneous energy difference in the laser field .therefore , , the rise time of the control laser pulse has to be longer for a dc field of inlineform52 than for a dc field of 20.7 .if this requirement is not fulfilled , the dynamics becomes non - adiabatic and population is transferred between the two pendular states forming the doublet .in this case the resulting orientation for a system starting in the ground state is reduced since the two pendular states orient in opposite directions , see fig : theory b. for rotationally excited states ,the field - dressed dynamics is more complicated .in addition to the pendular doublet formation , the field - free - degenerate j , m manifold splits into distinct inlineform53 components .this results in narrow avoided crossings between energetically neighboring pendular states in the combined field .the avoided crossing between the inlineform54 and inlineform55 states is shown in fig : theory c for inlineform56 (dashed lines ) and 20.7 ( solid lines ) .a larger splitting is observed for stronger dc fields and , therefore , the corresponding dynamics is more adiabatic .our calculations have shown that a field strength on the order of 400 is required to provide adiabatic orientation for the inlineform57 states with a control pulse similar to the experimental one , but without roughness .in fig : intensity-35 the slopes of all experimentally determined degrees of orientation were steeper than for the calculated ones .a possible reason for this discrepancy are errors in the experimentally determined intensity of the control laser , which relies on a determination of the spatial profile of the laser focus .for these beam - profile measurements , the laser beam had to be attenuated by seven orders of magnitudes , which was achieved by using reflections of optical flats and neutral density filters and which might have affected the beam profile .furthermore , the profile of the laser focus might change slightly with pulse energy , for instance , due to self focusing at high pulse energies .the slopes of the experiment and the calculations match nicely if we assume a 1.43 times more intense control laser beam , well within our error estimates .the theoretical degree of orientation taking into account our experimental conditions are shown as solid lines in fig : intensity-35 .the initial rotational state distribution is given by inlineform58 , inlineform59 , and inlineform60 , corresponding to the state distribution obtained from the deflection profile in fig : deflection assuming that the individual states are adiabatically transferred from the deflector to the interaction region inside the velocity map imaging spectrometer .the experimentally determined temporal laser intensity profile , shown in fig : delay a , was taken into account .in comparison to the experimental results we observe a higher degree of orientation for the theoretical curves .we attribute this discrepancy to the following effects : first , simulations have shown that molecules in excited rotational states are not adiabatically transferred from the deflector to the velocity map imaging spectrometer .the non adiabatic transfer is mostly caused by rotating electric field vectors   in the fringe field regions of the deflector and the vmi .moreover , majorana transitions could occur in field free regions .second , a smoother temporal profile of the laser ( vide supra ) pulse would result in a larger ( smaller ) weight of the inlineform61 ( inlineform62 ) state due to a more - adiabatic passage at the corresponding avoided crossing .because inlineform63 is anti - oriented while inlineform64 is oriented this would lead to a decreased degree of orientation .adjusting the input parameters for the calculations , a better agreement between experiment and theory was obtained .the dashed lines in fig : intensity-35 correspond to calculations where the peak intensity was increased by a factor of 1.43 and an initial state population of inlineform65 , inlineform66 , inlineform67 , and inlineform68 was assumed .the results of these calculations show a better agreement with the experimental measurements .the theoretical curve for 5.2 shows a decrease of the degree of orientation for increasing laser intensities above inlineform69 w / cm inlineform70 .this can be attributed to increased non - adiabatic coupling and population transfer between the inlineform71 and inlineform72 states , which gets more important for higher intensities as the slope of the intensity - change and , therefore , the temporal variation of the hamiltonian gets faster .the theoretical decrease is within the error of the experimental data and is not resolved in the experimental results .the non adiabatic dynamics can be further investigated by studying the time dependent weights of the decomposition of the time - dependent wave function inlineform73in the basis of the adiabatic pendular states inlineform74 .the purple area in fig : delay a depicts the temporal laser beam profile with its slow rising and a fast falling edge obtained from the spectrum of the chirped control laser pulse .in addition , the experimental degree of orientation and alignment as a function of the relative timing between the control laser pulse and the probe pulse is shown .the dashed line mark the delay we used for the intensity measurements .both , the degree of orientation and alignment peak at this intensity .the intensity used for the calculation of the time dependent weights is given by inlineform75 .the dc field strengths is inlineform76 .in fig : delay b \u2013 d the time dependent weights inlineform77 of systems initially in the inlineform78 , inlineform79 , and inlineform80 states are presented .a deviation from a weight inlineform81 indicates population transfer and , therefore , non - adiabatic dynamics .the field - dressed dynamics of the ground state inlineform82 in fig : delay b is characterized by the formation of the pendular pair at a delay of approximately 50 ps , when population is transferred to the first rotational excited state resulting in a weight inlineform83 .in addition , population transfer to states that correlate adiabatically to the inlineform84 manifold is observed in the calculation .this is attributed to the roughness of the time - profile and the sudden changes in intensity of the experimental pulse , and not due to the slow inlineform85 rise time of the laser pulse , which is long compared to the rotational period of 82 ps .initially , population is transferred to inlineform86 .at stronger ac fields , this state encounters an avoided crossing at which practically all population is diabatically transferred to the inlineform87 state .furthermore , for stronger fields further population transfer from the ground - state pendular doublet proceeds to this inlineform88 state , which reaches a population of inlineform89 .although the field - dressed dynamics of inlineform90 including the experimental laser profile is non - adiabatic , the pendular states contributing to the dynamics , inlineform91 , inlineform92 and inlineform93 , are all strongly oriented anda computed degree of orientation of inlineform94 is obtained for inlineform95 at the peak laser intensity .we have also performed calculations with an ideal pulse without roughness , which was generated by fitting error functions to the experimental pulse .for this completely smooth theoretical pulse the field - dressed dynamics of the ground - state state is only affected by the formation of the pendular doublet and the dynamics would be completely adiabatic , confirming that the remaining non - adiabaticity is due to the , albeit small , experimental noise in the laser intensity .for the ground state of the odd irreducible representation , inlineform96 , we encounter an equivalent field - dressed dynamics , shown in fig : delay c ; it is slower because the pendular doublet formation occurs at stronger ac fields .at approximately 100 ps we observe an ac - field - induced population transfer between the initially populated inlineform97 state and the inlineform98 state .at 200 ps later this population transfers diabatically to the inlineform99 state .almost simultaneously , and due to the formation of the first pendular doublet in this irreducible representation , there is some population transferred from the inlineform100 state to inlineform101 .at the peak intensity , the pendular states significantly contributing to the time - dependent wave functioninlineform102 are inlineform103 , inlineform104 , and inlineform105 .analogously to the absolute ground - state , the dynamics of this state inlineform106 in an ideal pulsewould only be affected by the formation of the pendular doublet between the states inlineform107 and inlineform108 .in fig : delay d the weights of the expansion coefficients of the time - dependent inlineform109 wave function for the experimental pulse with peak intensity inlineform110 and a dc field with strength inlineform111 is presented .the mixed - field dynamics of this state is more complicated .in the presence of a tilted static electric field , the pendular states inlineform112and inlineform113 are energetically very close , and even a weak ac field provokes a strong coupling between them .at weak laser intensities , when the splitting of the inlineform114 manifold due to the strong dc field takes place , a significant amount of population is transferred between them .thereafter , the state inlineform115 possesses the dominant contribution to the inlineform116 state .this non - adiabatic behavior takes place before the pendular doublet formation , , at low intensities and short times .by further increasing the ac field strength , population is transferred to inlineform117 and inlineform118 due to the formation of the pendular doublets with inlineform119 and inlineform120 , respectively .due to ac - field - induced couplings with other pendular states and narrow avoided crossings , we observed that many adiabatic pendular states contribute to the dynamics .at the peak intensity , the pendular states that significantly contribute to the time - dependent wave function inlineform121 are inlineform122 , inlineform123 , inlineform124 , inlineform125 , inlineform126 , inlineform127 , inlineform128 , and inlineform129 .since inlineform130 is anti - oriented and cancels the contributions form other states , inlineform131 shows no orientation at the peak intensity , , inlineform132 .in contrast , the dynamics of this inlineform133 state in an ideal pulse without roughness is mainly affected by the splitting of the inlineform134 manifold , and weakly by the subsequent formation of the pendular pairs .for this ideal pulse , only two adiabatic pendular states contribute significantly , with inlineform135 and inlineform136 , resulting in anti - orientation .for the ideal pulse with peak intensityinlineform137 and a dc field of 50 , the non - adiabaticity during the splitting of the inlineform138 manifold would be significantly reduced , and the population - transfer from inlineform139 to inlineform140 would be inlineform141 .\n\nconclusion: adiabatic mixed field orientation of ground - state - selected ocs molecules has been demonstrated using strong dc electric fields of 10\u201320 kv / cm .the experiments demonstrate strong orientation with inlineform142 in agreement with our theoretical description .for dc electric fields of 10.4 or stronger , the observed degree of orientation was independent of the dc electric field strength , which indicated that the molecules in their ground state are oriented adiabatically .comparison with calculations showed that only a very small fraction of the population was transferred to excited states .the deviation of the degree of orientation from its maximal possible value of inlineform143 was attributed to contributions of excited rotational states present in the deflected part of the molecular beam that was used in the orientation experiments .preparing the molecules in the absolute ground state would result in full adiabatic orientation dynamics and , therefore , in an even higher degree of orientation .the adiabatic orientation of an excited rotational state is more challenging .avoided crossing and the degeneracy at low laser intensity make non - adiabatic behavior more likely .compared to other techniques   our approach ensures a strong degree of orientation while employing only moderately strong laser intensities on the order of 1e11 , which are far below the onset of ionization , even for larger molecules   .moreover , these moderate fields strengths allow for the investigation of chemical dynamics , using molecular - frame - imaging approaches , without significant distortions of the dynamics .our findings hold for polar molecules in general , as the hamiltonian can be rescaled accordingly .due to the complexity of the rotational level structure of asymmetric tops , non - adiabatic effects will have a larger impact on the orientation dynamics of these more complex molecules   .nevertheless , our finding hold for any molecule prepared in the rotational ground state ; the experimental realization of such a sample was experimentally demonstrated for c inlineform144 h inlineform145 n using the alternating - gradient inlineform146 selector   .the improved adiabaticity in mixed field orientation and the resulting increase in the degree of orientation will improve , especially for complex molecules , imaging experiments with fixed - in - space molecules such as the investigation of molecular - frame photoelectron angular distributions   or the recording of molecular movies by x - ray   and electron diffraction   ,   or photoelectron holography   .\n\nacknowledgements: besides desy , this work has been supported by the deutsche forschungsgemeinschaft ( dfg ) through the excellence cluster \u201c the hamburg center for ultrafast imaging \u2013 structure , dynamics and control of matter at the atomic scale \u201d ( cui , exc1074 ) and the helmholtz association \u201c initiative and networking fund \u201d .r.g.f .gratefully acknowledges financial support by the spanish project fis2014 - 54497-p ( mineco ) and the andalusian research group fqm-207 .\n\nmeasurement of the temporal control laser profile: the temporal profiles of the control - laser pulses were deduced from a measurement of their spectrum and a calibrated wavelength - to - time conversion .all spectra were recorded with a commercial spectrometer ( photon control spm-002-x ) .the conversion function between the measured spectrum , shown in fig : delay a , and the corresponding temporal intensity profile of the control laser pulse , shown in fig : delay d , was determined from the spectral interference of the control laser and the time - delayed 30 fs probe laser pulses .both laser beams were linearly polarized , parallel to each other , colinearly overlapped , and their simultaneous spectrum recorded .the resulting spectral interference between the two laser pulses manifests itself as a localized large amplitude fluctuation in the spectrum .these fluctuations mark the position \u201c in time \u201d of the short probe pulse within the spectrum of the temporarily stretched \u2013 chirped \u2013 control laser pulse .as an example , the combined spectrum of both lasers is shown for one relative timing in fig :delay b.the position of the spectral interference is highlighted by the red ellipse and the amplitude of its fluctuation is indicated by the green curve .the wavelength inlineform147 of the spectral interference pattern in the spectrum as a function of the delay - stage position inlineform148 is shown in fig : delay c.the blue line is a quadratic fit according to inlineform149 from which we obtained inlineform150 , inlineform151 and inlineform152 .the conversion from delay stage positioninlineform153 to timeinlineform154 is given by inlineform155 , where inlineform156 is the speed of light .the factor of two is taking into account that the light was traveling back and forth in the translation stage .the resulting temporal profile of the control laser pulse , calculated according to displayform0is shown in fig : hv - pico - time d.",
      "target_text": "we experimentally demonstrated strong adiabatic mixed - field orientation of carbonyl sulfide molecules ( ocs ) in their absolute ground state of $ \\text{n}_{\\text{up}}/\\text{n}_{\\text{tot}}=0.882$. ocs was oriented in combined non - resonant laser and static electric fields inside a two - plate velocity map imaging spectrometer .the transition from non - adiabatic to adiabatic orientation for the rotational ground state was studied by varying the applied laser and static electric field .above static electric field strengths of 10 kv / cm and laser intensities of $ 10^{11 } \\text{w / cm}^2 $the observed degree of orientation reached a plateau .these results are in good agreement with computational solutions of the time - dependent schr\\\"odinger equation .",
      "output_text": "theoretical study of adi - ably oriented ground - state - selected molecules   .the molecules were prepared by a combination of strong orientation and quantum state selection , and their orientations were measured using diffraction , electron and X - ray spectroscopy and high - resolution electron microscopy   .\n\nresults: the ad - ab - oriented doublets were found to be strongly anisotropic , with anisotropy ranging from 0 to 100% , depending on laser frequency and intensity , and the orientation of the dipoles was found to depend on the direction of the applied magnetic field .the orientation was measured in the plane perpendicular to the magnetic field , and in a plane parallel to the field , with the orientation determined by the ratio of the intensities of the diffraction peaks in the two orientations   .with the exception of one sample , the orientation was determined with a precision of 0.05\u00b0 , which is sufficient for most applications   .mixed - field oriented samples were also found to exhibit a large degree of isotropy , with orientations ranging between 0 and 90\u00b0 , and with a mean orientation of 30\u00b0 .the isotopic distribution of the orientations was found not to depend strongly on the applied field , indicating that the orientation is not strongly dependent on the isotope , but rather on the population of the excited states   .based on the passage above, Can you summarize the main findings of the scientific article on the mixed field orientations of carbon-sulfur molecules?"
    },
    {
      "input_text": "Title: Stochastic Variance Reduced Riemannian Eigensolver\nDomains: Mathematics\n\nintroduction: matrix eigen - decomposition is among the core and long - standing topics in numerical computing   .it plays fundamental roles in various scientific and engineering computing problems ( such as numerical computation   ,   and structural analysis   ) as well as machine learning tasks ( such as kernel approximation   , dimensionality reduction   and spectral clustering   ) .thus far , there has n't been many algorithms proposed for this problem .pioneering ones include the method of power iteration   andthe ( block ) lanczos algorithm  , while randomized svd   and online learning of eigenvectors   are recently proposed .the problem can also be expressed as a quadratically constrained quadratic program ( qcqp ) , and thus can be approached by various optimization methods , such as trace penalty minimization   and riemannian optimization algorithms   .most of these algorithms perform the batch learning , i.e. , using the entire dataset to perform the update at each step .this could be well addressed by designing appropriate stochastic algorithms .however , the state - of - the - art stochastic algorithm dsrg - eigs   requires the learning rate to repeatedly decay till vanishing in order to guarantee convergence , which results in a slow convergence of sub - linear rate .we propose a new stochastic riemannian algorithm that makes a significant breakthrough theoretically .it improves the state - of - the - art sub - linear convergence rate to an exponential convergence one .the algorithm is inspired by the stochastic variance reduced gradient ( svrg ) optimization , which was originally developed to solve convex problems in the euclidean space .we propose the general form of variance reduction , called svrrg , in the framework of the stochastic riemannian gradient ( srg ) optimization   , such that it is able to enjoy the convergence properties ( e.g. , almost sure local convergence ) of the srg framework .we then get it specialized to the riemannian eigensolver ( rg - eigs ) problem so that it gives rise to our stochastic variancereduced riemannian eigensolver , termed as svrrg - eigs .our theoretical analysis shows that svrrg - eigs can use a constant learning rate , thus eliminating the need of using the decaying learning rate .moreover , it not only possesses the global convergence in expectation compared to srg   , but also gains an accelerated convergence of exponential rate compared to dsrg - eigs .to the best of our knowledge , we are the first to propose and analyze the generalization of svrg to riemannian manifolds .the rest of the paper is organized as follows .section secref2 briefly reviews some preliminary knowledge on matrix eigen - decomposition , stochastic riemannian gradient optimization and stochastic riemannian eigensolver .section secref3 presents our stochastic variance reduced riemannian eigensolver algorithm , starting from establishing the general form of variance reduction for the stochastic riemannian gradient optimization .theoretical analysis is conducted in section secref4 , followed by the empirical study of our algorithm in section secref5 .section 6 discusses related works .finally , section secref7 concludes the paper .\n\nmatrix eigen-decomposition: the eigen - decomposition of a symmetric matrix inlineform0 can be written as inlineform1 , where inlineform2 ( identity matrix ) , and inlineform3 is a diagonal matrix .the inlineform4 -th column inlineform5 of inlineform6 is called the eigenvector corresponding to the eigenvalue inlineform7( inlineform8 -th diagonal element of inlineform9 ) , i.e. , inlineform10 .assume that inlineform11 , inlineform12 and inlineform13 , inlineform14 and inlineform15 .in practice , matrix eigen - decomposition only aims at the set of top eigenvectors inlineform16 .from the optimization perspective , this can be formulated as the following non - convex qcqp problem : displayform0where inlineform17 and inlineform18 represents the trace of a square matrix , i.e. , the sum of diagonal elements of a square matrix .it can be easily verified that inlineform19 maximizes the trace at inlineform20 .\n\nstochastic riemannian gradient optimizaiton: given a riemmanian manifold inlineform21 , the tangent space at a point inlineform22 , denoted as inlineform23 , is a euclidean space that locally linearizes inlineform24 aroundinlineform25   .one iterate of the riemannian gradient optimization on inlineform26 takes the form similar to that of the euclidean case   : displayform0where inlineform27 is a tangent vector of inlineform28 at inlineform29 and represents the search direction at the inlineform30 -th step , inlineform31 is the learning rate ( i.e. , step size ) , and inlineform32 represents the retraction at inlineform33 that maps a tangent vector inlineform34 to a point on inlineform35 .tangent vectors that serve as search directions are generally gradient - related .the gradient of a function inlineform36 on inlineform37 , denoted as inlineform38 , depends on the riemannian metric , which is a family of smoothly varying inner products on tangent spaces , i.e. , inlineform39 , where inlineform40 for any inlineform41 .the riemannian gradient inlineform42 is the unique tangent vector that satisfies displayform0for any inlineform43 , where inlineform44 represents the directional derivative of inlineform45 in the tangent direction inlineform46 .setting inlineform47 in ( eqref5 ) leads to the riemannian gradient ( rg ) ascent method : displayform0we can also set inlineform48 in ( eqref5 ) and induce the stochastic riemannian gradient ( srg )ascent method  : displayform0where inlineform49 is an observation of the random variable inlineform50 at the inlineform51 -th step that follows some distribution and satisfies inlineform52 , and inlineform53 is the stochastic riemannian gradient such thatinlineform54 .according to   , the srg method possesses the almost sure ( local ) convergence under certain conditions , including inlineform55 and inlineform56( the latter condition implies that inlineform57 as inlineform58 ) .\n\nstochastic riemannian eigensolver: the constraint set in problem ( eqref3 ) constitutes a stiefel manifold , inlineform59 , which turns ( eqref3 ) into a riemannian optimization problem : displayform0where inlineform60 .note that inlineform61 is an embedded riemannian sub - manifold of the euclidean spaceinlineform62   .with the metric inherited from the embedding space inlineform63 , i.e. , inlineform64 , and using ( eqref6 ) , we can get the riemannian gradientinlineform65as : inlineform66the orthogonal projection onto inlineform67 under this metric is given by : displayform0for any inlineform68 , where inlineform69 .in this paper , we use the retraction   displayform0for any inlineform70 .the deployment of ( eqref7 ) and ( eqref8 ) here will then generate the riemannian eigensolver ( denoted as rg - eigs ) and the stochastic riemannian eigensolver ( denoted as srg - eigs ) , respectively .to the best of our knowledge , there is no existing stochastic riemannian eigensolver that uses this retraction .the closest counterpart is the dsrg - eigs that uses the cayley transformation based retraction .however , based on the work of dsrg - eigs , it can be shown that srg - eigs possesses the same theoretical properties as dsrg - eigs , e.g. , sub - linear convergence to global solutions .\n\nsvrrg-eigs: in this section , we propose the stochastic variance reduced riemannian gradient ( svrrg ) and specialize it to the eigensolver problem .\n\nsvrrg: recall that the stochastic variance reduced gradient ( svrg )   is built on the vanilla stochastic gradient and achieves variance reduction through constructing control variates   .control variates are stochastic and zero - mean , serving to augment and correct stochastic gradients towards the true gradients .following   , svrg is encoded as displayform0where inlineform71 is a version of the estimated inlineform72 that is kept as a snapshot after every inlineform73 sgd steps , and inlineform74 is the full gradient at inlineform75 .our task here is to develop the riemannian counterpart svrrg of svrg .denote the svrrg as inlineform76 .a naive adaptation of ( eqref15 ) to a riemannian manifold inlineform77 reads inlineform78where inlineform79 and inlineform80 .however , this adaptation is not sound theoretically : the stochastic riemannian gradient inlineform81 and the control variate inlineform82 reside in two different tangent spaces , and thus making their difference inlineform83 not well - defined .we rectify this problem by the parallel transport   , which moves tangent vectors from one point to another ( accordingly from one tangent space to another ) along geodesics in parallel .more specifically , we parallel transport the control variate from inlineform84 to inlineform85 .for computational efficiency , the first - order approximation , called vector transport   , is used .vector transport of a tangent vector from point inlineform86 to point inlineform87 , denoted as inlineform88 , is a mapping from tangent space inlineform89 to tangent space inlineform90 .when inlineform91 is an embedded riemannian sub - manifold of a euclidean space , vector transport can be simply defined as   : inlineform92where inlineform93 represents the orthogonal projector onto inlineform94 for the embedding euclidean space .with the vector transport , we obtain the well - defined svrrg in inlineform95 : inlineform96we then arrive at our svrrg method : displayform0by setting inlineform97 in ( eqref5 ) .note that the svrrg method ( eqref16 ) is naturally subsumed into the srg method ( eqref8 ) , and thus enjoys all the properties of srg .svrrg   data inlineform98 , initial inlineform99 , learning rate inlineform100 ,epoch length inlineform101  inlineform102 compute inlineform103 inlineform104 inlineform105 pick inlineform106 from the sample space uniformly at random compute inlineform107 and inlineform108 compute inlineform109 compute inlineform110 compute inlineform111 inlineform112\n\ntheoretical analysis: we give the main theoretical results in this section .the proofs are provided in the supplementary material .theorem 4.1 consider a symmetric matrix inlineform158 which can be written as inlineform159such that inlineform160 .the eigen - decomposition of inlineform161 is as defined in section secref1 .and the eigen - gap inlineform162 .then the top inlineform163 eigenvectors inlineform164 can be approximated to arbitrary accuracy inlineform165 and with any confidence level inlineform166 by running inlineform167 epochs of our svrrg - eigs algorithm , in the sense that the potential function inlineform168 with probability at least inlineform169 , provided that the following conditions about initial iterateinlineform170 , fixed learning rate inlineform171 and epoch length inlineform172 , are simultaneously satisfied : inlineform173where the constants are positive and defined as inlineform174note that we have no loss of generality from assuming that inlineform175 in the theorem .in fact , if inlineform176 with inlineform177 ( which could be estimated by , e.g. , gershgorin circle theorem ) , we could replace inlineform178 with inlineform179 to get inlineform180 and arrive at the same eigen - space .another way of addressing this generality is to adopt the idea of   , that is , replacing the learning rate inlineform181 with inlineform182 and the eigen - gap inlineform183 with inlineform184 , with some of the constants in the theorem re - derived .the condition on the initial iterate , i.e. , inlineform185 , is theoretically non - trivial .however , empirically this condition can be well satisfied by running other stochastic algorithms ( e.g. , srg - eigs or dsrg - eigs ) or a few steps of deterministic iterative algorithms ( e.g. , rg - eigs ) , because they are good at finding sub - optimal solutions .in our experiments , we use srg - eigs for this purpose , which makes the theorem amount to a convergence analysis at a later stage of the hybrid algorithm ( e.g. , starting from inlineform186 instead of inlineform187 ) .the convergence rate of our algorithm can be roughly identified by the iteration number inlineform188 which establishes an exponential global convergence rate .compared to the sub - linear rate inlineform189 of dsrg - eigs by   , it achieves a significant improvement since the complexity of a single iteration in the two algorithms only differs by constants .in summary , initialized by a low - precision eigensolver , our svrg - eigs algorithm would obtain a high - precision solution in a limited number of epochs ( data passes ) , which is theoretically guaranteed by theorem secref20 .we provide an elegant proof of theorem secref20 in appendix , though it is a bit involved .for ease of exposition and understanding , we decompose this course into three steps in a way similar to   , including the analysis on one iteration , one epoch and one run of the algorithm .among them , the first step ( i.e. , one iteration analysis ) lies at the core of the main proof , where the techniques we use are dramatically different from those in   ,   due to our new context of rimannian manifolds , or more precisely , stiefel manifolds .this inherently different context requires new techniques , which in turn yield an improved exponential global convergence and accordingly bring more improvements over the convergence of sub - linear rate   .\n\nexperiments: in this section , we empirically verify the exponential convergence rate of our svrrg - eigs algorithm and demonstrate its capability of finding solutions of high precision when combined with other algorithms of low precision .specifically , we use srg - eigs to generate a low - precision solution for initializing svrrg - eigs , and do the comparison with both rg - eigs and srg - eigs .among various implementations of rg - eigs with different choices of metric and retraction in ( eqref5 ) , we choose the one with canonical metric and cayley transformation based retraction   since its code is publically available .this version of rg - eigs uses the non - monotone line search with the well - known barzilai - borwein step size , which significantly reduces the iteration number , and performs well in practice .both rg - eigs and srg - eigs are fed with the same random initial value of inlineform190 , where each entry is sampled from the standard normal distribution inlineform191 and then all entries as a whole are orthogonalized .srg - eigs uses the decaying learning rate inlineform192 where inlineform193 will be tuned .we verify the properties of our algorithm on a real symmetric matrix , schenk , of inlineform194 size , with inlineform195 nonzero entries .we partition inlineform196 into column blocks with block size equal to 100 so that we can write inlineform197 with inlineform198 and each inlineform199 having only one column block of inlineform200 and all others zero .we set inlineform201 .for svrrg - eigs , we are able to use a fixed learning rate inlineform202 and adopt the heuristic inlineform203 ( inlineform204 represents the matrix 1-norm ) , similar to that in   .we set inlineform205 and epoch lengthinlineform206 , i.e. , each epoch takes inlineform207passes over inlineform208 ( including one pass for computing the full gradient ) .accordingly , the epoch length of srg - eigs is set to inlineform209 .in addition , we set inlineform210 .the performance of different algorithms is evaluated using three quality measures :feasibility inlineform211 , relative error functioninlineform212 , and normalized potential functioninlineform213 .the ground truths in these measures , including both inlineform214and inlineform215 that is set to inlineform216 , are obtained using matlab 's eigs function for benchmarking .for each measure , lower values indicate higher quality .given a solution inlineform217 of low precision at inlineform218 , our svrrg - eigs targets a double precision , that is , inlineform219 or inlineform220 .each algorithm terminates when the precision requirement is met or the maximum number of epoches ( set as 20 ) is reached .we report the convergence curves in terms of each measure , on which empirical convergence rates of the algorithms can be observed .figure figref24 reports the performance of different algorithms .in terms of feasibility , both srg - eigs and svrrg - eigs perform well , while rg - eigs produces much poorer results .this is because the cayley transformation based retraction used therein relies heavily on the sherman - morrison - woodbury formula , which suffers from the numerical instability .from figures uid26and uid27 , we observe similar convergence trends for each algorithm under the two different measures .all three algorithms improve their solutions with more iteration .there are several exceptions in rg - eigs .this is due to the non - monotone step size used in its implementation .we also observe that srg - eigs presents an exponential convergence rate at an early stage thanks to a relatively large learning rate .however , it subsequently steps into a long period of sub - exponential convergence , which leads to small progress towards the optimal solution .in contrast , our svrrg - eigs inherits the initial momentum from srg - eigs and keeps the exponential convergence rate throughout the entire process .this enables it to approach the optimal solution at a fast speed .rg - eigs has a different trend .it converges sub - exponentially at the beginning and performs the worst .though it converges fast at a later stage , it still needs more passes over data than svrrg - eigs in order to achieve a high precision .\n\nrelated work: existing methods on eigensolvers include the power method   ,the ( block ) lanczos algorithms   , randomized svd  , riemannian methods and so on .all these methods performs the batch learning , while our focus in this paper is on stochastic algorithms .from this perspective , few existing works include online learning of eigenvectors   which aims at the leading eigenvector , i.e. , inlineform221 , and doubly stochastic riemannian method ( dsrg - eigs )   where the learning rate has to decay to zero .  provides the regret analysis without empirical verification for their method , while dsrg - eigs belongs to one of implementations of srg - eigs in this paper where the double stochasticity comes from sampling over both data and coordinates of riemmanian gradients .on the other hand , since the work of   , variance reduction ( svrg ) has become an appealing technique to stochastic optimization .there are quite some variants developed from different perspectives , such as practical svrg   , second - order svrg   , distributed or asynchronous svrg and non - convex svrg   .our svrrg belongs to non - convex svrg , but is addressed from the riemannian optimization perspective .the core techniques we use are dramatically different from existing ones due to our new context .\n\nconclusion: in this paper , we proposed the generalization of svrg to riemannian manifolds , and established the general framework of svrg in this setting , svrrg , which requires the key ingredient , vector transport , to make itself well - defined .it is then deployed to the eigensolver problem and induces the svrrg - eigs algorithm .we analyzed its theoretical properties in detail .as suggested by our theoretical results , the proposed algorithm is guaranteed to find high - precision solutions at an exponential convergence rate .the theoretical implications are verified on a real dataset .for future work , we will explore the possibility of addressing the limitations of svrrg - eigs , e.g. , dependence on eigen - gap and non - trivial initialization .we may also conduct more empirical investigations on the performance of svrrg - eigs .\n\nuseful lemmas: in this section , some definition , basics , and a group of useful lemmas are provided .all the matrices are assumed to be real .\n\ndefinitions and basics: the matrix inlineform222 ( inlineform223 ) represents that inlineform224 is symmetric and positive semidefinite ( definite ) , and if inlineform225 then inlineform226 as well .the trace of a square matrix , inlineform227 , is the sum of diagonal entries of inlineform228 .a useful fact about trace is the circular property , e.g. , inlineform229 for matricesinlineform230 .inlineform231 and inlineform232 represents the frobenious - norm and spectral norm ( i.e. , matrix 2-norm ) of matrix inlineform233 , respectively .here inlineform234 represents the maximum eigenvalue of an inlineform235 matrix ,inlineform236 represents the maximum singular value of an inlineform237 matrix .note that inlineform238 and inlineform239 have the same set of nonzero eigenvalues for two matrices inlineform240 and inlineform241 .thus , inlineform242 .in this document , we always assume that the eigenvalues of an inlineform243 matrix inlineform244 takes the forminlineform245 .thus inlineform246 and inlineform247 for any inlineform248 ,where inlineform249 is called the spectral radius of a square matrixinlineform250 .and also inlineform251 , which in turn implies inlineform252 for any matrixinlineform253 .for any two matrices inlineform254 and inlineform255 that make inlineform256 well - defined , inlineform257 holds for both frobenious - norm and spectral norm , and inlineform258 holds .furthermore , the orthogonal invariance also holds for both frobenious - norm and spectral norm , i.e. , inlineform259 for column - orthonormal matrices inlineform260 and inlineform261 ( i.e. , inlineform262 and inlineform263 ) .for inlineform264 , let inlineform265 represent its orthogonal complement , i.e. , inlineform266 which implies inlineform267 and inlineform268 .the filtration , defined on a measurable probability space , is an increasing sequence of sub - sigma algebras inlineform269 for inlineform270 , meaning that inlineform271 for all inlineform272 .in our context , inlineform273 encodes the set of all the random variables seen thus far ( i.e. , from 0 to inlineform274 ) .in this document , conditioned on inlineform275 refers to conditioned on inlineform276 for brevity .let inlineform277 and inlineform278 be a stochastic process and a filtration , respectively , on the same probability space .then inlineform279 is called a martingale ( super - martingale ) with respect to inlineform280 if for each inlineform281 , inlineform282 is inlineform283 -measurable , inlineform284 , and inlineform285( inlineform286 ) .given a random variable inlineform287 and a constant inlineform288 , the probability inlineform289 ( markov inequality ) .let inlineform290 be a martingale or supermartingale such that inlineform291 ( i.e. , bounded difference )where inlineform292 is a deterministic function of inlineform293 .then for all inlineform294and any inlineform295 , the probabilityinlineform296 ( azuma - hoeffding inequality )   .\n\nlemmas: the proofs of lemma secref32 - secref39 can be found in   .lemma a.1 for any inlineform297, it holds that inlineform298lemma a.2if inlineform299 and inlineform300 , then inlineform301 .lemma a.3 let inlineform302 be inlineform303 square matrix , where inlineform304 are fixed and inlineform305 are stochastic zero - mean .furthermore , suppose that for some fixed inlineform306 , it holds with probability 1 thatfor all inlineform307 , inlineform308  inlineform309  inlineform310then inlineform311lemma a.4 let inlineform312 be a inlineform313 matrix with minimal singular value inlineform314 and inlineform315 .then inlineform316lemma a.5 for any inlineform317 matrices inlineform318 with orthonormal columns , let inlineform319 .then inlineform320where inlineform321 is the svd of inlineform322 .lemma a.6 let inlineform323 and inlineform324 be as defined in section 3.2 of the main paper .assume inlineform325 andinlineform326 .then for any inlineform327 matrix inlineform328 with orthonormal columns , it holds thatinlineform329note that inlineform330 since inlineform331 and thus inlineform332   .based on the proof of lemma 9 in   , it suffices for us to show that inlineform333 and inlineform334 .in fact , from section 3.2 of the main paper , we have inlineform335since inlineform336 , we have inlineform337 , inlineform338 andthus inlineform339 . note that inlineform340 .then we have inlineform341similarly , inlineform342thus , inlineform343 .lemma a.7if inlineform344 and inlineform345 , then inlineform346 .inlineform347by lemma secref32 - secref33 , we have inlineform348lemma a.8 ( von neumann 's trace inequality   )for two symmetric inlineform349 matrices inlineform350 and inlineform351 , it holds thatinlineform352lemma a.9 for two symmetricinlineform353 matricesinlineform354 and inlineform355 , it holds that inlineform356the proof is done by replacing inlineform357 with inlineform358 or replacing inlineform359 with inlineform360 in von neumann 's trace inequality .\n\nmain proof: the proof of the theorem is a bit involved .for ease of exposition and understanding , we decompose this course into three steps in a way similar to   , including the analysis on one iteration , one epoch and one run of the algorithm .among them , the first step ( i.e. , one iteration analysis ) lies at the core of the main proof , where the techniques we use are dramatically different from those in   ,   due to our new context of rimannian manifolds , more precisely , stiefel manifolds .this inherently different context requires new techniques , which yield an improved exponential global convergence and accordingly bring more improvements over the convergence of sub - linear rate by   .\n\none iteration analysis: in the first step , we consider a single iteration inlineform361 of our svrrg - eigs algorithm .the goal here is to establish a stochastic recurrence relation on inlineform362 such that inlineform363 tends to inlineform364 as inlineform365 goes to infinity with high probability ( w.h.p . ) .note that inlineform366 implies that inlineform367 converges to the global solution inlineform368 up to a inlineform369 orthogonal matrix w.h.p . , which is exactly one of our ultimate goals ( i.e. , convergence to global solutionsw.h.p . , fixed learning rate and exponential convergence rate ) .for brevity , we omit the lengthy superscripts by letting inlineform370 , inlineform371 , inlineform372 , and inlineform373 .and assume that inlineform374 .lemma b.1 follow the notations and assumptions made in lemma secref48 .then it holds that inlineform375based on section 2.1 of the main paper , the eigen - decomposition of matrix inlineform376 can be written as inlineform377 .then inlineform378by lemma secref43 , we have inlineform379note that both matrices above , i.e. , inlineform380 and inlineform381 are symmetric and thus lemma secref43 can be applied .in fact , inlineform382which is symmetric .furthermore , it is positive seme - definite , because inlineform383and thus inlineform384likewise , we have inlineform385which is symmetric but negative semi - definite , because inlineform386and thus inlineform387we now can write inlineform388in which , we find that inlineform389and similarly inlineform390note that inlineform391and inlineform392therefore , we arrive at inlineform393lemma b.2 let inlineform394 and inlineform395 be defined by ( eqref50 ) and ( eqref49 ) , respectively , and follow the notations and assumptions made in lemma secref48 .then it holds that inlineform396note that inlineform397and inlineform398then by lemma secref33 , we get inlineform399since inlineform400 , inlineform401 and inlineform402we have inlineform403and note that inlineform404 .then by lemma secref32 , we can arrive at inlineform405to simplify above inequality , define inlineform406then inlineform407we now lower bound each of three items above .on one hand , by lemma secref45 , we get inlineform408on the other hand , by cauchy - schwarz inequality , we can obtain inlineform409for the middle term , noting that inlineform410 and inlineform411 , then it can be derived as follows inlineform412where inlineform413and similarly inlineform414 .thus , we could write inlineform415therefore , we now can arrive at inlineform416lemma b.3 follow the notations made in lemma secref48 , assumeinlineform417 with inlineform418 ( thus inlineform419 ) , and let inlineform420recalling from section 3.2 of the main paper .then it holds that inlineform421and we can take inlineform422note that inlineform423 and inlineform424 .then we have inlineform425we now upper bound the spectral norm and frobenius norm of inlineform426 .first we rewrite it as inlineform427noting that inlineform428 , we get inlineform429while inlineform430to proceed further , each of three items in above bracket needs to upper bounded .to this end , note that inlineform431 by the definition of inlineform432 and lemma secref39 .then if we let inlineform433 and inlineform434 , we can get inlineform435for other two items , noting that inlineform436 , we have inlineform437and similarly inlineform438therefore , we get inlineform439lemma b.4 assumeinlineform440 is an inlineform441 symmetric matrix with the eigenvaluesinlineform442 and the eigen - gap inlineform443 .and it could be written as inlineform444 with inlineform445 ( thus inlineform446 ) .let inlineform447 be an inlineform448 stochastic zero - mean matrix( i.e. , inlineform449 ) with inlineform450 and inlineform451 almost surely .let inlineform452 and define inlineform453for some inlineform454 .if inlineform455 consisting of inlineform456 's inlineform457 eigenvectors corresponding to eigenvalues inlineform458 and accordingly inlineform459 consisting of inlineform460 's inlineform461 eigenvectors corresponding to eigenvalues inlineform462 , then it holds thatinlineform463first , we have inlineform464using the definition of inlineform465 and the factinlineform466 , we have the expansion inlineform467 where inlineform468similarly , inlineform469 can be written as inlineform470 with inlineform471then we get inlineform472note that inlineform473 .thus , displayform0in addition , let displayform0and note that inlineform474 .then by lemma secref41 and secref32 , we obtain inlineform475we now would like to apply lemma secref34 for removing inlineform476 and inlineform477 .doing so needs to meet the conditions of lemma secref34 .in fact ,  inlineform478 and inlineform479 are stochastic zero - mean :inlineform480 and inlineform481 are linear functions of the stochastic zero - mean matrix inlineform482 .thus they are stochastic zero - mean as well .  inlineform483 and inlineform484 are fixed .this is true since no stochastic quantities are involved .  inlineform485 for allinlineform486 .it 's easy to see that inlineform487 , and meanwhile since inlineform488 , inlineform489 ,inlineform490 and inlineform491, we get inlineform492note that inlineform493 is symmetric and inlineform494 .we thus could write inlineform495 .then inlineform496 .  inlineform497 .note that inlineform498 .then inlineform499similarly , we could get inlineform500 .  inlineform501 .note that similar toright above , we could have inlineform502 .then inlineform503thus , inlineform504thus , we have inlineform505 , inlineform506 and inlineform507 .then by lemma secref34 , we get inlineform508moreover , by lemma secref46 , we arrive at inlineform509lemma b.5 let inlineform510 and inlineform511 be defined as by our svrrg - eigs algorithm in section 3.2 of the main paper .assume that inlineform512 has the eigen - decomposition as defined in section 2.1 of the main paper , the eigen - gap inlineform513 , andinlineform514 .further suppose that inlineform515 and inlineform516 .then it holds thatinlineform517where the expectation is taken with respect to the random inlineform518 for inlineform519 conditioned on inlineform520 , and in addition inlineform521 for any inlineform522 with inlineform523and inlineform524 .first by lemma secref47 , inlineform525 is conditionally stochastic zero - mean .and inlineform526 .then inlineform527 .thus lemma secref48 can be applied , and we have inlineform528let inlineform529 be the minimum singular value of inlineform530 .since inlineform531 , then by lemma secref38 we have inlineform532and then by lemma secref47 , inlineform533note that inlineform534 implies the singular values of inlineform535 fall into inlineform536 .if inlineform537 then inlineform538 , which contradicts the assumptioninlineform539 .thus , inlineform540 .furthermore , inlineform541 .we thus get inlineform542since inlineform543 , inlineform544 .then inlineform545and inlineform546further let inlineform547we then arrive at inlineform548and solving the equation inlineform549 , ensuring inlineform550 , together with the assumption about inlineform551 made in this lemma , yields inlineform552 with inlineform553which simultaneously satisfies inlineform554 , inlineform555 , and inlineform556 .\n\none epoch analysis: we now solve the stochastic recurrence relation for a single epoch of our svrrg - eigs algorithm .in this subsection , we still assume that inlineform557 .let inlineform558 , inlineform559 and inlineform560( note that inlineform561 ) .then by lemma secref57 we have that if inlineform562 and inlineform563 , then inlineform564where the expectation is taken with respect to the random inlineform565 for inlineform566 .lemma b.6 assume inlineform567 is fixed and inlineform568 .let inlineform569 and inlineform570 .then inlineform571we need to examine the evolution of inlineform572 as a function of inlineform573 , while inlineform574 itself is a deterministic function of inlineform575 and inlineform576 .then we have inlineform577taking expectation over inlineform578 ( on behalf of the filtration inlineform579 ) on both sides , unwinding the recursion and noting that inlineform580 is fixed , we have inlineform581setting inlineform582 above completes the proof .we now need to show that the event inlineform583 occurs w.h.p .so that lemma secref60 makes sense in practice .lemma b.7 assume inlineform584 .then for any inlineform585and inlineform586 , if inlineform587then it holds that the event inlineform588 ( i.e. , inlineform589 for all inlineform590 ) occurs with probability at least inlineform591 .the key here is that inlineform592 as a stochastic process induces a super - martingale with respect to the filtration inlineform593 about random drawsinlineform594( note that inlineform595 is used on behalf of inlineform596 for brevity ) , and thus is amenable to a concentration of measure argument .in fact , according to the proof of lemma secref57 and noting that inlineform597we have inlineform598where inlineform599 . define inlineform600 for inlineform601 .note that inlineform602 , and { inlineform603 } is a finite sequence of random variables and thus the natural continuation can be applied to arrive at an infinite sequence such that inlineform604for any inlineform605 including inlineform606 .meanwhile , we have inlineform607thus , inlineform608 is a super - martingale .furthermore , by lemma secref40 , we have inlineform609where inlineform610 .now we are able to apply azuma - hoeffding inequality and have that for any inlineform611 and inlineform612inlineform613where inlineform614 .solving inlineform615 with respect to inlineform616 yieldsinlineform617 with inlineform618 .therefore , we get that inlineform619 , i.e. , inlineform620for all inlineform621 , with probability at least inlineform622 .note that the condition inlineform623 implies that inlineform624 .then it 's reduced to inlineform625 , which can be satisfied by using a sufficiently small inlineform626 when inlineform627 is set properly , e.g. , inlineform628 .lemma b.8 fix confidence parameters inlineform629 and assume that inlineform630 are set such that inlineform631 and inlineform632then it holds that with probability at least inlineform633 , inlineform634by markov inequality , we get inlineform635while by lemma secref60 , we have inlineform636thus , inlineform637that is , with probability at least inlineform638 , inlineform639 conditioned on inlineform640 .combining with lemma secref61 , we get that inlineform641 with probabilityat least inlineform642 .\n\none run analysis: we now proceed to the analysis on one complete run of our svrrg - eigs algorithm .again , assume that inlineform643 .let inlineform644 and assume that inlineform645 .then by lemma secref62 , for any inlineform646 , inlineform647 , andinlineform648 such that inlineform649we have that inlineform650with probability at least inlineform651 .note that inlineform652 for any inlineform653 and hence inlineform654 for any inlineform655 which in turn inducesinlineform656 ,i.e. , inlineform657 , for any inlineform658 and inlineform659 .since inlineform660 by inlineform661 , we can write inlineform662noting that inlineform663 , we get inlineform664 with probability at least inlineform665 .in a similar fashion , since inlineform666 and thus inlineform667we can apply lemma secref62 on the second epoch and get inlineform668 with probabilityat least inlineform669 , conditioned on the first epoch .if conditioned on the initial setting , we then have inlineform670 with probabilityat least inlineform671 provided that inlineform672 .in this way , we can see that repeating above process till the inlineform673 -th epoch will result in inlineform674with probability at least inlineform675 , conditioned on the initial setting and inlineform676 .then solving inlineform677 for inlineform678 tells that inlineform679 epochs suffice to achieve any aimed accuracy inlineform680 for inlineform681 with probability at least inlineform682 .to simplify these expressions , setting inlineform683 leads to inlineform684accordingly , the initial conditions become inlineform685 , inlineform686 ,inlineform687 and inlineform688with the assumptioninlineform689 , we could rewrite the above inequality as inlineform690now we can conclude that , for any inlineform691 and any inlineform692 , we have inlineform693 with probability at least inlineform694 by running inlineform695 epochs of our svrrg - eigs algorithm , if the following conditions are satisfied : inlineform696where the positive constants are inlineform697",
      "target_text": "we study the stochastic riemannian gradient algorithm for matrix eigen - decomposition .the state - of - the - art stochastic riemannian algorithm requires the learning rate to decay to zero and thus suffers from slow convergence and sub - optimal solutions .in this paper , we address this issue by deploying the variance reduction ( vr ) technique of stochastic gradient descent ( sgd ) .the technique was originally developed to solve convex problems in the euclidean space .we generalize it to riemannian manifolds and realize it to solve the non - convex eigen - decomposition problem .we are the first to propose and analyze the generalization of svrg to riemannian manifolds .specifically , we propose the general variance reduction form , svrrg , in the framework of the stochastic riemannian gradient optimization .it 's then specialized to the problem with eigensolvers and induces the svrrg - eigs algorithm .we provide a novel and elegant theoretical analysis on this algorithm .the theory shows that a fixed learning rate can be used in the riemannian setting with an exponential global convergence rate guaranteed .the theoretical results make a significant improvement over existing studies , with the effectiveness empirically verified .",
      "output_text": "decaying learning rate in dsrg-eigs .theoretical analysis also shows that the convergence rate of svrg- eigs is exponential in the number of iterations , which is much faster than the exponential convergence rate in the case of dsrg.experimental results show that the proposed algorithm outperforms the state-of-the-art algorithms in terms of the convergence speed and the quality of the solution."
    }
  ]
}